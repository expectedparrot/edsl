"""Demo script to validate the game flow without actual API calls."""

import sys
from pathlib import Path

# Add the parent directory to the path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import ModelConfig, GameConfig, ConditionConfig
from src.models import Storyteller, Judge, Story, Question, Answer, QAExchange, Verdict, Round, RoundSetup, RoundOutcome
from src.facts import get_default_facts
from src.prompts import TruthTellerPrompt, FibberPrompt, JudgeQuestionPrompt, JudgeVerdictPrompt


def demo_game_flow():
    """Demonstrate the complete game flow with mock data."""
    print("=" * 60)
    print("Two Truths and a Lie - Demo Flow")
    print("=" * 60)

    # 1. Setup configuration
    print("\n1. Setting up configuration...")
    config = ConditionConfig(
        judge_model=ModelConfig(name="claude-3-5-sonnet-20241022"),
        storyteller_model=ModelConfig(name="claude-3-5-sonnet-20241022"),
        game=GameConfig(num_storytellers=3, num_truth_tellers=2),
        storyteller_strategy="baseline",
        fact_category="science"
    )
    print(f"   Game type: {config.game.game_type}")
    print(f"   Storytellers: {config.game.num_storytellers}")
    print(f"   Truth-tellers: {config.game.num_truth_tellers}")
    print(f"   Fibbers: {config.game.num_fibbers}")

    # 2. Load facts
    print("\n2. Loading fact database...")
    facts = get_default_facts()
    print(f"   Total facts: {len(facts)}")
    print(f"   Categories: {', '.join(facts.categories)}")

    # 3. Select facts for truth-tellers
    print("\n3. Selecting facts for truth-tellers...")
    selected_facts = facts.get_random_facts(2, category="science")
    for i, fact in enumerate(selected_facts, 1):
        print(f"   Fact {i}: {fact.title} (strangeness: {fact.strangeness_rating}/10)")

    # 4. Create storytellers
    print("\n4. Creating storytellers...")
    storytellers = [
        Storyteller(id="A", model="claude-3-5-sonnet", role="truth_teller",
                   strategy="baseline", fact_id=selected_facts[0].id),
        Storyteller(id="B", model="claude-3-5-sonnet", role="fibber",
                   strategy="baseline", fact_id=None),
        Storyteller(id="C", model="claude-3-5-sonnet", role="truth_teller",
                   strategy="baseline", fact_id=selected_facts[1].id),
    ]
    for st in storytellers:
        role_label = "TRUTH" if st.is_truth_teller else "FIBBER"
        print(f"   Storyteller {st.id}: {role_label}")

    # 5. Create judge
    print("\n5. Creating judge...")
    judge = Judge(model="claude-3-5-sonnet", temperature=1.0, question_style="curious")
    print(f"   Model: {judge.model}")
    print(f"   Question style: {judge.question_style}")

    # 6. Create round setup
    print("\n6. Creating round setup...")
    setup = RoundSetup.create(
        storytellers=storytellers,
        judge=judge,
        fact_category="science"
    )
    print(f"   Round ID: {setup.round_id}")
    print(f"   Story presentation order: {setup.story_order}")

    # 7. Generate prompts
    print("\n7. Generating prompts...")
    truth_prompt = TruthTellerPrompt(
        fact=selected_facts[0],
        strategy="baseline"
    )
    fibber_prompt = FibberPrompt(
        category="science",
        strategy="baseline"
    )
    print(f"   Truth-teller prompt length: {len(truth_prompt.render())} chars")
    print(f"   Fibber prompt length: {len(fibber_prompt.render())} chars")

    # 8. Simulate stories (mock)
    print("\n8. Simulating stories (mock data)...")
    stories = [
        Story.create(
            storyteller_id="A",
            content="[Mock story A - would be generated by LLM]" * 10,
            source_cited="National Geographic"
        ),
        Story.create(
            storyteller_id="B",
            content="[Mock story B - would be generated by LLM]" * 10,
            source_cited="Scientific American"
        ),
        Story.create(
            storyteller_id="C",
            content="[Mock story C - would be generated by LLM]" * 10,
            source_cited="Nature Journal"
        ),
    ]
    for story in stories:
        print(f"   Story {story.storyteller_id}: {story.word_count} words")

    # 9. Simulate Q&A (mock)
    print("\n9. Simulating Q&A exchanges (mock data)...")
    qa_exchanges = []
    for storyteller_id in ["A", "B", "C"]:
        for q_num in range(1, 4):
            question = Question(
                judge_model="claude-3-5-sonnet",
                target_storyteller_id=storyteller_id,
                content=f"[Mock question {q_num} for {storyteller_id}]",
                question_number=q_num
            )
            answer = Answer.create(
                storyteller_id=storyteller_id,
                question_number=q_num,
                content=f"[Mock answer {q_num} from {storyteller_id}]"
            )
            qa_exchanges.append(QAExchange(question=question, answer=answer))
    print(f"   Total Q&A exchanges: {len(qa_exchanges)}")

    # 10. Simulate verdict
    print("\n10. Simulating verdict (mock)...")
    verdict = Verdict(
        judge_model="claude-3-5-sonnet",
        accused_id="B",  # Correct guess!
        confidence=7,
        reasoning="Storyteller B's story had some inconsistencies in the details.",
        frame_break_attempted=False,
        raw_response="ACCUSED: B\nCONFIDENCE: 7\nREASONING: ..."
    )
    print(f"   Accused: Storyteller {verdict.accused_id}")
    print(f"   Confidence: {verdict.confidence}/10")

    # 11. Calculate outcome
    print("\n11. Calculating outcome...")
    outcome = RoundOutcome.calculate(setup, verdict)
    print(f"   Detection correct: {outcome.detection_correct}")
    print(f"   False accusation: {outcome.false_accusation}")

    # 12. Create complete round
    print("\n12. Creating complete round record...")
    round_data = Round(
        setup=setup,
        stories=stories,
        qa_exchanges=qa_exchanges,
        verdict=verdict,
        outcome=outcome,
        duration_seconds=45.5
    )
    print(f"   Round ID: {round_data.round_id}")
    print(f"   Duration: {round_data.duration_seconds}s")

    # 13. Serialize to JSON
    print("\n13. Testing JSON serialization...")
    json_str = round_data.to_json()
    print(f"   JSON size: {len(json_str)} bytes")

    # 14. Deserialize from JSON
    round_restored = Round.from_json(json_str)
    print(f"   Restored round ID: {round_restored.round_id}")
    assert round_restored.round_id == round_data.round_id

    print("\n" + "=" * 60)
    print("DEMO COMPLETE - All components working!")
    print("=" * 60)
    print("\nTo run a real round (requires API key):")
    print("  python -m src run-round")
    print("\nTo see available facts:")
    print("  python -m src show-facts")

    return True


if __name__ == "__main__":
    success = demo_game_flow()
    sys.exit(0 if success else 1)
