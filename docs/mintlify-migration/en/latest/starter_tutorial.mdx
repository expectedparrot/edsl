---
title: "Starter Tutorial"
description: "This tutorial provides step-by-step instructions for getting started using EDSL (*Expected Parrot Domain-Specific Language*), an open-source Python library for simulating surveys, experiments and other research tasks using AI agents and large language models. EDSL is developed by [Expected Parrot](https://www.expectedparrot.com/about) and available under the MIT License. The source code is hosted on [GitHub](https://github.com/expectedparrot/edsl)."
---

**Goals of this tutorial**

We begin with technical setup: instructions for installing the EDSL library and storing API keys to access language models. Then we demonstrate some of the basic features of EDSL, with examples for constructing and running surveys with agents and models, and analyzing responses as datasets. By the end of this tutorial, you will be able to use EDSL to do each of the following:

- Construct various types of [questions](/en/latest/questions) tailored to your research objectives.
- Combine questions into [surveys](/en/latest/surveys) and integrate logical rules to control the survey flow.
- Add context to questions by *piping*answers, adding *memory* of prior questions and answers, and using [scenarios](/en/latest/scenarios) to add data or content to questions.
- Design personas for AI [agents](/en/latest/agents) to simulate responses to your surveys.
- Choose and deploy [language models](/en/latest/language_models) to generate responses for AI agents.
- Analyze [results](/en/latest/results) as datasets with built-in analytical tools.
- Validate LLM answers with [human respondents](/en/latest/humanize).

**Storing & sharing your work**

We also introduce [Coop](https://www.expectedparrot.com/content/explore): a platform for creating, storing and sharing AI-based research. Coop is fully integrated with EDSL and free to use. At the end of the tutorial we show how to use EDSL with Coop by posting content created in this tutorial for anyone to view at the web app. Learn more about how coop works in the EDSL documentation.

<Note>
**Note:**

You can also view and download the contents of this tutorial in a [notebook at Coop](https://www.expectedparrot.com/content/RobinHorton/starter-tutorial)
</Note>

**Further reading**

In addition to this tutorial, please also see an [Overview](/en/latest/overview#overview) of features and common use cases for EDSL and a [Survey logic checklist](/en/latest/checklist#checklist) of tips for using EDSL effectively in the [EDSL documentation page](/en/latest/index). To see recent research using or citing EDSL, see [Papers & Citations](/en/latest/papers#papers) in the documentation.

**Questions**

If you encounter any issues or have questions, please email us at [info@expectedparrot.com](mailto:info@expectedparrot.com) or post a question at our [Discord channel](https://discord.com/invite/mxAYkjfy9m).


## Pre-requisites

EDSL is compatible with Python 3.9 - 3.12. Before starting this tutorial, please ensure that you have a Python environment set up on your machine or in a cloud-based environment, such as Google Colab. You can find instructions for installing Python at the [Python Software Foundation](https://www.python.org/downloads/).

## Recommendations

Run code examples in a notebook

The code examples in this tutorial are designed to be run in a Jupyter notebook or another Python environment, or in a cloud-based environment such as Google Colab. If you are using Google Colab, please see additional instructions for setting up EDSL in the [Colab setup](/en/latest/colab_setup) page in the documentation.

Use a virtual environment

We also recommend using a virtual environment when installing and using EDSL in order to avoid conflicts with other Python packages. You can find instructions for setting up a virtual environment at the [Python Packaging Authority](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).

Special instructions for Colab users

If you are using EDSL in a cloud-based environment, such as Google Colab, you can find additional instructions for setting up EDSL in the [Colab setup](/en/latest/colab_setup) page in the documentation.

## Installation

To begin using EDSL, you first need to install the library. This can either be done locally on your machine or in a cloud-based environment, such as Google Colab. Once you have decided where to install EDSL, you can choose to whether install it from [PyPI](https://pypi.org/project/edsl/) or [GitHub](https://github.com/expectedparrot/edsl):

From PyPI

Install EDSL directly using pip, which is straightforward and recommended for most users. We also recommend using a virtual environment to manage your Python packages (see *Recommendations* above). Run the following command in your notebook to install EDSL from PyPI:

```bash
! uv pip install edsl -q
```

From GitHub

You can find the source code for EDSL and contribute to the project at [GitHub](https://github.com/expectedparrot/edsl). Installing from GitHub allows you to get the latest updates to EDSL before they are released to a new version at PyPI. This is recommended if you are using new features or contributing to the project. Run the following command to install EDSL from GitHub:

```bash
pip install git+https://github.com/expectedparrot/edsl.git@main
```

After installing EDSL, you can check the version that you have installed by running the following command in your notebook:

```bash
pip show edsl
```

To update your installation of EDSL to the latest version at PyPI, run the following command:

```bash
pip install --upgrade edsl
```

## Create an account

Creating an account allows you to run survey jobs at Expected Parrot using language models of your choice, and automatically cache your results. Your account also allows you to launch human surveys and share your content and workflows with other users. Your account comes with $25 in credits for API calls to LLMs for getting started, and a referal code for earning more credits.

[Create an account](https://www.expectedparrot.com/login) with an email address and password, or run the following code to be prompted automatically:

```python
from edsl import login

login()
```

The above code also automatically stores your Expected Parrot API key for use with EDSL (see below).

## Accessing Language Models

The next step is to decide how you want to access language models. EDSL works with many popular language models that you can choose from to generate responses to your surveys. These models are hosted by various service providers, such as Anthropic, Azure, Bedrock, Deep Infra, DeepSeek, Google, Groq, Mistral, OpenAI, Replicate, Together and Xai. In order to run a survey, you need to provide API keys for the service providers of models that you want to use. There are two methods for providing API keys to EDSL:

- Use an Expected Parrot API key to access all available models
- Provide your own API keys from service providers

### Managing keys

The easiest way to manage your keys is from your Expected Parrot account. [Log in](https://www.expectedparrot.com/login) to your account and navigate to your [Keys](https://www.expectedparrot.com/home/keys) page to find options for adding and sharing your keys.

Your Expected Parrot key is automatically available to use by default whenever remote inference is activated. This key allows you to access the Expected Parrot server and run surveys with all available models.

Please see the [Managing Keys](/en/latest/api_keys) section for more details on methods of storing and managing keys.

<Note>
*Note:* If you try to run a survey without storing a required API key, you will be provided a link to activate remote inference and use your Expected Parrot key.
</Note>

### Credits & tokens

Running surveys with language models requires tokens. If you are using your own API keys, service providers will bill you directly. If you are using your Expected Parrot API key to access models, you will need to purchase credits to cover token costs. Please see the model pricing page for details on available models and their current prices.

<Note>
*Note:* Your account comes with 2,500 free credits ($25 worth of API calls). You can purchase more credits at any time at your [Credits](https://www.expectedparrot.com/home/purchases) page.
</Note>

After installing EDSL and storing API keys you are ready to run some examples!

## Example: Running a simple question

EDSL comes with a [variety of question types](/en/latest/questions) that we can choose from based on the form of the response that we want to get back from a model, including multiple choice, checkbox, rank, top-k, linear scale, likert five, yes/no, numerical, free text, extract, list, matrix and functional questions.

We can inspect the components of a particular question type by importing the question type class and calling the example method on it:

```python
from edsl import (
  # QuestionCheckBox,
  # QuestionExtract,
  # QuestionFreeText,
  # QuestionFunctional,
  # QuestionLikertFive,
  # QuestionLinearScale,
  # QuestionList,
  QuestionMultipleChoice,
  # QuestionNumerical,
  # QuestionRank,
  # QuestionTopK,
  # QuestionYesNo
)

q = QuestionMultipleChoice.example() # substitute any question type class name
q
```

Output:

| key | value |
| :--- | :--- |
| question_name | how_feeling |
| question_text | How are you? |
| question_options:0 | Good |
| question_options:1 | Great |
| question_options:2 | OK |
| question_options:3 | Bad |
| include_comment | False |
| question_type | multiple_choice |

Here we create a simple multiple choice question:

```python
from edsl import QuestionMultipleChoice

q = QuestionMultipleChoice(
  question_name = "smallest_prime",
  question_text = "Which is the smallest prime number?",
  question_options = [0, 1, 2, 3]
)
```

We can administer it to a language model by calling the run() method on it.

```python
results = q.run()
```

This generates a dataset of Results that we can readily access with [built-in methods for analysis](/en/latest/results). Here we inspect the response, together with the model that was used and the model’s “comment” about its response–a field that is automatically added to all question types other than free text:

```python
results.select("model", "smallest_prime", "smallest_prime_comment")
```

Output:

| model.model | answer.smallest_prime | comment.smallest_prime_comment |
| :--- | :--- | :--- |
| gpt-4o | 2 | 2 is the smallest prime number because it is the only even number greater than 1 that is divisible only by 1 and itself. |

The Results also include information about the question, model parameters, prompts, generated tokens and raw responses. To see a list of all the components:

```python
results.columns
```

Output:

| 0 |
| :--- |
| agent.agent_instruction |
| agent.agent_name |
| answer.smallest_prime |
| comment.smallest_prime_comment |
| generated_tokens.smallest_prime_generated_tokens |
| iteration.iteration |
| model.frequency_penalty |
| model.logprobs |
| model.max_tokens |
| model.model |
| model.presence_penalty |
| model.temperature |
| model.top_logprobs |
| model.top_p |
| prompt.smallest_prime_system_prompt |
| prompt.smallest_prime_user_prompt |
| question_options.smallest_prime_question_options |
| question_text.smallest_prime_question_text |
| question_type.smallest_prime_question_type |
| raw_model_response.smallest_prime_cost |
| raw_model_response.smallest_prime_one_usd_buys |
| raw_model_response.smallest_prime_raw_model_response |

<Note>
*Note:* If we are running the job locally we can pass run(progress_bar=True) to view a Progress Report. Any exceptions will appear in the console.
</Note>

If remote inference is activated, a link to a Progress Report will appear automatically, as well as a link to an Exceptions Report if there are any. When the job is completed, a link to the Results page will also appear.

## Example: Conducting a survey with agents and models

In the next example we construct a more complex survey consisting of multiple questions and design personas for AI agents to answer it. Then we select specific language models to generate the answers.

We start by creating questions in different types and passing them to a Survey:

```python
from edsl import QuestionLinearScale, QuestionFreeText

q_enjoy = QuestionLinearScale(
  question_name = "enjoy",
  question_text = "On a scale from 1 to 5, how much do you enjoy reading?",
  question_options = [1, 2, 3, 4, 5],
  option_labels = {1:"Not at all", 5:"Very much"}
)

q_favorite_place = QuestionFreeText(
  question_name = "favorite_place",
  question_text = "Describe your favorite place for reading."
)
```

We construct a Survey by passing a list of questions:

```python
from edsl import Survey

survey = Survey(questions = [q_enjoy, q_favorite_place])
```

### Agents

An important feature of EDSL is the ability to create AI agents to answer questions. This is done by passing dictionaries of relevant “traits” to Agent objects that are used by language models to generate responses. Learn more about [designing agents](/en/latest/agents).

Here we construct several simple agent personas to use with our survey:

```python
from edsl import AgentList, Agent

agents = AgentList(
  Agent(traits = {"persona":p}) for p in ["artist", "mechanic", "sailor"]
)
```

### Language models

EDSL works with many popular large language models that we can select to use with a survey. This makes it easy to compare responses among models in the results that are generated.

To see a current list of available models:

```python
from edsl import Model

# Model.available() # uncomment this code and run it to see the list of available models
```

To check the default model that will be used if no models are specified for a survey (e.g., as in the first example above):

```python
Model()
```
Output (may be different if the default model has changed):

| key | value |
| :--- | :--- |
| model | gpt-4o |
| parameters:temperature | 0.5 |
| parameters:max_tokens | 1000 |
| parameters:top_p | 1 |
| parameters:frequency_penalty | 0 |
| parameters:presence_penalty | 0 |
| parameters:logprobs | False |
| parameters:top_logprobs | 3 |

Here we select some models to use with our survey:

```python
from edsl import ModelList, Model

models = ModelList(
  Model(m) for m in ["gpt-4o", "gemini-pro"]
  )
```

### Running a survey

We add agents and models to a survey using the by method. Then we administer a survey the same way that we do an individual question, by calling the run method on it:

```python
results = survey.by(agents).by(models).run()

(
  results
  .sort_by("persona", "model")
  .select("model", "persona", "enjoy", "favorite_place")
)
```

Example output:

| model.model | agent.persona | answer.enjoy | answer.favorite_place |
| :--- | :--- | :--- | :--- |
| gemini-pro | artist | 5 | Nestled amidst the verdant embrace of a sprawling park, my favorite reading sanctuary unfolds as a secluded haven where tranquility reigns supreme. Beneath the towering canopy of ancient oak trees, a quaint bench beckons, its weathered surface inviting me to sink into its embrace. As I settle in, the gentle rustling of leaves overhead creates a soothing symphony that calms my mind and prepares me for the literary journey ahead. The air is fragrant with the sweet scent of blooming wildflowers, carried by a soft breeze that whispers secrets through the trees. The vibrant hues of nature paint the canvas around me, inspiring a sense of wonder and connection to the world. As I open the pages of my chosen book, the outside world fades into oblivion. The words dance before my eyes, inviting me into realms unknown. The characters become my companions, their stories unfolding before me like a captivating tapestry. Time seems to stand still in this idyllic setting. The worries of the day dissolve as I immerse myself in the written word. As the sun begins its descent, casting long shadows across the park, I close my book and savor the lingering glow of the day. The world around me has transformed into a magical realm, where the boundaries between reality and imagination blur. |
| gpt-4o | artist | 4 | My favorite place for reading is a cozy nook by a large window in my art studio. The natural light that streams in during the day is perfect for both reading and painting. I have a comfortable armchair draped with a colorful throw, and a small wooden side table where I keep a steaming cup of herbal tea. The walls are adorned with my paintings, which add a touch of inspiration and creativity to the atmosphere. It’s a quiet, peaceful space where I can lose myself in a good book or simply gaze out at the changing scenery outside. |
| gemini-pro | mechanic | 5 | In the heart of my cozy abode, where solitude and inspiration intertwine, lies my sanctuary of literary bliss—my reading nook. Bathed in the warm glow of a vintage lamp, it beckons me with its allure, a haven where I can escape into the realms of imagination. The walls are adorned with shelves brimming with an eclectic collection of books, their spines whispering tales of adventure, romance, and wisdom. The air is infused with the faint scent of paper and ink, a symphony that awakens my senses. A plush armchair, upholstered in soft velvet, invites me to sink into its embrace, enveloping me in a cocoon of comfort. A large window frames the verdant garden outside, offering a tranquil view of nature’s artistry. As I turn the pages, the rustling of leaves and the chirping of birds create a soothing soundtrack that enhances my reading experience. The gentle breeze carries the sweet fragrance of blooming flowers, mingling with the scent of freshly brewed coffee on my side table. In this tranquil haven, I am free to lose myself in the written word. Time seems to stand still as I journey through distant lands, unravel mysteries, and explore the depths of human emotion. The characters become my companions, their struggles and triumphs mirroring my own. |
| gpt-4o | mechanic | 2 | As a mechanic, my favorite place for reading might not be what you’d expect. I enjoy reading in my garage, surrounded by the hum of engines and the smell of oil. There’s something comforting about being in my element, with tools and parts all around me. I usually set up a small corner with a sturdy chair and a good lamp, so I can dive into a book during my breaks. Whether it’s a manual on the latest automotive technology or a novel to unwind, the garage is my go-to spot. |
| gemini-pro | sailor | 5 | Amidst the bustling city’s cacophony, I seek solace in a sanctuary of tranquility—my favorite reading nook. Nestled in a cozy corner of my apartment, it is an oasis of serenity. The soft glow of a vintage lamp illuminates a comfortable armchair, its plush cushions inviting me to sink into its embrace. A large window frames a vibrant cityscape, providing a backdrop of constant movement and life. Yet, within this cozy haven, I find stillness and escape. The walls are adorned with an eclectic collection of artwork, each piece evoking a different memory or inspiration. A vibrant abstract painting captures the essence of a stormy sea, while a delicate watercolor depicts the serene beauty of a mountain meadow. These visual cues transport me to distant realms, setting the stage for literary adventures. The air is scented with the faint aroma of freshly brewed coffee and the subtle fragrance of old books. The gentle hum of the city outside fades into a distant murmur, creating an atmosphere conducive to deep contemplation and immersion. As I settle into my armchair, I reach for a book. Its pages hold the promise of countless worlds to explore, characters to meet, and lessons to learn. The weight of the book in my hands feels both comforting and exhilarating, a tangible connection to the boundless possibilities within its covers. With each turn of the page, I am transported to different times and places. I witness the rise and fall of empires, the triumphs and tragedies of human lives, and the wonders of the natural world. The words dance before my eyes, painting vivid images in my mind. I become lost in the stories, my own worries and concerns fading away. |
| gpt-4o | sailor | 3 | Ah, my favorite place for reading has to be the deck of a ship, with the vast ocean stretching out endlessly before me. There’s something about the gentle rocking of the waves and the salty sea breeze that makes any book come alive. I love settling into a sturdy deck chair, perhaps with a mug of strong coffee or a tot of rum by my side, and losing myself in a tale while the sun sets on the horizon, painting the sky with colors that even the best of stories can’t quite capture. The sound of the water lapping against the hull provides a soothing background, making it the perfect spot to dive into a good book. |

### Running a survey in the background

If remote inference is activated, we can optionally run the survey in the background and continue working (or not) while waiting for results to be generated:

```python
results = survey.by(agents).by(models).run(background=True)
```

This will return a link to the progress bar page (as usual), which you can check at any time. You can also check the status of the job by running:

```python
results.fetch()
```

This will return either a status update or the results. Once the job is completed, you can call the results as usual, e.g.:

```python
results.columns # to view a list of all columns

results.select("answer.*") # to view all answers
```

## [Example: Adding context to questions](/en/latest/#id24)

EDSL provides a variety of ways to add data or content to survey questions. These methods include:

- [Piping](/en/latest/surveys#id2) answers to questions into follow-on questions
- [Adding “memory”](/en/latest/surveys#question-memory) of prior questions and answers in a survey when presenting other questions to a model
- [Parameterizing questions with data](/en/latest/scenarios), e.g., content from PDFs, CSVs, docs, images or other sources that you want to add to questions

### [Piping question answers](/en/latest/#id25)

Here we demonstrate how to pipe the answer to a question into the text of another question. This is done by using a placeholder {'{ <question_name>.answer }'} in the text of the follow-on question where the answer to the prior question is to be inserted when the survey is run. This causes the questions to be administered in the required order (survey questions are administered asynchronously by default). Learn more about [piping question answers](/en/latest/surveys#id2).

Here we insert the answer to a numerical question into the text of a follow-on yes/no question:

```python
from edsl import QuestionNumerical, QuestionYesNo, Survey

q1 = QuestionNumerical(
  question_name = "random_number",
  question_text = "Pick a random number between 1 and 1,000."
)

q2 = QuestionYesNo(
  question_name = "prime",
  question_text = "Is this a prime number: {{ random_number.answer }}"
)

survey = Survey([q1, q2])

results = survey.run()
```

We can check the user_prompt for the prime question to verify that that the answer to the random_number question was piped into it:

```python
results.select("random_number", "prime_user_prompt", "prime", "prime_comment")
```

Example output:

| answer.random_number | prompt.prime_user_prompt | answer.prime | comment.prime_comment |
| :--- | :--- | :--- | :--- |
| 487 | Is this a prime number: 487  No  Yes  Only 1 option may be selected. Please respond with just your answer.  After the answer, you can put a comment explaining your response. | No | 487 is not a prime number because it can be divided evenly by 1, 487, and also by 19 and 25. |

### [Adding “memory” of questions and answers](/en/latest/#id26)

Here we instead add a “memory” of the first question and answer to the context of the second question. This is done by calling a memory rule and identifying the question(s) to add. Instead of just the answer, information about the full question and answer are presented with the follow-on question text, and no placeholder is used. Learn more about [question memory rules](/en/latest/surveys#survey-rules-logic).

Here we demonstrate the add_targeted_memory method (we could also use set_full_memory_mode or other memory rules):

```python
from edsl import QuestionNumerical, QuestionYesNo, Survey

q1 = QuestionNumerical(
  question_name = "random_number",
  question_text = "Pick a random number between 1 and 1,000."
)

q2 = QuestionYesNo(
  question_name = "prime",
  question_text = "Is the number you picked a prime number?"
)

survey = Survey([q1, q2]).add_targeted_memory(q2, q1)

results = survey.run()
```

We can again use the user_prompt to verify the context that was added to the follow-on question:

```python
results.select("random_number", "prime_user_prompt", "prime", "prime_comment").table().long()
```

Example output:

| row | key | value |
| :--- | :--- | :--- |
| 0 | answer.random_number | 487 |
| 0 | prompt.prime_user_prompt | Is the number you picked a prime number?  No  Yes |

## Scenarios

We can also add external data or content to survey questions. This can be useful when you want to efficiently create and administer multiple versions of questions at once, e.g., for conducting data labeling tasks. This is done by creating Scenario dictionaries for the data or content to be used with a survey, where the keys match {`{ placeholder }`} names used in question texts (or question options) and the values are the content to be added. Scenarios can also be used to [add metadata to survey results](/en/latest/notebooks/adding_metadata), e.g., data sources or other information that you may want to include in the results for reference but not necessarily include in question texts.

In the next example we revise the prior survey questions about reading to take a parameter for other activities that we may want to add to the questions, and create simple scenarios for some activities. EDSL provides methods for automatically generating scenarios from a variety of data sources, including PDFs, CSVs, docs, images, tables and dicts. We use the from_list method to convert a list of activities into scenarios.

Then we demonstrate how to use scenarios to create multiple versions of our questions either \(i\) when constructing a survey or \(ii\) when running it:

- In the latter case, the by method is used to add scenarios to a survey of questions with placeholders at the time that it is run (the same way that agents and models are added to a survey). This adds a scenario column to the results with a row for each answer to each question for each scenario.
- In the former case, the loop method is used to create a list of versions of a question with the scenarios already added to it; when the questions are passed to a survey and it is run, the results include columns for each individual question; there is no scenario column and a single row for each agent’s answers to all the questions.

Learn more about [using scenarios](/en/latest/scenarios).

Here we create simple scenarios for a list of activities:

```python
from edsl import ScenarioList, Scenario

scenarios = ScenarioList.from_list("activity", ["reading", "running", "relaxing"])
```

### Adding scenarios using the by method

Here we add the scenarios to the survey when we run it, together with any desired agents and models:

```python expandable
from edsl import QuestionLinearScale, QuestionFreeText, Survey

q_enjoy = QuestionLinearScale(
  question_name = "enjoy",
  question_text = "On a scale from 1 to 5, how much do you enjoy {{ activity }}?",
  question_options = [1, 2, 3, 4, 5],
  option_labels = {1:"Not at all", 5:"Very much"}
)

q_favorite_place = QuestionFreeText(
  question_name = "favorite_place",
  question_text = "In a brief sentence, describe your favorite place for {{ activity }}."
)

survey = Survey([q_enjoy, q_favorite_place])

results = survey.by(scenarios).by(agents).by(models).run()

(
  results
  .filter("model.model == 'gpt-4o'")
  .sort_by("activity", "persona")
  .select("activity", "persona", "enjoy", "favorite_place")
)
```

Output:

| scenario.activity | agent.persona | answer.enjoy | answer.favorite_place |
| :--- | :--- | :--- | :--- |
| reading | artist | 4 | My favorite place for reading is a cozy nook by a large window, where the natural light spills over the pages, surrounded by plants and the gentle hum of city life outside. |
| reading | mechanic | 2 | My favorite place for reading is in my garage, surrounded by the hum of engines and the scent of motor oil, where I can escape into a good book during breaks. |
| reading | sailor | 3 | Ah, my favorite place for reading is out on the deck of a ship, with the salty sea breeze in my hair and the gentle rocking of the waves beneath me. |
| relaxing | artist | 4 | My favorite place for relaxing is a sun-dappled studio filled with the scent of fresh paint and the gentle hum of creativity. |
| relaxing | mechanic | 3 | My favorite place for relaxing is in my garage, tinkering with an old engine, where the hum of tools and the smell of grease help me unwind. |
| relaxing | sailor | 3 | There’s nothing quite like the gentle sway of a hammock on the deck of a ship, with the sound of the ocean waves lapping against the hull and the salty breeze in the air. |
| running | artist | 2 | My favorite place for running is a winding forest trail where the sunlight filters through the leaves, creating a dappled pattern on the ground. |
| running | mechanic | 1 | My favorite place for running is a quiet trail through the woods, where the fresh air and natural surroundings make each step feel refreshing. |
| running | sailor | 2 | Ah, my favorite place for running is along the rugged coastline, where the salty sea breeze fills the air and the waves crash against the rocks, reminding me of the vastness of the ocean. |

## Exploring Results

EDSL comes with [built-in methods for analyzing and visualizing survey results](/en/latest/language_models). For example, you can call the to_pandas method to convert results into a dataframe:

```python
df = results.to_pandas(remove_prefix=True)
```

The Results object also supports SQL-like queries with the the sql method:

```python
results.sql("""
select model, persona, enjoy_reading, favorite_place_reading
from self
order by 1,2,3
""")
```

Output:

```python

```

## Posting to Coop

The [Coop](https://www.expectedparrot.com/content/explore) is a platform for creating, storing and sharing LLM-based research. It is fully integrated with EDSL and accessible from your workspace or Coop account page. Learn more about [creating an account](https://www.expectedparrot.com/login) and [using Coop](/en/latest/coop).

We can post any EDSL object to Coop by calling the push method on it, optionally passing a description, a convenient alias for the Coop URL that is created and a visibility status (*public*, *private* or *unlisted* by default):

```python
results.push(
  description = "Starter tutorial sample survey results",
  alias = "starter-tutorial-example-survey-results",
  visibility = "public"
)
```

Example output (UUIDs will be unique to objects):

```json
{
'description': 'Starter tutorial sample survey results',
'object_type': 'results',
'url': 'https://www.expectedparrot.com/content/9c8ba866-2be3-4ad6-9d2f-8160a06b2cf7',
'uuid': '9c8ba866-2be3-4ad6-9d2f-8160a06b2cf7',
'version': '0.1.47.dev1',
'visibility': 'public'
}
```

To post a notebook:

```python
from edsl import Notebook

notebook = Notebook(path="filename.ipynb")

notebook.push(description="Starter Tutorial", alias = "example-notebook-new-alias", visibility="public")
```

You can view and download a notebook for this tutorial [at Coop](https://www.expectedparrot.com/content/RobinHorton/starter-tutorial).

