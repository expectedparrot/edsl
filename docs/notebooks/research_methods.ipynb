{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8d3a12ec47fb4b75b5fc8351d0da55cc",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Research: Exploring use cases & creating new methods\n",
    "This demo notebook shows some ways of using EDSL to conduct research, including data labeling, cognitive testing and creating new methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/expectedparrot/edsl/blob/main/docs/notebooks/research_methods.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "28ff78e673114ddc8ff7ab0c963761df",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2964,
    "execution_start": 1709255945423,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# ! pip install edsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c42102c4e43d4df193939499ede981fa",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Cognitive testing\n",
    "In this example we use the tools to evaluate some draft survey questions and suggest improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "4ef542687e9147d592ef12257f2fef5b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 241,
    "execution_start": 1709255968869,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from edsl.questions import QuestionFreeText\n",
    "from edsl import Agent, Scenario, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4f5539d6a4084723b87a26dad9e737ea",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Create a relevant persona and assign it to an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "63f1700826e64775bf5b22ea641f7f23",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 23,
    "execution_start": 1709255974214,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "agent_description = \"You are an expert in survey methodology and evaluating questionnaires.\"\n",
    "\n",
    "agent = Agent(traits = {\"background\": agent_description})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7c800923b0224f6b8ef081bc614f1f3c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Identify a set of texts for review (these can also be imported):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "797649ed15674781a29ac2716890f890",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 110,
    "execution_start": 1709255976757,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "draft_texts = [\n",
    "    \"Do you feel the product is almost always of good quality?\",\n",
    "    \"On a scale of 1 to 5, where 1 means strongly agree and 5 means strongly disagree, how satisfied are you with our service?\",\n",
    "    \"Do you believe our IT team's collaborative synergy effectively optimizes our digital infrastructure?\",\n",
    "    \"What do you think of our recent implementation of Project X57?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8df2503d9284419c861d33df5526c474",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Construct a question about the texts, which will be added as a parameter of the question individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "0804128d2581473b92936fea7618f3d0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 90,
    "execution_start": 1709255979846,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "question = QuestionFreeText(\n",
    "    question_name = \"review_questions\",\n",
    "    question_text = \"\"\"Consider the following survey question: {{draft_text}}\n",
    "    Identify the problematic phrases in the excerpt and suggestion a revised version of it.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b1b17279959d4abe9255a9cb326e432c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Create \"scenarios\" of the question with the texts as paraemeters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "39746b95d16743d48e39b86280807aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 133,
    "execution_start": 1709255982576,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "scenarios = [Scenario({\"draft_text\": text}) for text in draft_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9c1164c8a20c479a87cad7b1cb8443fa",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Select an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "12b811cd5e454d499ed8234336f6d616",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 18,
    "execution_start": 1709255991411,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['claude-3-haiku-20240307',\n",
       " 'claude-3-opus-20240229',\n",
       " 'claude-3-sonnet-20240229',\n",
       " 'dbrx-instruct',\n",
       " 'gemini_pro',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-4-1106-preview',\n",
       " 'llama-2-13b-chat-hf',\n",
       " 'llama-2-70b-chat-hf',\n",
       " 'mixtral-8x7B-instruct-v0.1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "c6c5207fa5de46ebb64d1da248e7ce7c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 69,
    "execution_start": 1709256000175,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "model = Model('gpt-4-1106-preview', cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Administer the survey to the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "079d32f62e3c427f90a593c9a50c4921",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10223,
    "execution_start": 1709256002493,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "results = question.by(scenarios).by(agent).by(model).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "3986b40662054e3ab3396fc2070888c5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 548,
    "execution_start": 1709256035339,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent.agent_name',\n",
       " 'agent.background',\n",
       " 'answer.review_questions',\n",
       " 'iteration.iteration',\n",
       " 'model.frequency_penalty',\n",
       " 'model.logprobs',\n",
       " 'model.max_tokens',\n",
       " 'model.model',\n",
       " 'model.presence_penalty',\n",
       " 'model.temperature',\n",
       " 'model.top_logprobs',\n",
       " 'model.top_p',\n",
       " 'prompt.review_questions_system_prompt',\n",
       " 'prompt.review_questions_user_prompt',\n",
       " 'raw_model_response.review_questions_raw_model_response',\n",
       " 'scenario.draft_text']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "25d506fd9433468fb1124cc349674d9b",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "View select components of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "8bdfd00fb07b4b05b39b6be6d1774751",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 404,
    "execution_start": 1709256059995,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table id=\"myTable\" class=\"display\">\n",
       "  <thead>\n",
       "  <tr>\n",
       "    <th>Draft text</th>\n",
       "    <th>Evaluation</th>\n",
       "  </tr>\n",
       "  </thead>\n",
       "</tbody>\n",
       "  <tr>\n",
       "    <td>On a scale of 1 to 5, where 1 means strongly agree and 5 means strongly disagree, how satisfied are you with our service?</td>\n",
       "    <td>The problematic phrase in the survey question is the scale description, which mixes agreement with satisfaction levels, potentially leading to confusion. A revised version of the question could be: 'On a scale of 1 to 5, where 1 means very satisfied and 5 means very dissatisfied, how satisfied are you with our service?'</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Do you feel the product is almost always of good quality?</td>\n",
       "    <td>The problematic phrase in the question is 'almost always,' which introduces ambiguity and can lead to different interpretations of what constitutes 'almost.' Additionally, 'good quality' is subjective and may vary from person to person. A revised version of the question could be: 'How would you rate the quality of the product? (Please select one: Excellent, Good, Fair, Poor)' This revision provides a clear scale for respondents to evaluate the product quality, reducing ambiguity and subjectivity.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Do you believe our IT team's collaborative synergy effectively optimizes our digital infrastructure?</td>\n",
       "    <td>The original question contains jargon and could be considered leading, as it assumes that there is 'collaborative synergy' and that it has an effect on 'optimizing digital infrastructure.' A revised version of the question could be: 'How effective do you believe our IT team is in improving our digital infrastructure through collaboration? Please rate on a scale from 1 (not effective at all) to 5 (very effective).' This revised question is more straightforward and allows for a quantifiable response.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>What do you think of our recent implementation of Project X57?</td>\n",
       "    <td>The question 'What do you think of our recent implementation of Project X57?' is vague and open-ended, which could result in a wide variety of responses that may be difficult to analyze quantitatively. It assumes that respondents are aware of 'Project X57' and its implementation details. To improve the question, it should be made more specific and include options that allow for more structured responses. A revised version could be: 'How satisfied are you with the recent implementation of Project X57?' with a follow-up question such as 'Please rate your satisfaction on a scale from 1 (very unsatisfied) to 5 (very satisfied).' Additionally, it would be helpful to provide a brief description of Project X57 to ensure all respondents have a clear understanding of what they are evaluating.</td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(results\n",
    " .select(\"scenario.*\", \"answer.*\")\n",
    " .print(pretty_labels={\"scenario.draft_text\":\"Draft text\", \"answer.review_questions\": \"Evaluation\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "33fcff38d9d14f959d23294a73fcef48",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Qualitative reviews\n",
    "In this example we read in a set of hypothetical customer service tickets and prompt an LLM to extract a set of themes that we could use in follow-on questions (e.g., as a set of options to multiple choice questions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "b3a774c910d84625a4b11da0de00a647",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 61,
    "execution_start": 1709256071211,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from edsl.questions import QuestionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "f15821f15aff40fca1478ac54eebe644",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 41,
    "execution_start": 1709256072751,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "tickets = [\n",
    "    \"I waited for 20 minutes past the estimated arrival time, and the driver still hasn't arrived. This made me late for my appointment.\",\n",
    "    \"The driver was very rude and had an unpleasant attitude during the entire ride. It was an uncomfortable experience.\",\n",
    "    \"The driver was speeding and frequently changing lanes without signaling. I felt unsafe throughout the ride.\",\n",
    "    \"The car I rode in was dirty and messy. There were crumbs on the seats, and it didn't look like it had been cleaned in a while.\",\n",
    "    \"The driver took a longer route, which resulted in a significantly higher fare than expected. I believe they intentionally extended the trip.\",\n",
    "    \"I was charged for a ride that I did not take. The ride appears on my account, but I was not in the vehicle at that time.\",\n",
    "    \"I left my wallet in the car during my last ride. I've tried contacting the driver, but I haven't received a response.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "efbba29abc164ea3ba349699009a0017",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 104,
    "execution_start": 1709256074720,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "a_customer_service = Agent(traits = {\"background\": \"You are an experienced customer service agent for a ridesharing company.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "148a0d908a654bf6b9e7347f67ce7995",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 162,
    "execution_start": 1709256076156,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "q_topics = QuestionList(\n",
    "    question_name = \"ticket_topics\",\n",
    "    question_text = \"Create a list of the topics raised in these customer service tickets: {{tickets_texts}}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "7ffb93a3a2f444bc9c2781a9c6f88156",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 95,
    "execution_start": 1709256079048,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "scenario = Scenario({\"tickets_texts\": \"; \".join(tickets)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "68ebd83c67674752a9853082a8dbda99",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5957,
    "execution_start": 1709256080633,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "topics = q_topics.by(scenario).by(a_customer_service).by(model).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "80816b1f01864ec5990f0c7b85943c02",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 107,
    "execution_start": 1709256086595,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delayed pickup',\n",
       " 'Driver behavior',\n",
       " 'Reckless driving',\n",
       " 'Vehicle cleanliness',\n",
       " 'Route and fare issues',\n",
       " 'Incorrect charge',\n",
       " 'Lost item']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.select(\"ticket_topics\").to_list()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "49864c94106d4859833e86c5273c4ed9",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Data labeling\n",
    "In this example we prompt an LLM to rating the seriousness of tickets about safety issues.\n",
    "\n",
    "See this notebook as well for a more complex data labeling exercise: <a href=\"https://deepnote.com/workspace/expected-parrot-c2fa2435-01e3-451d-ba12-9c36b3b87ad9/project/Expected-Parrot-examples-b457490b-fc5d-45e1-82a5-a66e1738a4b9/notebook/Data%20Labeling%20Agents-ed823c7d26d6410cb357d0b81ff95d80\">Data Labeling Agents</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "bfd0c44c909e48ec9601d4895cfab1d3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 130,
    "execution_start": 1709256114849,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from edsl.questions import QuestionLinearScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "89dff3f166c54628baac1ec5a2c28428",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 54,
    "execution_start": 1709256116102,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "safety_tickets = [\n",
    "    \"During my ride, I noticed that the driver was frequently checking their phone for directions, which made me a bit uncomfortable. It didn't feel like they were fully focused on the road.\",\n",
    "    \"The driver had to brake abruptly to avoid a collision with another vehicle. It was a close call, and it left me feeling quite shaken. Please address this issue.\",\n",
    "    \"I had a ride with a driver who was clearly speeding and weaving in and out of traffic. Their reckless driving put my safety at risk, and I'm very concerned about it.\",\n",
    "    \"My ride was involved in a minor accident, and although no one was seriously injured, it was a scary experience. The driver is handling the situation, but I wanted to report it.\",\n",
    "    \"I had a ride with a driver who exhibited aggressive and threatening behavior towards me during the trip. I felt genuinely unsafe and want this matter to be taken seriously.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "de3e872a118b43718713e6d600485ee9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42,
    "execution_start": 1709256118136,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "q_rating = QuestionLinearScale(\n",
    "    question_name = \"safety_rating\",\n",
    "    question_text = \"\"\"On a scale from 0-10 rate the seriousness of the issue raised in this customer service ticket\n",
    "    (0 = Not serious, 10 = Extremely serious): {{ticket}}\"\"\",\n",
    "    question_options = [0,1,2,3,4,5,6,7,8,9,10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "db9aefc45979428890512d4566779a92",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 97,
    "execution_start": 1709256119940,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "scenarios = [Scenario({\"ticket\": safety_ticket}) for safety_ticket in safety_tickets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "415c1a347a734475a1f996ef667f7b96",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7709,
    "execution_start": 1709256121635,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "r_rating = q_rating.by(scenarios).by(a_customer_service).by(model).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "4d6ee841c57747a4984f64787c5f1822",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 200,
    "execution_start": 1709256129358,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table id=\"myTable\" class=\"display\">\n",
       "  <thead>\n",
       "  <tr>\n",
       "    <th>scenario.ticket</th>\n",
       "    <th>answer.safety_rating_comment</th>\n",
       "    <th>answer.safety_rating</th>\n",
       "  </tr>\n",
       "  </thead>\n",
       "</tbody>\n",
       "  <tr>\n",
       "    <td>I had a ride with a driver who was clearly speeding and weaving in and out of traffic. Their reckless driving put my safety at risk, and I'm very concerned about it.</td>\n",
       "    <td>Reckless driving and endangering the safety of a passenger is an extremely serious issue that requires immediate attention and action.</td>\n",
       "    <td>10</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>I had a ride with a driver who exhibited aggressive and threatening behavior towards me during the trip. I felt genuinely unsafe and want this matter to be taken seriously.</td>\n",
       "    <td>Safety is our top priority. Aggressive and threatening behavior is unacceptable and is treated with the utmost seriousness. We will investigate this immediately and take appropriate action.</td>\n",
       "    <td>10</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>The driver had to brake abruptly to avoid a collision with another vehicle. It was a close call, and it left me feeling quite shaken. Please address this issue.</td>\n",
       "    <td>Safety concerns during a ride are taken very seriously. An abrupt braking incident indicates a potential safety risk and can be quite distressing for passengers. We will investigate the circumstances of this event to ensure the safety of all our riders and take appropriate action.</td>\n",
       "    <td>8</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>During my ride, I noticed that the driver was frequently checking their phone for directions, which made me a bit uncomfortable. It didn't feel like they were fully focused on the road.</td>\n",
       "    <td>Safety is a top priority for us, and any report of a driver not fully focusing on the road is taken seriously. While using a phone for navigation is common, it should not interfere with safe driving practices. We will address this behavior with the driver to ensure it doesn't happen again.</td>\n",
       "    <td>6</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>My ride was involved in a minor accident, and although no one was seriously injured, it was a scary experience. The driver is handling the situation, but I wanted to report it.</td>\n",
       "    <td>Any accident involving a rideshare vehicle is taken very seriously due to the potential for harm to passengers and others, as well as the liability concerns for the driver and the company. Even though it was reported as a minor accident and no one was seriously injured, the experience can be traumatic for the passengers involved, and it is important that the incident is thoroughly investigated and appropriate measures are taken to prevent future occurrences.</td>\n",
       "    <td>8</td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(r_rating\n",
    " .select(\"scenario.*\", \"answer.*\")\n",
    " .print()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a1de032fb5304edaa79afcca384a7d83",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Creating new methods\n",
    "We can use the question prompts to create new methods, such as a translator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "d9c41b771dda4880b921f759b342fbdd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 111,
    "execution_start": 1709256140288,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "def translate_to_german(text):\n",
    "    q = QuestionFreeText(\n",
    "        question_name = \"deutsch\",\n",
    "        question_text = \"Please translate '{{ text }}' into German\"\n",
    "    )\n",
    "    result = q.by(Scenario({'text':text})).run()\n",
    "    return result.select(\"deutsch\").print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "f53af9c537ab4dcabb71ea7db6ce0062",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2238,
    "execution_start": 1709256142875,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table id=\"myTable\" class=\"display\">\n",
       "  <thead>\n",
       "  <tr>\n",
       "    <th>answer.deutsch</th>\n",
       "  </tr>\n",
       "  </thead>\n",
       "</tbody>\n",
       "  <tr>\n",
       "    <td>Hallo, Freund, bist du gereist?</td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate_to_german(\"Hello, friend, have you been traveling?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cdfdcae5a35443f0904d0290900179e0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "<p style=\"font-size: 14px;\">Copyright Â© 2024 Expected Parrot, Inc. All rights reserved.   <a href=\"www.expectedparrot.com\" style=\"color:#130061\">www.expectedparrot.com</a></p>"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "38963c933f704e83be11c08115641953",
  "deepnote_persisted_session": {
   "createdAt": "2024-03-01T02:04:44.197Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
