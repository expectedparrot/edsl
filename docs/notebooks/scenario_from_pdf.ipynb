{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b2d8e23-4783-4221-95af-0ef5be8c1b31",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Using PDFs in a survey\n",
    "This notebook provides sample [EDSL](https://docs.expectedparrot.com/) code demonstrating a method `from_pdf()` that imports a PDF and automatically creates `Scenario` objects for the pages to use as parameters of survey questions. This can be helpful when using EDSL to extract qualitative information from a large text efficiently. \n",
    "\n",
    "EDSL is an open-source library for simulating surveys and experiments with AI agents and large language models. Please see our [documentation page](https://docs.expectedparrot.com/) for tips and tutorials on getting started.\n",
    "\n",
    "## How it works\n",
    "EDSL comes with a [variety of question types](https://docs.expectedparrot.com/en/latest/questions.html) that we can select from based on the desired form of the response (multiple choice, free text, etc.). We can also parameterize questions with textual content in order to ask questions about it. We do this by creating a `{{ placeholder }}` in a question text, e.g., *What are the key themes of this text: {{ text }}*, and then creating `Scenario` objects for the content to be inserted in the placeholder when we run the survey. This allows us to administer multiple versions of a question with different inputs all at once. A common use case for this is performing [data labeling tasks](https://docs.expectedparrot.com/en/latest/notebooks/data_labeling_example.html) designed as questions about one or more pieces of textual data that can be inserted into the survey question texts. [Learn more about using scenarios](https://docs.expectedparrot.com/en/latest/scenarios.html).\n",
    "\n",
    "## Example\n",
    "For purposes of demonstration we use a PDF copy of the first page of the recent paper [Automated Social Science:\n",
    "Language Models as Scientist and Subjects](https://arxiv.org/pdf/2404.11794) and conduct a survey consisting of several questions about the contents of it:\n",
    "\n",
    "<img src=\"automated_social_science_paper.png\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed3a0e-82e0-484b-b422-cb52d23e5d5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Posting a PDF to Coop using the `FileStore` module:\n",
    "\n",
    "    from edsl import FileStore\n",
    "    \n",
    "    ass_pdf = FileStore(\"automated_social_scientist.pdf\")\n",
    "    ass_pdf.push(\n",
    "        description = \"Automated Social Scientist paper\",\n",
    "        alias = \"automated-social-scientist\",\n",
    "        visibility = \"public\"\n",
    "    )\n",
    "\n",
    "Info about the object we can use to retrieve it:\n",
    "\n",
    "    {'description': 'Automated Social Scientist paper',\n",
    "     'object_type': 'scenario',\n",
    "     'url': 'https://www.expectedparrot.com/content/eccca1bf-1703-4b35-8fe1-b30390eb7786',\n",
    "     'uuid': 'eccca1bf-1703-4b35-8fe1-b30390eb7786',\n",
    "     'version': '0.1.47.dev1',\n",
    "     'visibility': 'public'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca387cf-719c-4c59-a98b-34cea74c3985",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now that we have stored it at the Coop we can retrieve it (this step can be run with the UUID for any Coop object that you want to import):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592d7ac0-60c3-4761-a6ce-036efe0177b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from edsl import FileStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba31188d-d5fa-4a25-99c1-177fe973f46d",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "ass_pdf = FileStore.pull('eccca1bf-1703-4b35-8fe1-b30390eb7786')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ec739-f288-4861-9639-6b2748b38bb3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Next we create a `ScenarioList` for the pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "473e065a-6dd7-4fe5-8fef-1c45a7fff305",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><a href='https://docs.expectedparrot.com/en/latest/scenarios.html#scenariolist'>ScenarioList</a> scenarios: 63; keys: ['page', 'filename', 'text'];</p>\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_e7c34_row0_col0, #T_e7c34_row0_col2, #T_e7c34_row1_col0, #T_e7c34_row1_col2, #T_e7c34_row2_col0, #T_e7c34_row2_col2, #T_e7c34_row3_col0, #T_e7c34_row3_col2, #T_e7c34_row4_col0, #T_e7c34_row4_col2, #T_e7c34_row5_col0, #T_e7c34_row5_col2, #T_e7c34_row6_col0, #T_e7c34_row6_col2, #T_e7c34_row7_col0, #T_e7c34_row7_col2, #T_e7c34_row8_col0, #T_e7c34_row8_col2, #T_e7c34_row9_col0, #T_e7c34_row9_col2, #T_e7c34_row10_col0, #T_e7c34_row10_col2, #T_e7c34_row11_col0, #T_e7c34_row11_col2, #T_e7c34_row12_col0, #T_e7c34_row12_col2, #T_e7c34_row13_col0, #T_e7c34_row13_col2, #T_e7c34_row14_col0, #T_e7c34_row14_col2, #T_e7c34_row15_col0, #T_e7c34_row15_col2, #T_e7c34_row16_col0, #T_e7c34_row16_col2, #T_e7c34_row17_col0, #T_e7c34_row17_col2, #T_e7c34_row18_col0, #T_e7c34_row18_col2, #T_e7c34_row19_col0, #T_e7c34_row19_col2, #T_e7c34_row20_col0, #T_e7c34_row20_col2, #T_e7c34_row21_col0, #T_e7c34_row21_col2, #T_e7c34_row22_col0, #T_e7c34_row22_col2, #T_e7c34_row23_col0, #T_e7c34_row23_col2, #T_e7c34_row24_col0, #T_e7c34_row24_col2, #T_e7c34_row25_col0, #T_e7c34_row25_col2, #T_e7c34_row26_col0, #T_e7c34_row26_col2, #T_e7c34_row27_col0, #T_e7c34_row27_col2, #T_e7c34_row28_col0, #T_e7c34_row28_col2, #T_e7c34_row29_col0, #T_e7c34_row29_col2, #T_e7c34_row30_col0, #T_e7c34_row30_col2, #T_e7c34_row31_col0, #T_e7c34_row31_col2, #T_e7c34_row32_col0, #T_e7c34_row32_col2, #T_e7c34_row33_col0, #T_e7c34_row33_col2, #T_e7c34_row34_col0, #T_e7c34_row34_col2, #T_e7c34_row35_col0, #T_e7c34_row35_col2, #T_e7c34_row36_col0, #T_e7c34_row36_col2, #T_e7c34_row37_col0, #T_e7c34_row37_col2, #T_e7c34_row38_col0, #T_e7c34_row38_col2, #T_e7c34_row39_col0, #T_e7c34_row39_col2, #T_e7c34_row40_col0, #T_e7c34_row40_col2, #T_e7c34_row41_col0, #T_e7c34_row41_col2, #T_e7c34_row42_col0, #T_e7c34_row42_col2, #T_e7c34_row43_col0, #T_e7c34_row43_col2, #T_e7c34_row44_col0, #T_e7c34_row44_col2, #T_e7c34_row45_col0, #T_e7c34_row45_col2, #T_e7c34_row46_col0, #T_e7c34_row46_col2, #T_e7c34_row47_col0, #T_e7c34_row47_col2, #T_e7c34_row48_col0, #T_e7c34_row48_col2, #T_e7c34_row49_col0, #T_e7c34_row49_col2, #T_e7c34_row50_col0, #T_e7c34_row50_col2, #T_e7c34_row51_col0, #T_e7c34_row51_col2, #T_e7c34_row52_col0, #T_e7c34_row52_col2, #T_e7c34_row53_col0, #T_e7c34_row53_col2, #T_e7c34_row54_col0, #T_e7c34_row54_col2, #T_e7c34_row55_col0, #T_e7c34_row55_col2, #T_e7c34_row56_col0, #T_e7c34_row56_col2, #T_e7c34_row57_col0, #T_e7c34_row57_col2, #T_e7c34_row58_col0, #T_e7c34_row58_col2, #T_e7c34_row59_col0, #T_e7c34_row59_col2, #T_e7c34_row60_col0, #T_e7c34_row60_col2, #T_e7c34_row61_col0, #T_e7c34_row61_col2, #T_e7c34_row62_col0, #T_e7c34_row62_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e7c34_row0_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row1_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row2_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #faf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row3_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row4_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #f5eff6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row5_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #f3edf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row6_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #f1ebf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row7_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #eee9f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row8_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #ebe6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row9_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #e7e3f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row10_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #e4e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row11_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #e0deed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row12_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #dddbec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row13_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #d9d8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row14_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #d6d6e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row15_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #d2d3e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row16_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd0e5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row17_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #c8cde4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row18_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #c2cbe2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row19_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #bdc8e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row20_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #b8c6e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row21_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #b3c3de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row22_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #adc1dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row23_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #a8bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row24_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #a1bbda;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row25_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #9ab8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row26_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6d7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row27_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #8eb3d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row28_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #88b1d4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e7c34_row29_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #81aed2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row30_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #7bacd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row31_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #73a9cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row32_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #6ba5cd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row33_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #63a2cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row34_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #5c9fc9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row35_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #549cc7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row36_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #4c99c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row37_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #4496c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row38_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #3d93c2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row39_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #348ebf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row40_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #2d8abd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row41_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #2786bb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row42_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #2182b9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row43_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #1b7eb7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row44_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #157ab5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row45_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #0f76b3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row46_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #0872b1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row47_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #056ead;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row48_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #056ba9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row49_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #0569a4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row50_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #0566a0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row51_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #04639b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row52_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #046097;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row53_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #045e93;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row54_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #045b8e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row55_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #045687;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row56_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #045280;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row57_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #034d79;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row58_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #034973;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row59_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #03456c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row60_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #034165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row61_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #023c5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e7c34_row62_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e7c34\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e7c34_level0_col0\" class=\"col_heading level0 col0\" >filename</th>\n",
       "      <th id=\"T_e7c34_level0_col1\" class=\"col_heading level0 col1\" >page</th>\n",
       "      <th id=\"T_e7c34_level0_col2\" class=\"col_heading level0 col2\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e7c34_row0_col0\" class=\"data row0 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_e7c34_row0_col2\" class=\"data row0 col2\" >Automated Social Science:\n",
       "Language Models as Scientist and Subjects∗\n",
       "Benjamin S. Manning†\n",
       "MIT\n",
       "Kehang Zhu†\n",
       "Harvard\n",
       "John J. Horton\n",
       "MIT & NBER\n",
       "April 26, 2024\n",
       "Abstract\n",
       "We present an approach for automatically generating and testing, in silico,\n",
       "social scientific hypotheses. This automation is made possible by recent ad-\n",
       "vances in large language models (LLM), but the key feature of the approach\n",
       "is the use of structural causal models. Structural causal models provide a lan-\n",
       "guage to state hypotheses, a blueprint for constructing LLM-based agents, an\n",
       "experimental design, and a plan for data analysis. The fitted structural causal\n",
       "model becomes an object available for prediction or the planning of follow-on\n",
       "experiments. We demonstrate the approach with several scenarios: a nego-\n",
       "tiation, a bail hearing, a job interview, and an auction. In each case, causal\n",
       "relationships are both proposed and tested by the system, finding evidence\n",
       "for some and not others. We provide evidence that the insights from these\n",
       "simulations of social interactions are not available to the LLM purely through\n",
       "direct elicitation. When given its proposed structural causal model for each\n",
       "scenario, the LLM is good at predicting the signs of estimated effects, but\n",
       "it cannot reliably predict the magnitudes of those estimates. In the auction\n",
       "experiment, the in silico simulation results closely match the predictions of\n",
       "auction theory, but elicited predictions of the clearing prices from the LLM\n",
       "are inaccurate. However, the LLM’s predictions are dramatically improved if\n",
       "the model can condition on the fitted structural causal model. In short, the\n",
       "LLM knows more than it can (immediately) tell.\n",
       "∗Thanks to generous support from Drew Houston and his AI for Augmentation and Productivity\n",
       "seed grant. Thanks to Jordan Ellenberg, Benjamin Lira Luttges, David Holtz, Bruce Sacerdote,\n",
       "Paul R¨ottger, Mohammed Alsobay, Ray Duch, Matt Schwartz, David Autor, and Dean Eckles\n",
       "for their helpful feedback. Author’s contact information, code, and data are currently or will be\n",
       "available at http://www.benjaminmanning.io/.\n",
       "†Both authors contributed equally to this work.\n",
       "1\n",
       "arXiv:2404.11794v2  [econ.GN]  25 Apr 2024\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e7c34_row1_col0\" class=\"data row1 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_e7c34_row1_col2\" class=\"data row1 col2\" >1\n",
       "Introduction\n",
       "There is much work on efficiently estimating econometric models of human behavior\n",
       "but comparatively little work on efficiently generating and testing those models to\n",
       "estimate. Previously, developing such models and hypotheses to test was exclusively\n",
       "a human task. This is changing as researchers have begun to explore automated\n",
       "hypothesis generation through the use of machine learning.1 But even with novel\n",
       "machine-generated hypotheses, there is still the problem of testing.\n",
       "A potential\n",
       "solution is simulation. Researchers have shown that Large Language Models (LLM)\n",
       "can simulate humans as experimental subjects with surprising degrees of realism.2\n",
       "To the extent that these simulation results carry over to human subjects in out-of-\n",
       "sample tasks, they provide another option for testing (Horton, 2023). In this paper,\n",
       "we combine these ideas—automated hypothesis generation and automated in silico\n",
       "hypothesis testing—by using LLMs for both purposes. We demonstrate that such\n",
       "automation is possible. We evaluate the approach by comparing results to a setting\n",
       "where the real-world predictions are well known and test to see if an LLM can be\n",
       "used to generate information that it cannot access through direct elicitation.\n",
       "The key innovation in our approach is the use of structural causal models to orga-\n",
       "nize the research process. Structural causal models are mathematical representations\n",
       "of cause and effect (Pearl, 2009b; Wright, 1934) and have long offered a language\n",
       "for expressing hypotheses.3 What is novel in our paper is the use of these models\n",
       "as a blueprint for the design of agents and experiments. In short, each explanatory\n",
       "variable describes something about a person or scenario that has to vary for the effect\n",
       "to be identified, so the system “knows” it needs to generate agents or scenarios that\n",
       "1A few examples include generative adversarial networks to formulate new hypotheses (Ludwig\n",
       "and Mullainathan, 2023), algorithms to find anomalies in formal theories (Mullainathan and Ram-\n",
       "bachan, 2023), reinforcement learning to propose tax policies (Zheng et al., 2022), random forests\n",
       "to identify heterogenous treatment effects (Wager and Athey, 2018), and several others (Buyalskaya\n",
       "et al., 2023; Cai et al., 2023; Enke and Shubatt, 2023; Girotra et al., 2023; Peterson et al., 2021).\n",
       "2(Aher et al., 2023; Argyle et al., 2023; Bakker et al., 2022; Binz and Schulz, 2023b; Brand et\n",
       "al., 2023; Bubeck et al., 2023; Fish et al., 2023; Mei et al., 2024; Park et al., 2023)\n",
       "3In an unfortunate clash of naming conventions, some disciplines have alternative definitions\n",
       "for the term “structural” when discussing formal models. Here, structural does not refer to the\n",
       "definition traditionally used in economics. See Appendix B for a more detailed explanation.\n",
       "2\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e7c34_row2_col0\" class=\"data row2 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row2_col1\" class=\"data row2 col1\" >3</td>\n",
       "      <td id=\"T_e7c34_row2_col2\" class=\"data row2 col2\" >vary on that dimension—a straightforward transition from stated theory to experi-\n",
       "mental design and data generation. Furthermore, the structural causal model offers\n",
       "a pre-specified plan for estimation (Haavelmo, 1943, 1944; J¨oreskog, 1970).\n",
       "We built an open-source computational system implementing this structural causal\n",
       "model-based approach. The system can automatically generate hypotheses, design\n",
       "experiments, run those experiments on independent LLM-powered agents, and ana-\n",
       "lyze the results. We use this system to explore several social scenarios: (1) two people\n",
       "bargaining over a mug, (2) a bail hearing for tax fraud, (3) a lawyer interviewing\n",
       "for a job, and (4) an open ascending price auction with private values for a piece\n",
       "of art. We allow the system to propose the hypotheses for the first two scenarios\n",
       "and then run the experimental simulations without intervention. For (3) and (4),\n",
       "we demonstrate the system’s ability to accommodate human input at any point by\n",
       "selecting the hypotheses ourselves and editing some of the agents, but otherwise, we\n",
       "allow the system to proceed autonomously.\n",
       "Though yet to be optimized for novelty, the system formulates and tests multiple\n",
       "falsifiable hypotheses—from which it generates several findings. The probability of\n",
       "a deal increased as the seller’s sentimental attachment to the mug decreased, and\n",
       "both the buyer’s and the seller’s reservation prices mattered. A remorseful defendant\n",
       "was granted lower bail but was not so fortunate if his criminal history was exten-\n",
       "sive. However, the judge’s case count before the hearing—which was hypothesized\n",
       "to matter—did not affect the final bail amount. The candidate passing the bar exam\n",
       "was the only important factor in her getting the job. Neither the candidate’s height\n",
       "nor the interviewer’s friendliness affected the outcome.\n",
       "The auction scenario is particularly illuminating. An increase in the bidders’\n",
       "reservation prices caused an increase in the clearing price, a clearing price that is\n",
       "always close to the second-highest reservation amongst the bidders. These simula-\n",
       "tion results closely match the theory (Maskin and Riley, 1985) and what has been\n",
       "observed empirically (Athey et al., 2011).\n",
       "None of the findings from the system’s experiments are “counterintuitive,” but\n",
       "it is important to emphasize they were the result of empiricism, not just model\n",
       "introspection.\n",
       "However, this does raise the question of whether the simulations\n",
       "3\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e7c34_row3_col0\" class=\"data row3 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row3_col1\" class=\"data row3 col1\" >4</td>\n",
       "      <td id=\"T_e7c34_row3_col2\" class=\"data row3 col2\" >are even necessary.4\n",
       "Instead of simulation, could an LLM simply do a “thought\n",
       "experiment” about the proposed in silico experiment and achieve the same insight?\n",
       "To test this idea, we describe the experiments that will be simulated and ask the\n",
       "LLM to predict the results—both the path estimates and point predictions. The\n",
       "path estimates being the coefficients in the linear structural causal model. To make\n",
       "this concrete, suppose we had the simple linear model y = Xβ to describe some\n",
       "scenario, and we ran an experiment to estimate ˆβ. We describe the scenario and the\n",
       "experiment to the LLM and ask it to predict yi given a particular Xi (a “predict-yi”\n",
       "task). Separately, we ask it to predict ˆβ (a “predict-ˆβ” task). Later, we examine\n",
       "how the LLM does on the predict-yi task when it has access to the fitted structural\n",
       "causal model (i.e., ˆβ).\n",
       "In the predict-yi task, we prompt the LLM to predict the outcome yi given each\n",
       "possible combination of the Xi’s from the auction experiment. Direct elicitation of\n",
       "the predictions for yi in the auction experiment is wildly inaccurate. The predictions\n",
       "are even further from the theory than the empirical results.\n",
       "In the predict-ˆβ task, the LLM is asked to predict the fitted structural causal\n",
       "model’s path estimates for all four experiments, provided with contextual information\n",
       "about each scenario. On average, the LLM predicts the path estimates are 13.2 times\n",
       "larger than the experimental results. Its predictions are overestimates for 10 out of\n",
       "12 of the paths, although they are generally in the correct direction.\n",
       "We repeat the predict-yi task, but this time, we provide the LLM with the ex-\n",
       "perimental path estimates. For each Xi, we fit the structural causal model using\n",
       "all but the ith observation and then ask the LLM to predict yi given Xi and this\n",
       "fitted model. In this “predict-yi|ˆβ−i” task, the predictions are far better than in the\n",
       "predict-yi task without the fitted model. The mean squared error is six times lower,\n",
       "and the predictions are much closer to those made by the theory, but they are still\n",
       "further from the theory than they are to the simulations.\n",
       "We design and implement an approach to automated social science because LLMs\n",
       "possess latent information about human behavior that can be systematically explored\n",
       "and extracted (Burns et al., 2023; Scherrer et al., 2024). These models are trained to\n",
       "4Performing these experiments required a substantial software infrastructure.\n",
       "4\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e7c34_row4_col0\" class=\"data row4 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row4_col1\" class=\"data row4 col1\" >5</td>\n",
       "      <td id=\"T_e7c34_row4_col2\" class=\"data row4 col2\" >predict the next token in a sequence of text from a massive human-generated corpus.\n",
       "From this straightforward objective, the models develop a remarkably sophisticated\n",
       "model of the world, at least as captured in text (Bubeck et al., 2023; Gurnee and\n",
       "Tegmark, 2023; Patel and Pavlick, 2021). And while there are many situations where\n",
       "LLMs are imperfect proxies for humans (Cheng et al., 2023; Santurkar et al., 2023),\n",
       "there is also a growing body of work demonstrating that experiments with LLMs as\n",
       "subjects can predict human behavior in never-before-seen tasks (Binz and Schulz,\n",
       "2023a; Li et al., 2024). Rapid and automated exploration of these models’ behavior\n",
       "could be a powerful tool to efficiently generate new insights about humans. Our\n",
       "contribution is to demonstrate that it is possible to create such a tool: a system that\n",
       "can simulate the entire social scientific process without human input at any step.\n",
       "The remainder of this paper is structured as follows: Section 2 provides an\n",
       "overview of the system. Section 3 provides some results generated using our system.\n",
       "Section 4 explores an LLM’s capacity to predict the results in Section 3. Section\n",
       "5 discusses the advantages of using SCMs over other methods for studying causal\n",
       "relationships in simulations of social interactions. The paper concludes in Section 6.\n",
       "2\n",
       "Overview of the system\n",
       "To perform this automated social science, we needed to build a system. The system\n",
       "intentionally mirrors the experimental social scientific process. These steps are, in\n",
       "broad strokes:\n",
       "1. Social scientists start by selecting a topic or domain to study (e.g., misinfor-\n",
       "mation, auctions, bargaining, etc).\n",
       "2. Within the domain, they identify interesting outcomes and some causes that\n",
       "might affect the outcomes. These variables and their proposed relationships\n",
       "are the hypotheses.\n",
       "3. They design an experiment to test these hypotheses by inducing variation in\n",
       "the causes and measuring the outcomes.\n",
       "5\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e7c34_row5_col0\" class=\"data row5 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row5_col1\" class=\"data row5 col1\" >6</td>\n",
       "      <td id=\"T_e7c34_row5_col2\" class=\"data row5 col2\" >4. After designing the experiment, social scientists determine how they will ana-\n",
       "lyze the data in a pre-analysis plan.\n",
       "5. Next, they recruit participants, run the experiment, and collect the data.\n",
       "6. Finally, they analyze the data per the pre-analysis plan to estimate the rela-\n",
       "tionships between the proposed causes and outcomes.\n",
       "While any given social scientist might not follow this sequence exactly, whatever\n",
       "their approach may be, the first two steps should always guide the later steps—the\n",
       "development of the hypothesis guides the experimental design and model estimation.\n",
       "Of course, many social scientists must often omit steps 3-5 when a controlled exper-\n",
       "iment is not possible, but they typically have some notion of the experiment they\n",
       "would like to run.\n",
       "To build our system, we formalized a sequence of these steps analogous to those\n",
       "listed above. The system executes them autonomously. Since the system uses AI\n",
       "agents instead of human subjects, it can always design and execute an experiment.\n",
       "Structural causal models (SCM) are essential to the design of the system because\n",
       "they make unambiguous causal statements, which allow for unambiguous estimation\n",
       "and experimental design.5 Algorithms can determine precisely which variables must\n",
       "be exogenously manipulated to identify the effect of a given cause (Pearl, 2009b). If\n",
       "the first two steps in the social scientific process are building the SCM, the last four\n",
       "can be directly determined subject to the SCM. Such precision makes automation\n",
       "possible as the system only relies on a few key early decisions. Otherwise, the space\n",
       "of possible choices for the latter steps would explode, making automation infeasible.\n",
       "The system is implemented in Python and uses GPT-4 for all LLM queries.\n",
       "Its decisions are editable at every step.\n",
       "The overview in this section is a high-\n",
       "level description of the system, but there are many more specific design choices and\n",
       "programming details in Appendix A. For the purposes of most readers, the high-\n",
       "5We use simple linear SCMs unless stated otherwise. This assumption is not necessarily correct\n",
       "but offers an unequivocal starting point to generate hypotheses. Functional assumptions can be\n",
       "tested by comparing fitted SCMs with various forms using data generated from a known causal\n",
       "structure. Section B in the appendix provides a more detailed explanation of SCMs.\n",
       "6\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e7c34_row6_col0\" class=\"data row6 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row6_col1\" class=\"data row6 col1\" >7</td>\n",
       "      <td id=\"T_e7c34_row6_col2\" class=\"data row6 col2\" >level overview should be sufficient to understand the system’s process, the results we\n",
       "present in Section 3, and the additional analyses in Sections 4 and 5.\n",
       "The system takes as input some scenario of social scientific interest: a negotia-\n",
       "tion, a bail decision, a job interview, an auction, and so on. Starting with (1) this\n",
       "input, the system (2) generates outcomes of interest and their potential causes, (3)\n",
       "creates agents that vary on the exogenous dimensions of said causes, (4) designs an\n",
       "experiment, (5) executes the experiment with LLM-powered agents simulating hu-\n",
       "mans, (6) surveys the agents to measure the outcomes, (7) analyzes the results of\n",
       "the experiment to assess the hypotheses, which can be used to plan a follow-on ex-\n",
       "periment. Figure 1 illustrates these steps, and we will briefly explore each in greater\n",
       "depth.\n",
       "Figure 1: An overview of the automated system.\n",
       "Notes: Each step in the process corresponds to an analogous step in the social scientific process as\n",
       "done by humans. The development of the hypothesis guides the experimental design, execution, and\n",
       "model estimation. Researchers can edit the system’s decisions at any step in the process.\n",
       "The first step is to generate hypotheses as SCMs based on the social scenario, the\n",
       "scenario being the only necessary input to the system. This is done by querying an\n",
       "7\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e7c34_row7_col0\" class=\"data row7 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row7_col1\" class=\"data row7 col1\" >8</td>\n",
       "      <td id=\"T_e7c34_row7_col2\" class=\"data row7 col2\" >LLM for the relevant agents and then interesting outcomes, their potential causes,\n",
       "and methods to operationalize and measure both.6\n",
       "We use Typewriter text to\n",
       "indicate example output from the system. Suppose the social scenario is “two people\n",
       "bargaining over a mug.” The LLM may generate whether a deal occurs for the\n",
       "mug as an outcome, and operationalizes the outcome as a binary variable with\n",
       "a ‘‘1’’ when a deal occurs and a ‘‘0’’ when it does not.\n",
       "It then gener-\n",
       "ates potential exogenous causes and their operationalizations: the buyer’s budget,\n",
       "which is operationalized as the buyer’s willingness to pay in dollars. The\n",
       "system takes each of these variables, constructs an SCM (see the second step in Fig-\n",
       "ure 1), and stores the relevant information about the operationalizations associated\n",
       "with each variable.78 From this point on, the SCM serves as a blueprint for the rest\n",
       "of the process, namely the automatic instantiation of agents, their interaction, and\n",
       "the estimation of the linear paths.\n",
       "The second step is to construct the relevant agents—the Buyer and the Seller\n",
       "in Figure 1, step 3. By “construct,” we mean that the system prompts indepen-\n",
       "dent LLMs to be people with sets of attributes. These attributes are the exogenous\n",
       "dimensions of the SCM, dimensions that are varied in each simulation. I.e., the dif-\n",
       "ferent experimental conditions. For the current scenario, a Budget is provided to the\n",
       "buyer that can take on values of {$5, $10, $20, $40}. By simulating interactions\n",
       "of agents that vary on the exogenous dimensions of the SCM, the data generated can\n",
       "be used to fit the SCM.\n",
       "Next, the system generates survey questions to gather data about the outcomes\n",
       "6When we say “query an LLM,” we mean this literally. We have written a prompt that the\n",
       "system provides to an LLM with the scenario.\n",
       "For example, the prompt used to generate the\n",
       "relevant agents is: In the following scenario: “{scenario}”, who are the individual human agents in\n",
       "a simple simulation of this scenario? Where “{scenario}” is replaced with the scenario of interest.\n",
       "The LLM then returns a list of agents, which are stored in the system and can be used in follow-on\n",
       "prompts, prompts that generate things like the outcomes and proposed causes. The system contains\n",
       "over 50 pre-written scenario-neutral prompts to gather all the information needed to generate the\n",
       "SCM, run the experiment, and analyze the results.\n",
       "7The system generates several other pieces of information about each variable, which help guide\n",
       "the experimental design and data analysis. See Appendix A for further details.\n",
       "8The graph in the second step of Figure 1 is a directed acyclic graph (DAG). For convenience,\n",
       "we will use DAGs to represent SCMs throughout the paper and assume they imply a simple linear\n",
       "model unless stated otherwise.\n",
       "8\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e7c34_row8_col0\" class=\"data row8 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row8_col1\" class=\"data row8 col1\" >9</td>\n",
       "      <td id=\"T_e7c34_row8_col2\" class=\"data row8 col2\" >from the agents automatically once each simulation is complete. An LLM can easily\n",
       "generate these questions when provided with information about the variables in the\n",
       "SCM (e.g., asking the buyer, “Did a deal happen?”). All LLM-powered agents in\n",
       "our system have “memory.” They store what happened during the simulation in\n",
       "text, making it easy to ask them questions about what happened.\n",
       "Fourth, the system determines how the agents should interact. LLMs are designed\n",
       "to generate text in sequence. Since independent LLMs power each agent, one agent\n",
       "must finish speaking before the next begins. This necessitates a turn-taking protocol\n",
       "to simulate the conversation. We programmed a menu of six ordering protocols,\n",
       "from which an LLM is queried to select the most appropriate for a given scenario.\n",
       "We describe each protocol in Appendix A, and they are presented in Figure A.2,\n",
       "but in our bargaining scenario with two agents, there are only two possible ways for\n",
       "the agents to alternate speaking. In this case, the system selects: speaking order:\n",
       "(1) Buyer, (2) Seller, (step 4, Figure 1). The speaking order can be flexible in\n",
       "more complex simulations with more agents, such as an auction or a bail hearing.\n",
       "Now, the system runs the experiment. The conditions are simulated in parallel\n",
       "(step 5 in Figure 1), each with a different value for the exogenous dimensions of the\n",
       "SCM—the possible budgets for the buyer.\n",
       "The system must also determine when to stop the simulations. There is no obvious\n",
       "rule for when a conversation should end.\n",
       "Like the halting problem in computer\n",
       "science—it is impossible to write a universal algorithm that can determine whether\n",
       "a given program will complete (Turing, 1937)—such a rule for conversations does\n",
       "not exist. We set two stopping conditions for the simulations. After each agent\n",
       "speaks in a simulation, an external LLM is prompted with the transcript of the\n",
       "conversation and asked if the conversation should continue. If yes, the next agent\n",
       "speaks; otherwise, the simulation ends. Additionally, we limit the total number of\n",
       "agent statements to twenty. One could imagine doing something more sophisticated\n",
       "both with the social interactions and the stopping conditions in the future. This\n",
       "is even a place for possible experimentation as the structure of social interactions\n",
       "can impact various outcomes of interest (Jahani et al., 2023; Rajkumar et al., 2022;\n",
       "Sacerdote, 2001).\n",
       "9\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e7c34_row9_col0\" class=\"data row9 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row9_col1\" class=\"data row9 col1\" >10</td>\n",
       "      <td id=\"T_e7c34_row9_col2\" class=\"data row9 col2\" >Finally, the system gathers the data for analysis. Outcomes are measured by\n",
       "asking the agents the survey questions (Figure 1, step 6) as determined before the\n",
       "experiment. The data is then used to estimate the linear SCM. For our negotiation,\n",
       "that would be a simple linear model with a single path estimate (i.e., linear coef-\n",
       "ficient) for the effect of the buyer’s budget on the probability of a deal—the final\n",
       "step in Figure 1. Note that an SCM specifies, ex-ante, the exact statistical analyses\n",
       "to be conducted after the experiment—akin to a pre-analysis plan. This step of the\n",
       "system’s process is, therefore, mechanical.\n",
       "The system, as outlined, is automated from start to finish—the SCM and its\n",
       "accompanying metadata serve as a blueprint for the rest of the process. Once there\n",
       "is a fitted SCM, this process can be repeated. Although we have not automated\n",
       "the transition from one experiment to the next, the system can generate new causal\n",
       "variables, induce variations, and run another experiment based on the results of the\n",
       "first.\n",
       "3\n",
       "Results of experiments\n",
       "We present results for four social scenarios explored using the system. In the first two\n",
       "scenarios, our involvement in the system’s process was restricted to entering the de-\n",
       "scription of the scenario and then the entire process was automated. In the third and\n",
       "fourth scenarios, we selected the hypotheses and edited some of the agents, but the\n",
       "system designed and executed the experiments. We intervened in the latter scenarios\n",
       "not because the system is incapable of simulating these scenarios autonomously, but\n",
       "to demonstrate the system’s capacity to accommodate human input at any point\n",
       "while still generating exciting results.\n",
       "3.1\n",
       "Bargaining over a mug\n",
       "We first use the system to simulate “two people bargaining over a mug”—this phrase\n",
       "being in quotes because it was the only input needed for the system to simulate the\n",
       "following process. The system selected a buyer and seller as the relevant agents,\n",
       "10\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_e7c34_row10_col0\" class=\"data row10 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row10_col1\" class=\"data row10 col1\" >11</td>\n",
       "      <td id=\"T_e7c34_row10_col2\" class=\"data row10 col2\" >the outcome as whether a deal occurs, and the buyer’s budget, the seller’s mini-\n",
       "mum acceptable price, and the seller’s emotional attachment to the mug as potential\n",
       "causes.\n",
       "Table 2a provides the information generated by the system about the SCM and\n",
       "the experimental design. The topmost row, simulation details, provides high-level\n",
       "information about the structure of the simulation.\n",
       "The remaining rows provide\n",
       "information about the variables in the SCM and how they were operationalized. The\n",
       "system automatically generated all this information by iteratively querying the LLM.\n",
       "The three exogenous variables were operationalized as the buyer’s budget in dol-\n",
       "lars, the seller’s minimum acceptable price in dollars, and the seller’s emotional\n",
       "attachment as an ordinal scale from “no emotional attachment” to “extreme emo-\n",
       "tional attachment.” The system chose nine values (the “Attribute Treatments” in\n",
       "Table 2a) to vary for each of the first two causes and five for the seller’s feelings of\n",
       "love towards the mug (one for each level of the scale). This led to 9 × 9 × 5 = 405\n",
       "experimental runs of the simulated conversation between the buyer and seller.\n",
       "Figure 2b provides the fitted SCM. The outcome variable is given with its mean\n",
       "and variance. The raw path estimates and their standard errors are shown on the\n",
       "arrows. For ordinal variables (e.g., the seller’s feelings of love), we treat the levels as\n",
       "numerical values. The buyer and seller reached a deal for the mug in half of the sim-\n",
       "ulations, and all three causes had a statistically significant effect on the probability\n",
       "of a deal.\n",
       "A one-dollar increase in the buyer’s budget caused an average increase of 3.7\n",
       "percentage points in the probability of a deal (ˆβ* = 0.51, p < 0.001).9 A one-dollar\n",
       "increase in the seller’s minimum acceptable price caused an average decrease of 3.5\n",
       "percentage points in the probability of a deal occurring (ˆβ* = −0.49, p < 0.001).\n",
       "Finally, a one-unit increase in the ordinal scale of the seller’s love for the mug, such\n",
       "as going from moderate emotional attachment to high emotional attachment, caused\n",
       "an average decrease of 2.5 percentage points in the probability of a deal (ˆβ* = −0.07,\n",
       "p = 0.044).\n",
       "9We report standardized effect size estimates with ˆβ*. Standardized effect sizes being “a one\n",
       "standard deviation increase in X causes a ˆβ* standard deviation increase in Y.”\n",
       "11\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_e7c34_row11_col0\" class=\"data row11 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row11_col1\" class=\"data row11 col1\" >12</td>\n",
       "      <td id=\"T_e7c34_row11_col2\" class=\"data row11 col2\" >Figure 2: Experimental design and fitted SCM for “two people bargaining over a\n",
       "mug.”\n",
       "SIMULATION DETAILS\n",
       "Agents: Buyer, Seller\n",
       "Simulations Run: 9 × 9 × 5 = 405\n",
       "Speaking Order: Buyer, Seller, Buyer, ...repeat\n",
       "VARIABLE INFORMATION\n",
       "Whether or not a deal occurs\n",
       "Measurement\n",
       "Question:\n",
       "coordinator:\n",
       "“Did the\n",
       "buyer and seller explicitly agree on the price of the mug\n",
       "during their interaction?”\n",
       "Variable Type: Binary\n",
       "Buyer’s Budget\n",
       "Attribute Treatments: [‘3’, ‘6’, ‘7’, ‘8’, ‘10’, ‘13’,\n",
       "‘18’, ‘20’, ‘25’]\n",
       "Proxy Attribute: Your budget for the mug\n",
       "Variable Type: Continuous\n",
       "Seller’s minimum acceptable price\n",
       "Attribute Treatments: [‘3’, ‘5’, ‘7’, ‘8’, ‘10’, ‘13’,\n",
       "‘18’, ‘20’, ‘25’]\n",
       "Proxy Attribute: Your minimum acceptable price for\n",
       "the mug\n",
       "Variable Type: Continuous\n",
       "Seller’s feelings of love towards the mug\n",
       "Attribute Treatments: [‘no emotional attachment’,\n",
       "‘slight emotional attachment’, ‘moderate emotional at-\n",
       "tachment’, ‘high emotional attachment’, ‘extreme emo-\n",
       "tional attachment’]\n",
       "Proxy Attribute: Your feelings of love for the mug\n",
       "Variable Type: Ordinal\n",
       "(a) Information for experimental design\n",
       "Deal\n",
       "Occurs\n",
       "µ = 0.5\n",
       "σ2 = 0.25\n",
       "Buyer\n",
       "Budget\n",
       "Seller Min\n",
       "Seller Love\n",
       "0.037\n",
       "(0.003)\n",
       "-0.035\n",
       "(0.002)\n",
       "-0.025\n",
       "(0.012)\n",
       "(b) Fitted SCM\n",
       "Notes: Figure 2a provides the information automatically generated by the system to execute the\n",
       "experiment for its proposed hypothesis. This includes the high level structure of the simulations,\n",
       "how the outcome is measured, and the treatment variations for each of the causes. The fitted SCM\n",
       "in Figure 2b shows the results of the experiment. The outcome is given with its mean and variance.\n",
       "The edges are labeled with their unstandardized path estimate and standard error. We assume a\n",
       "simple linear model for the SCM, such that the above graph can also be written as DealOccurs =\n",
       "0.037BuyerBudget −0.035MinPrice −0.025SellerLove.\n",
       "12\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_e7c34_row12_col0\" class=\"data row12 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row12_col1\" class=\"data row12 col1\" >13</td>\n",
       "      <td id=\"T_e7c34_row12_col2\" class=\"data row12 col2\" >3.2\n",
       "A bail hearing\n",
       "Next, we explore “a judge is setting bail for a criminal defendant who committed\n",
       "50,000 dollars in tax fraud.”\n",
       "Table 3a shows that the system selected a judge,\n",
       "defendant, defense attorney, and prosecutor as the relevant agents. In this scenario,\n",
       "the system selected a more flexible interaction protocol than the one used in the\n",
       "previous experiment. The judge was chosen as a center agent and, in order, the\n",
       "prosecutor, defense attorney, and defendant as the non-center agents. This means\n",
       "the judge spoke first in every simulation, alternating with the other agents: judge,\n",
       "prosecutor, judge, defense attorney, judge, defendant, and so on. As described in\n",
       "Section A.3, we call this the “center-ordered” interaction protocol.\n",
       "Figure 3: Experimental design and fitted SCM for “a judge is setting bail for a\n",
       "criminal defendant who committed 50,000 dollars in tax fraud.”\n",
       "SIMULATION DETAILS\n",
       "Agents: Judge, Defendant, Defense attorney, Prosecutor\n",
       "Simulations Run: 7 × 7 × 5 = 243\n",
       "Speaking Order: Judge, Prosecutor, Judge,\n",
       "Defense Attorney, Judge, Defendant, ... repeat\n",
       "VARIABLE INFORMATION\n",
       "Bail amount set by the judge\n",
       "Measurement Question: Judge: “What was the bail\n",
       "amount you set for the defendant?”\n",
       "Variable Type: Continuous\n",
       "Defendant’s criminal history\n",
       "Attribute Treatments: [‘0’, ‘1’, ‘2’, ‘3’, ‘6’, ‘9’, ‘12’]\n",
       "Proxy Attribute: Number of your prior convictions\n",
       "Variable Type: Count\n",
       "Prior case count for judge that day\n",
       "Attribute Treatments: [‘0’, ‘2’, ‘5’, ‘9’, ‘12’, ‘18’,\n",
       "‘23’]\n",
       "Proxy Attribute: Number of cases you have already\n",
       "heard today\n",
       "Variable Type: Count\n",
       "Defendant’s level of remorse\n",
       "Attribute Treatments: [‘no expressed remorse’, ‘low\n",
       "expressed remorse’, ‘moderate expressed remorse’, ‘high\n",
       "expressed remorse’, ‘extreme expressed remorse’]\n",
       "Proxy Attribute: Your level of expressed remorse\n",
       "Variable Type: Ordinal\n",
       "(a) Information for experimental design\n",
       "Bail\n",
       "Amount\n",
       "µ =\n",
       "54428.57\n",
       "σ2 = 1.9e7\n",
       "Criminal\n",
       "History\n",
       "Judge Case\n",
       "Count\n",
       "Defendant’s\n",
       "Remorse\n",
       "521.53\n",
       "(206.567)\n",
       "-74.632\n",
       "(109.263)\n",
       "-1153.061\n",
       "(603.325)\n",
       "(b) Fitted SCM\n",
       "Notes: Figure 3a provides the information automatically generated by the system to execute the\n",
       "experiment for its proposed hypothesis. Figure 3b shows the fitted SCM from the experiment.\n",
       "13\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_e7c34_row13_col0\" class=\"data row13 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row13_col1\" class=\"data row13 col1\" >14</td>\n",
       "      <td id=\"T_e7c34_row13_col2\" class=\"data row13 col2\" >The system chose the outcome to be the final bail amount, and the three pro-\n",
       "posed causes are the defendant’s criminal history, the number of cases the judge has\n",
       "already heard that day, and the defendant’s level of remorse. The number of cases\n",
       "the judge already heard that day and the defendant’s level of remorse are opera-\n",
       "tionalized literally, as the count of cases the judge has heard and five ordinal levels\n",
       "of possible outward expressions of remorsefulness. The defendant’s criminal history\n",
       "is operationalized as the number of previous convictions.\n",
       "In the fitted SCM in Figure 3b, only the defendant’s criminal history had a\n",
       "significant effect on the final bail amount with each additional conviction causing an\n",
       "average increase of $521.53 in bail (ˆβ* = 0.16, p = 0.012). It is unclear whether\n",
       "the defendant’s remorse affected the final bail amount. The effect size was small but\n",
       "non-trivial with borderline significance (ˆβ* = −0.12, and p = 0.056).\n",
       "When we estimated the SCM with interactions, the interaction between the\n",
       "judge’s case count and the defendant’s remorse was nontrivial (ˆβ* = −0.32, p =\n",
       "0.047). In this specification (Figure A.5), none of the other interactions or the stand-\n",
       "alone causes have a significant effect, including the defendant’s criminal history.\n",
       "3.3\n",
       "Interviewing for a job as a lawyer\n",
       "In our third simulated experiment, we chose the scenario “a person interviewing for\n",
       "a job as a lawyer.” The system determined that a job applicant and an employer\n",
       "were the agents. Unlike the previous simulations, we manually selected the variables\n",
       "in the SCM. Table 4a shows that these were the employer’s hiring decision as the\n",
       "outcome and whether the applicant passed the bar, the interviewer’s friendliness,\n",
       "and the job applicant’s height as the potential causes.\n",
       "The system operationalized the causes as a binary variable for passing the bar,\n",
       "the job applicant’s height in centimeters, and the interviewer’s friendliness as the\n",
       "proposed number of friendly phrases to use during the simulation. Since one of the\n",
       "causes is a binary variable, the only potential cause in all our scenarios of this type,\n",
       "the sample size for the experimental simulations of this scenario is smaller (n = 80).\n",
       "By default, the system runs a factorial experimental design for all proposed values\n",
       "14\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_e7c34_row14_col0\" class=\"data row14 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row14_col1\" class=\"data row14 col1\" >15</td>\n",
       "      <td id=\"T_e7c34_row14_col2\" class=\"data row14 col2\" >Figure 4: Experimental design and fitted SCM for “a person is interviewing for a\n",
       "job as a lawyer.”\n",
       "SIMULATION DETAILS\n",
       "Agents: Interviewer, Job Applicant\n",
       "Simulations Run: 2 × 5 × 8 = 405\n",
       "Speaking Order: Interviewer, Job Applicant,\n",
       "Interviewer, ...repeat\n",
       "VARIABLE INFORMATION\n",
       "Employer’s Decision\n",
       "Measurement Question: Employer: “Have you de-\n",
       "cided to hire the job applicant?”\n",
       "Variable Type: Binary\n",
       "Whether Applicant Passed Exam\n",
       "Attribute Treatments: [‘Passed’, ‘Not’]\n",
       "Proxy Attribute: Your bar exam status\n",
       "Variable Type: Binary\n",
       "Interviewer’s level of friendliness\n",
       "Attribute Treatments: [‘2’, ‘7’, ‘12’, ‘17’, ‘22’]\n",
       "Proxy Attribute: Number of positive phrases to use\n",
       "during interview\n",
       "Variable Type: Count\n",
       "Job applicant’s height\n",
       "Attribute Treatments:\n",
       "[‘160’, ‘165’, ‘170’, ‘175’,\n",
       "‘180’, ‘185’, ‘190’, ‘195’]\n",
       "Proxy Attribute: Your height in centimeters\n",
       "Variable Type: Continous\n",
       "(a) Information for experimental design\n",
       "Employer\n",
       "Decision\n",
       "µ = 0.62\n",
       "σ2 = 0.24\n",
       "Passed Bar\n",
       "Interviewer\n",
       "Friend-\n",
       "liness\n",
       "Applicant\n",
       "Height\n",
       "0.75\n",
       "(0.068)\n",
       "-0.002\n",
       "(0.005)\n",
       "0.003\n",
       "(0.003)\n",
       "(b) Fitted SCM\n",
       "Notes: Figure 4a provides the information automatically generated by the system to execute the\n",
       "experiment for the proposed hypothesis. Figure 4b shows the fitted SCM from the experiment.\n",
       "15\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_e7c34_row15_col0\" class=\"data row15 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row15_col1\" class=\"data row15 col1\" >16</td>\n",
       "      <td id=\"T_e7c34_row15_col2\" class=\"data row15 col2\" >of each cause. With only two possible values for the job applicant passing the bar\n",
       "(as opposed to 5 varied treatment values for the interviewer’s friendliness and 8 for\n",
       "the applicant’s height), this limits the possible combinations of the causal variables\n",
       "to 2 × 5 × 8 = 80. A researcher could run more simulations to increase the sample\n",
       "size if so desired.\n",
       "We can see in Figure 4b that only the applicant passing the bar has a clear causal\n",
       "effect on whether the applicant gets the job. This is the largest standardized effect we\n",
       "see across the simulations in the four scenarios (ˆβ* = 0.78, p < 0.001). On average,\n",
       "whether or not the applicant passes the bar increases the probability she gets the job\n",
       "by 75 percentage points. When we test for interactions, none are significant (Figure\n",
       "A.6).\n",
       "3.4\n",
       "An auction for a piece of art\n",
       "Finally, we explored the scenario of “3 bidders participating in an auction for a piece\n",
       "of art starting at fifty dollars.” Table 5a shows that the causes are each bidder’s\n",
       "maximum budget for the piece of art, and the outcome is the final price of the piece\n",
       "of art—all of which we selected.\n",
       "All four variables are operationalized in dollars. To maintain symmetry in the\n",
       "simulations, we also manually selected the same proxy attribute for the three bidders:\n",
       "“your maximum budget for the piece of art.”\n",
       "Each bidder had the same seven\n",
       "possible values for their attribute, leading to 73 = 343 simulations of the auction. It\n",
       "is important to note that these budgets are private values. Unless a bidder publically\n",
       "reveals their budget, the other bidders do not know what it is.\n",
       "Like the tax fraud scenario, the system chose the center-ordered interaction pro-\n",
       "tocol for these simulations. The auctioneer was selected as the central agent, and\n",
       "the other agents were bidder 1, bidder 2, and bidder 3, who alternated with the\n",
       "auctioneer in that order.\n",
       "Figure 5b provides the results.\n",
       "All three causal variables had a positive and\n",
       "statistically significant effect on the final price. A one-dollar increase in any of the\n",
       "bidder’s budgets caused a $0.35, $0.29, and $0.31 increase in the final price for the\n",
       "16\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_e7c34_row16_col0\" class=\"data row16 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row16_col1\" class=\"data row16 col1\" >17</td>\n",
       "      <td id=\"T_e7c34_row16_col2\" class=\"data row16 col2\" >Figure 5: Experimental design and fitted SCM for “3 bidders participating in an\n",
       "auction for a piece of art starting at fifty dollars.”\n",
       "SIMULATION DETAILS\n",
       "Agents: Bidder 1, Bidder 2, Bidder 3, Auctioneer\n",
       "Simulations Run: 7 × 7 × 7 = 343\n",
       "Speaking Order: Auctioneer, Bidder 1, Auctioneer,\n",
       "Bidder 2, Auctioneer, Bidder 3, ... repeat\n",
       "VARIABLE INFORMATION\n",
       "Final price\n",
       "Measurement Question:\n",
       "Auctioneer:\n",
       "“What was\n",
       "the final bid for the piece of art at the end of the auc-\n",
       "tion?”\n",
       "Variable Type: Continuous\n",
       "Bidder 1’s maximum budget\n",
       "Attribute Treatments: [‘$50’, ‘$100’, ‘$150’, ‘$200’,\n",
       "‘$250’, ‘$300’, ‘$350’]\n",
       "Proxy Attribute: Your max budget for the art\n",
       "Variable Type: Continuous\n",
       "Bidder 2’s maximum budget\n",
       "Attribute Treatments: [‘$50’, ‘$100’, ‘$150’, ‘$200’,\n",
       "‘$250’, ‘$300’, ‘$350’]\n",
       "Proxy Attribute: Your max budget for the art\n",
       "Variable Type: Continuous\n",
       "Bidder 3’s maximum budget\n",
       "Attribute Treatments: [‘$50’, ‘$100’, ‘$150’, ‘$200’,\n",
       "‘$250’, ‘$300’, ‘$350’]\n",
       "Proxy Attribute: Your max budget for the art\n",
       "Variable Type: Continuous\n",
       "(a) Information for experimental design\n",
       "Final Price\n",
       "µ = 186.53\n",
       "σ2 = 3879.23\n",
       "Bidder 1\n",
       "Budget\n",
       "Bidder 2\n",
       "Budget\n",
       "Budder\n",
       "3 Budget\n",
       "0.35\n",
       "(0.015)\n",
       "0.29\n",
       "(0.015)\n",
       "0.31\n",
       "(0.015)\n",
       "(b) Fitted SCM\n",
       "Notes: Figure 5a provides the information automatically generated by the system to execute the\n",
       "experiment for the proposed hypothesis. Figure 5b shows the fitted SCM from the experiment.\n",
       "17\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_e7c34_row17_col0\" class=\"data row17 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row17_col1\" class=\"data row17 col1\" >18</td>\n",
       "      <td id=\"T_e7c34_row17_col2\" class=\"data row17 col2\" >piece of art for each respective bidder (ˆβ* = 0.57, p < 0.001; ˆβ* = 0.47, p < 0.001;\n",
       "ˆβ* = 0.5 p < 0.001). These quantities make sense as each bidder has a 1\n",
       "3 chance of\n",
       "being marginal.\n",
       "4\n",
       "LLM predictions for paths and points\n",
       "It is worth reiterating that the results in the previous section were not generated\n",
       "by directly prompting an LLM but rather through experimentation. Although the\n",
       "experiments were fast and inexpensive, they were not free–in total, they took about\n",
       "5 hours to run and cost over $1,000. This raises the question of whether the simu-\n",
       "lations were even necessary. Could an LLM do a “thought experiment” (i.e., make\n",
       "a prediction based on a prompt) about a proposed in silico experiment and achieve\n",
       "the same insight? If so, we should just prompt the LLM to come up with an SCM\n",
       "and elicit its predictions about the relationships between the variables.\n",
       "To test this idea, we describe some of the simulations to the LLM and ask it to\n",
       "predict the results—path estimates and point predictions.10 Specifically, we modeled\n",
       "each scenario as y = Xβ, where y is an n × 1 vector and X is a n × k matrix.\n",
       "Here, n is the number of simulations, and k is the number of proposed causes. The\n",
       "experiments from Section 3 provided us with estimates for ˆβ (a k × 1 vector). We\n",
       "describe the scenario and the experiment to the LLM and ask it to independently\n",
       "predict yi given each Xi (a predict-yi task) as well as to predict ˆβ (a predict-ˆβ task).\n",
       "The LLM’s yi predictions are highly inaccurate compared to those from auction\n",
       "theory, which predicts that the clearing price will be the second highest valuation in\n",
       "an open-ascending price auction with private values (Maskin and Riley, 1985). The\n",
       "LLM is also unable to accurately predict the path estimates (ˆβ) of the fitted SCM.\n",
       "Finally, we examine how the LLM does on the predict-yi task when provided with an\n",
       "SCM fit on all of the data except for the corresponding Xi (the predict-yi|ˆβ−i task).\n",
       "While the additional information dramatically improves the LLM’s predictions, they\n",
       "are still less accurate than those made by auction theory.\n",
       "10All predictions are made by the LLM once at temperature 0. When we elicit these predictions\n",
       "many times at higher temperatures, the results are similar.\n",
       "18\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_e7c34_row18_col0\" class=\"data row18 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row18_col1\" class=\"data row18 col1\" >19</td>\n",
       "      <td id=\"T_e7c34_row18_col2\" class=\"data row18 col2\" >4.1\n",
       "Predicting yi\n",
       "For various bidder reservation price combinations in the auction experiment, we\n",
       "supply the LLM with a prompt detailing the simulation and experimental design.11\n",
       "We then ask the LLM to predict the clearing price for the auction. This gives us a\n",
       "point prediction for each simulated auction (i.e., each unique row Xi in X) used to\n",
       "generate the fitted SCM in Figure 5b.\n",
       "Figure 6 presents a comparison of the LLMs predictions, the simulated experi-\n",
       "ments, and the predictions made by auction theory.12 The columns correspond to\n",
       "the different reservation values for bidder 3 in a given simulation, and the rows cor-\n",
       "respond to the different reservation values for bidder 2. The y-axis is the final bid\n",
       "price, and the x-axis lists bidder 1’s reservation price. The black triangles track the\n",
       "observed clearing price in each simulated experiment, the black line shows the pre-\n",
       "dictions made by auction theory, and the blue line indicates the LLM’s predictions\n",
       "without the fitted SCM—the predict-yi task.\n",
       "The LLM performs poorly at the predict-yi task.\n",
       "The blue line is often far\n",
       "from the black triangles and sometimes remains constant or even decreases as the\n",
       "second-highest reservation price across the agents increases.\n",
       "In contrast, auction\n",
       "theory is highly accurate in its predictions of the final bid price in the experiment—\n",
       "the black line often perfectly tracks the black triangles.13 The mean squared error\n",
       "(MSE) of the LLM’s predictions in the predict-yi task (MSEyi = 8628) is an order of\n",
       "magnitude higher than that of the theoretical predictions (MSETheory = 128), and\n",
       "the predictions are even further from the theory than they are from the empirical\n",
       "results (MSEyi−Theory = 8915).14\n",
       "11In 80/343 simulations, the agents made the maximum number of statements (20) allowed by\n",
       "the system before the auction ended. We remove these observations because, without additional\n",
       "information, auction theory does not make predictions about partially completed auctions.\n",
       "12We provide only a subset of the results in the main text as it is difficult to visualize all of them\n",
       "in a single figure. Figure A.10 shows the full set of predictions. The results are generally the same.\n",
       "13There are a few observations where the empirical clearing price is slightly above or below the\n",
       "theory prediction. In most cases where it was off, this was due to the auctioneer incrementing the\n",
       "bid price above the second-highest reservation price in the last round.\n",
       "14MSE is reported for all predictions, not just the subset shown in Figure 6.\n",
       "19\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_e7c34_row19_col0\" class=\"data row19 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row19_col1\" class=\"data row19 col1\" >20</td>\n",
       "      <td id=\"T_e7c34_row19_col2\" class=\"data row19 col2\" >Figure 6: Comparison of the LLM’s predictions to the theoretical predictions and a\n",
       "subset of experimental results for the auction scenario.\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Pred. yi\n",
       "Pred. yi | β^\n",
       "−i\n",
       "Auc. Theory\n",
       "Bidder 3\n",
       "Reservation: 150\n",
       "Bidder 3\n",
       "Reservation: 200\n",
       "Bidder 3\n",
       "Reservation: 250\n",
       "Bidder 3\n",
       "Reservation: 300\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 200\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 150\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 100\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 50\n",
       "100\n",
       "200\n",
       "300\n",
       "400\n",
       "100\n",
       "200\n",
       "300\n",
       "400\n",
       "100\n",
       "200\n",
       "300\n",
       "400\n",
       "100\n",
       "200\n",
       "300\n",
       "400\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "Bidder 1\n",
       "Reservation Price\n",
       "Final Clearing Price\n",
       "Experiment\n",
       "Notes: The columns correspond to the different reservation values for bidder 3 in a given simulation,\n",
       "and the rows correspond to the different reservation values for bidder 2. The y-axis is the clearing\n",
       "price, and the x-axis lists bidder 1’s reservation price. The black triangles track the observed clearing\n",
       "price in each simulated experiment, the black line shows the predictions made by auction theory\n",
       "(MSET heory = 128), the blue line indicates the LLM’s predictions without the fitted SCM—the\n",
       "predict-yi task (MSEyi = 8628), and the red line is the LLM’s predictions with the fitted SCM—the\n",
       "predict-yi|ˆβ−i task (MSEyi| ˆβ−i = 1505).\n",
       "20\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_e7c34_row20_col0\" class=\"data row20 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row20_col1\" class=\"data row20 col1\" >21</td>\n",
       "      <td id=\"T_e7c34_row20_col2\" class=\"data row20 col2\" >4.2\n",
       "Predicting ˆβ\n",
       "We prompted the LLM to predict the path estimates and whether they would be\n",
       "statistically significant for the simulated experiments in Section 3. This is the predict-\n",
       "ˆβ task. We then compare the LLM’s predictions to the fitted SCMs. With four\n",
       "experiments and three causes in each, we generate 12 predictions.\n",
       "We provide the LLM with extensive information to make its predictions for each\n",
       "experiment.15 This information includes the proposed SCM, the operationalizations\n",
       "of the variables, the number of simulations, and the possible treatment values. Each\n",
       "prediction is elicited once at temperature 0.\n",
       "The predictions are shown in Table A.1. They were, on average, 13.2 times larger\n",
       "than the actual estimates, and 10/12 of the predictions were overestimates. Even\n",
       "when we remove the largest overestimate, the average magnitude of the ratio between\n",
       "the predicted and actual estimates is still 5.3. The sign of the estimate was correct\n",
       "in 10/12 predictions, and 10/12 correctly guessed whether or not the estimate would\n",
       "be statistically significant. When we repeat the predictions at a higher temperature\n",
       "and take their average, the results are similar (see Table A.2).\n",
       "4.3\n",
       "Predicting yi|ˆβ−i\n",
       "The LLM was, on average, off by an order of magnitude for both the predict-yi task\n",
       "and the predict-ˆβ task, but maybe it can do better with more information. For each\n",
       "Xi in the auction simulations, we use the data from the experiment to estimate ˆβ−i,\n",
       "the path estimates from the SCM excluding the ith observation. We then prompt\n",
       "the LLM to predict the outcome for each Xi given ˆβ−i.\n",
       "The red line in Figure 6 provides these new predictions.\n",
       "The LLM’s predic-\n",
       "tions are much closer to the actual outcomes when it has access to a fitted SCM\n",
       "(MSEyi|ˆβ−i = 1505) as opposed to when it does not (MSEyi = 8628), even though\n",
       "all the predictions are out of sample and every Xi is unique.\n",
       "However, the LLM’s predictions on the predict-yi|ˆβ−i task are still not as accurate\n",
       "15See Figure A.11 in the appendix for the full prompt.\n",
       "21\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_e7c34_row21_col0\" class=\"data row21 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row21_col1\" class=\"data row21 col1\" >22</td>\n",
       "      <td id=\"T_e7c34_row21_col2\" class=\"data row21 col2\" >as the predictions made by auction theory (MSETheory = 128).16 They are also still\n",
       "further from the theory than they are from the empirical results (MSEyi|ˆβ−i−Theory =\n",
       "1761). There is clearly room for improvement. That improvement is feasible with\n",
       "the system: there exists an SCM perfectly consistent with auction theory. Only one\n",
       "exogenous variable was missing: the second-highest reservation price of the bidders.\n",
       "If allowed to generate and test enough potential causes, our system could have se-\n",
       "lected this variable as a possible cause by itself. In this case, the fitted SCM would\n",
       "have matched the theoretical predictions.17\n",
       "5\n",
       "Identifying causal structure ex-ante\n",
       "The SCM-based approach offers a promising new method for studying simulated be-\n",
       "havior at scale. However, it is not the only option for such rapid exploration. Others\n",
       "have designed large, quasi-unstructured simulations demonstrating exciting results.\n",
       "For example, Park et al. (2023) endows a group of LLM agents with personas and\n",
       "memory systems and then allows them to freely interact in a simulated community\n",
       "for an extended period. Despite no explicit instructions to do so, the agents in the\n",
       "simulation produce many human-like behaviors, such as throwing parties, going on\n",
       "dates, and making friends.\n",
       "While impressive and informative, a problem with such open-ended social simu-\n",
       "lations is that selecting and analyzing outcomes can be difficult. To unveil insights,\n",
       "researchers may need to comb through thousands of lines of unstructured text. If\n",
       "they are interested in casual relationships, they may need to infer the causal struc-\n",
       "ture ex-post, which can be problematic. In contrast, the SCM framework describes\n",
       "exactly what needs to be measured as a downstream outcome subject to the exoge-\n",
       "nous manipulations of the cause. Identification is guaranteed. In this section, we\n",
       "16It is also less accurate than the mechanical predictions made by the fitted SCM using the same\n",
       "procedure MSEMechanistic:yi| ˆβ−i = 725. Maybe the LLM cannot do the math, is still conditioning\n",
       "on other information beyond the path estimates when making its predictions, or, like humans, is\n",
       "ignoring relevant information when making choices (Handel and Schwartzstein, 2018).\n",
       "17When we do fit this SCM (see Figure A.9), the coefficient is close to one (β = 0.912), and\n",
       "almost all the variance in the outcome is explained (R2 = 0.977).\n",
       "22\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_e7c34_row22_col0\" class=\"data row22 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row22_col1\" class=\"data row22 col1\" >23</td>\n",
       "      <td id=\"T_e7c34_row22_col2\" class=\"data row22 col2\" >discuss how assuming or searching for causal structure in observational data, the\n",
       "type generated from massive open-ended simulations can lead to misidentification\n",
       "and how using SCMs avoids this problem.\n",
       "5.1\n",
       "Assuming causal structure from data\n",
       "All estimates in the fitted SCMs in Section 3 are unbiased. We know this because\n",
       "the data comes from an experiment, and we randomized on the causal variables.\n",
       "A nice feature of a perfectly randomized experiment is that we can get unbiased\n",
       "measurements of any downstream endogenous outcome relative to the exogenous\n",
       "manipulations.18 I.e., the coefficients on the fitted SCM are identified. For example,\n",
       "in the bargaining experiment, perhaps we are interested in the length of the con-\n",
       "versation as an outcome, even though it was not a part of the original SCM. The\n",
       "conversation length can be operationalized as the sum of the number of statements\n",
       "made by all agents, and we can use the transcript from the finished experiment to\n",
       "measure it. We can then fit an SCM with the data and get unbiased estimates of\n",
       "the effect of the exogenous variables on the conversation’s length.\n",
       "Figure 7a shows this fitted SCM using the data from the experiment in Section 3.\n",
       "Both the buyer’s budget and the seller’s minimum price have a significant effect on\n",
       "the length of the conversation (p < 0.001; p = 0.026), but the seller’s emotional\n",
       "attachment does not (p = 0.147).\n",
       "Suppose we did not know the actual causal structure of these scenarios or that the\n",
       "data came from an experiment. All we have are the data for the original three causes,\n",
       "the conversation length, and whether a deal was made (the original outcome). If we\n",
       "want to estimate the causal relationships between these variables, we would have to\n",
       "make untestable assumptions. For example, one could reasonably presume that the\n",
       "buyer’s budget, the seller’s minimum price, the seller’s emotional attachment, and\n",
       "whether a deal was made all causally affect the length of the conversation.\n",
       "Figure 7b provides the fitted SCM for this proposed causal structure.\n",
       "Only\n",
       "18When we say “downstream,” we mean any variable whose value is realized after the agents\n",
       "begin interacting in the simulated conversations.\n",
       "23\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_e7c34_row23_col0\" class=\"data row23 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row23_col1\" class=\"data row23 col1\" >24</td>\n",
       "      <td id=\"T_e7c34_row23_col2\" class=\"data row23 col2\" >Figure 7: Comparison of the true and misspecified SCMs.\n",
       "Convo\n",
       "Length\n",
       "Buyer\n",
       "Budget\n",
       "Seller\n",
       "Min\n",
       "Seller\n",
       "Love\n",
       "-0.111\n",
       "(0.031)\n",
       "0.069\n",
       "(0.031)\n",
       "0.222\n",
       "(0.153)\n",
       "(a) Correctly specified SCM\n",
       "Convo\n",
       "Length\n",
       "Deal\n",
       "Occurs\n",
       "Buyer\n",
       "Budget\n",
       "Seller\n",
       "Min\n",
       "Seller\n",
       "Love\n",
       "-0.051\n",
       "(0.039)\n",
       "0.012\n",
       "(0.037)\n",
       "-1.622\n",
       "(0.615)\n",
       "0.182\n",
       "(0.153)\n",
       "(b) Misspecified SCM\n",
       "Notes: Statistically significant paths are marked in red (α = 0.05). Each path is given with its\n",
       "estimated coefficient and standard error in parentheses. Both SCMs are estimated using the data\n",
       "from the bargaining scenario in Section 3. Subfigure (a) provides a correctly specified SCM from\n",
       "a randomized experiment. Subfigure (b) shows a misspecified SCM based on an assumed structure.\n",
       "The path estimates of the buyer’s budget and the seller’s minimum price go from significant in the\n",
       "correctly specified SCM to insignificant and far closer to zero in the misspecified SCM.\n",
       "whether a deal was made was estimated to have a significant effect on the length\n",
       "of the conversation (p = 0.008). But we know this is wrong. We have the true\n",
       "causal structure in Figure 7a from a perfectly randomized experiment, and both\n",
       "the buyer’s and the seller’s reservation prices had a significant effect on the length\n",
       "of the conversation. Here, they are insignificant and far closer to zero (p = 0.189;\n",
       "p = 0.755).\n",
       "Whether or not the deal occurred is a bad control that biases the\n",
       "estimates—it is probably codetermined with the length of the conversation.19\n",
       "The informed econometrician may presume that she would never make such a\n",
       "mistake, but many researchers are not so savvy.20 We were unsure of it until we\n",
       "had unbiased estimates from the correctly specified SCM as a reference. There are\n",
       "also many kinds of bad controls, and many of them are less obvious than those in\n",
       "19We cannot be sure about the causal relationship between the length of the conversation and\n",
       "whether a deal was made because neither is exogenously varied in the experiment. All we know\n",
       "is that controlling for whether or not a deal occurs induces bias, as we have the experiment as a\n",
       "reference.\n",
       "20LLMs are definitely not yet savvy enough to avoid this mistake.\n",
       "24\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_e7c34_row24_col0\" class=\"data row24 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row24_col1\" class=\"data row24 col1\" >25</td>\n",
       "      <td id=\"T_e7c34_row24_col2\" class=\"data row24 col2\" >this example (Cinelli et al., 2022). It is easy to misspecify a model when the data\n",
       "is observational and has many variables, even when their relationships may seem\n",
       "obvious.\n",
       "The SCM-based approach avoids the bad controls. The generation of the data is\n",
       "based on the causal structure. There is no need to instrument endogenous variables\n",
       "and presume their causal relationships. Exogenous variation is explicitly induced in\n",
       "the SCM to identify the causal relationships ex-ante. Even if we do not know how a\n",
       "new outcome is incorporated into the causal structure, we can always reference how\n",
       "it is affected by the exogenous variables by fitting a simple linear SCM.\n",
       "5.2\n",
       "Searching for causal structure in data\n",
       "Another strategy for identifying causal relationships when the underlying structure is\n",
       "unknown is to let the data speak for itself. For example, we could use an algorithm to\n",
       "find the model that makes the data most likely. There are many ways to do this, none\n",
       "of which can always, or even consistently, identify the correct causal relationships\n",
       "from observational data (Pearl, 2009a). These algorithms take as input potential\n",
       "variables of interest (a graph with no edges, only nodes) and data for these variables.\n",
       "They output a proposed DAG that best fits the data.21\n",
       "The simplest algorithm is to generate all possible DAGs for existing variables and\n",
       "then evaluate each model based on some criteria (e.g., maximum likelihood, Bayesian\n",
       "information criterion, etc.).22 Another method is to add edges that maximize the\n",
       "criteria greedily. This approach can be further improved by penalizing the model\n",
       "for complexity (based on additional criteria) and removing edges until the model is\n",
       "greedily optimized. The second approach is the Greedy Equivalence Search (GES)\n",
       "algorithm (Chickering, 2002), which we used on the data and from all the experiments\n",
       "21These algorithms often do not presume a functional form, so we refer refer to hypotheses as\n",
       "DAGs, not SCMs, in this section.\n",
       "22The number of possible DAGs grows exponentially with the number of nodes. For example,\n",
       "for n = 1, 2, 3, and 4 nodes, there are 1, 3, 25, and 543 possible DAGs. This is a combinatorial\n",
       "explosion, and it is not feasible to evaluate all potential models for a large number of nodes, which\n",
       "presents further problems for this approach.\n",
       "25\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_e7c34_row25_col0\" class=\"data row25 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row25_col1\" class=\"data row25 col1\" >26</td>\n",
       "      <td id=\"T_e7c34_row25_col2\" class=\"data row25 col2\" >in Section 3.23\n",
       "In some experiments, the algorithm incorrectly identified the causal structure.\n",
       "Figure 8 provides the DAG identified by the GES algorithm for the tax fraud scenario.\n",
       "As a reminder, the original causal variables are the defendant’s previous convictions,\n",
       "the judge’s number of cases heard that day, and the defendant’s level of remorse,\n",
       "and the outcome is the bail amount. The algorithm has no information about which\n",
       "variables are exogenously varied, just the raw data.\n",
       "Figure 8: Incorrect causal structure identified by the GES algorithm for the tax\n",
       "fraud experiment.\n",
       "Bail\n",
       "Amount\n",
       "Crime\n",
       "History\n",
       "Remorse\n",
       "Num\n",
       "Cases\n",
       "Notes: The Greedy Equivalence Search (GES) algorithm can incorrectly identify the causal structure\n",
       "of observational data. In the tax fraud scenario, we know from Figure 3b and the accompanying\n",
       "experiment that an increase in the defendant’s previous convictions caused an increase in the av-\n",
       "erage bail amount. However, the algorithm identified the causal relationship as equally likely in\n",
       "either direction. Without the correctly specified DAG, a researcher would have to assume the causal\n",
       "structure of the data, which can be problematic.\n",
       "The GES algorithm identified the defendant’s criminal history and the bail amount\n",
       "as the only variables in the scenario with any causal relationship. This is partially\n",
       "correct—we know from the experiment that an increase in the defendant’s previous\n",
       "convictions caused an increase in the average bail amount. However, the algorithm\n",
       "identified the causal relationship as equally likely in either direction.\n",
       "There was\n",
       "no more evidence in the data that the defendant’s criminal history caused the bail\n",
       "amount than the bail amount caused the defendant’s criminal history. And while we\n",
       "know that the former is correct from our experiment, a researcher using the algo-\n",
       "23The GES algorithm is not perfectly stable; different runs on the same data can produce different\n",
       "results, which is its own problem.\n",
       "26\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_e7c34_row26_col0\" class=\"data row26 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row26_col1\" class=\"data row26 col1\" >27</td>\n",
       "      <td id=\"T_e7c34_row26_col2\" class=\"data row26 col2\" >rithm without the correctly specified DAG would not. They would have to make an\n",
       "assumption, which, as we have shown, can be problematic.\n",
       "The SCM-based approach avoids search problems, as we never need to search\n",
       "for the causal structure given the data. Instead, we generate the data based on a\n",
       "proposed causal structure. Even if we want to measure a new outcome on the existing\n",
       "experimental data, we have already identified the sources of exogenous variation.\n",
       "We should note that problems with searching for or assuming causal structures\n",
       "from data are not new. Pearl (2009a) makes a similar point many times. However,\n",
       "social scientists have never had the tools to induce exogenous variation and explore\n",
       "causal relationships at scale in many different scenarios.\n",
       "6\n",
       "Conclusion\n",
       "This paper demonstrates an approach to automated in silico hypothesis generation\n",
       "and testing made possible through the use of SCMs. We implemented the approach\n",
       "by building a computational system with LLMs and provided evidence that simu-\n",
       "lations can elicit information from an LLM that was not ex-ante available to the\n",
       "model. We also showed that such simulations produce results that are highly con-\n",
       "sistent with theoretical predictions made by the relevant economic theory. In this\n",
       "final section, we will discuss why such systems could be useful and identify areas for\n",
       "future research.\n",
       "6.1\n",
       "Controlled experimentation at scale\n",
       "How might systems like the one presented in this paper be useful for social science\n",
       "research? One view is that these simulations are simple dress rehearsals for “real”\n",
       "social science. A more expansive and exciting view is that these simulations would\n",
       "yield insights that sometimes generalize to the real world.\n",
       "This is a view that sees these agents as a step forward in representing humans\n",
       "far beyond classical methods in agent-based modeling, such as those used to explore\n",
       "how individual preferences can lead to surprising social patterns (Schelling, 1969,\n",
       "27\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_e7c34_row27_col0\" class=\"data row27 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row27_col1\" class=\"data row27 col1\" >28</td>\n",
       "      <td id=\"T_e7c34_row27_col2\" class=\"data row27 col2\" >1971).24 This view would mirror recent advances in the use of machine learning for\n",
       "protein folding (Jumper et al., 2021) and material discovery (Merchant et al., 2023).\n",
       "The system presented in this paper can generate these controlled experimental\n",
       "simulations en masse with prespecified plans for data collection and analysis. That\n",
       "contrasts most academic social science research as currently practiced (Almaatouq\n",
       "et al., 2022).25 This contrast is important. In the social sciences, context can heavily\n",
       "influence results. Outcomes that hold true for one population may not for another.\n",
       "Even within the same population, a change in environment can nullify or flip re-\n",
       "sults (Lerner et al., 2004). Studying humans is also expensive and time-consuming,\n",
       "which makes rapid, inexpensive, and replicable exploration valuable. There is still,\n",
       "of course, the fundamental jump from simulations to human subjects.\n",
       "6.2\n",
       "Interactivity\n",
       "The system allows a scientist to monitor its entire process.\n",
       "Should a researcher\n",
       "disagree with or be uncertain about a decision made by the system, they can probe\n",
       "the system regarding its choice. This allows the researcher to either (1) understand\n",
       "why the decision was made, (2) ask the system to come up with a different option\n",
       "for that decision, or (3) input their own custom choice for that decision.\n",
       "A researcher can even ignore much of the automation process and fill in the details\n",
       "themselves. They can choose the variables of interest, their operationalizations, the\n",
       "attributes of the agents, how the agents interact, or customize the statistical analysis,\n",
       "among other decision points. Different parts of the system can also accommodate\n",
       "different types of LLMs simultaneously. For example, a researcher could use GPT-\n",
       "4 to generate hypotheses and Llama-2-70B to power the agents’ simulated social\n",
       "interactions.\n",
       "24See Horton (2023) for a full discussion on the differences between traditional agent-based mod-\n",
       "eling and the use of LLM-powered agents. This position reflects our views as it was written recently\n",
       "by some of the authors of this paper.\n",
       "25When a group of social scientists has the same data set on some human behavior or outcome,\n",
       "they can reach very different conclusions when analyzing it independently (Engzell, 2023; Salganik\n",
       "et al., 2020).\n",
       "28\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_e7c34_row28_col0\" class=\"data row28 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row28_col1\" class=\"data row28 col1\" >29</td>\n",
       "      <td id=\"T_e7c34_row28_col2\" class=\"data row28 col2\" >6.3\n",
       "Replicability\n",
       "Replicating social science experiments with human subjects can be difficult (Camerer\n",
       "et al., 2018). Despite the use of preregistrations, the exact procedures used in exper-\n",
       "iments are often unclear (Engzell, 2023). In contrast, the system allows for nearly\n",
       "frictionless communication and replication of the experimental design.\n",
       "The system’s entire procedure is exportable as a JSON file with the fitted SCM.26\n",
       "This JSON includes every decision the system makes, including natural language\n",
       "explanations for the choices and the transcripts from each simulation. These JSONs\n",
       "can be saved or uploaded at any point in the system’s process. A researcher could run\n",
       "experiments and post the JSON and results online. Other scientists could inspect,\n",
       "replicate the experiment, or extend the work.\n",
       "6.4\n",
       "Future research\n",
       "While designing our system, we encountered several areas for new research. First is\n",
       "the problem of “which attributes” to endow an LLM-powered agent beyond those im-\n",
       "mediately relevant to the proposed exogenous variables. For example, demographic\n",
       "information, personalities, and other traits are not included in the agent’s attributes\n",
       "unless they are a part of the SCM. To improve the fidelity of the simulations, it\n",
       "might make sense to add some or all of these attributes to the agents. However, it\n",
       "is unclear how to optimize this process.\n",
       "Second, we encountered the problem of engineering social interactions between\n",
       "LLM agents. LLMs are designed to exchange text in sequence, necessitating a pro-\n",
       "tocol for turn-taking that reflects the natural ebb and flow of human conversation.\n",
       "In an initial attempt to address this problem, we created a menu of flexible agent-\n",
       "ordering mechanisms. We also introduced an additional LLM-powered agent into our\n",
       "version of the system whom we dub the ‘coordinator.” The coordinator functions\n",
       "as a quasi-omniscient assistant who can read through transcripts and make choices\n",
       "26A JSON (JavaScript Object Notation) is a data format that is easy for humans to read and\n",
       "write and easy for machines to parse and generate. It is commonly used for transmitting data in\n",
       "web applications, as a configuration and data storage format, and for serializing and transmitting\n",
       "structured data over a network.\n",
       "29\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_e7c34_row29_col0\" class=\"data row29 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row29_col1\" class=\"data row29 col1\" >30</td>\n",
       "      <td id=\"T_e7c34_row29_col2\" class=\"data row29 col2\" >about the speaking order of other agents in the simulations. There are probably\n",
       "better ways to determine the speaking order of agents.\n",
       "A related problem is the question of when to stop the simulations. Like Turing’s\n",
       "halting problem, there is likely no universal rule for when conversations should end,\n",
       "but there are probably better rules than those we have implemented. A Markov\n",
       "model approximating the distribution of agents speaking, estimated from real con-\n",
       "versation data, might provide more naturalistic results for simulating and ending\n",
       "interactions, but that is an idea for future work.\n",
       "Lastly, if we can build a system that can automate one iteration of the scientific\n",
       "process and determine a follow-on experiment, a clear next step is to set up an\n",
       "intelligently automated research program. This would involve using outcomes from\n",
       "the simulations to inform continuous cycles of experimentation. Then, a researcher\n",
       "could intelligently explore a given scenario’s parameter space. How to optimize this\n",
       "exploration amongst so many possible variables will be an important problem to\n",
       "solve.\n",
       "As presented in this paper, the system provides only one possible implementation\n",
       "of the SCM-based approach. We made many subjective decisions. Other researchers\n",
       "might implement the approach with different design choices.\n",
       "There is room for\n",
       "improvement and exploration.\n",
       "30\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_e7c34_row30_col0\" class=\"data row30 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row30_col1\" class=\"data row30 col1\" >31</td>\n",
       "      <td id=\"T_e7c34_row30_col2\" class=\"data row30 col2\" >References\n",
       "Aher, Gati V, Rosa I Arriaga, and Adam Tauman Kalai, “Using large lan-\n",
       "guage models to simulate multiple humans and replicate human subject studies,”\n",
       "in “International Conference on Machine Learning” PMLR 2023, pp. 337–371.\n",
       "Almaatouq, Abdullah, Thomas L. Griffiths, Jordan W. Suchow, Mark E.\n",
       "Whiting, James Evans, and Duncan J. Watts, “Beyond Playing 20 Ques-\n",
       "tions with Nature: Integrative Experiment Design in the Social and Behavioral\n",
       "Sciences,” Behavioral and Brain Sciences, 2022, p. 1–55.\n",
       "Argyle, Lisa P, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christo-\n",
       "pher Rytting, and David Wingate, “Out of one, many: Using language models\n",
       "to simulate human samples,” Political Analysis, 2023, 31 (3), 337–351.\n",
       "Atari, M., M. J. Xue, P. S. Park, D. E. Blasi, and J. Henrich, “Which\n",
       "Humans?,” Technical Report 09 2023. https://doi.org/10.31234/osf.io/5b26t.\n",
       "Athey, Susan, Jonathan Levin, and Enrique Seira, “Comparing open and\n",
       "Sealed Bid Auctions: Evidence from Timber Auctions*,” The Quarterly Journal\n",
       "of Economics, 02 2011, 126 (1), 207–257.\n",
       "Bakker, Michiel, Martin Chadwick, Hannah Sheahan, Michael Tessler,\n",
       "Lucy Campbell-Gillingham,\n",
       "Jan Balaguer,\n",
       "Nat McAleese,\n",
       "Amelia\n",
       "Glaese, John Aslanides, Matt Botvinick, and Christopher Summerfield,\n",
       "“Fine-tuning language models to find agreement among humans with diverse pref-\n",
       "erences,” in S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh,\n",
       "eds., Advances in Neural Information Processing Systems, Vol. 35 Curran Asso-\n",
       "ciates, Inc. 2022, pp. 38176–38189.\n",
       "Binz, Marcel and Eric Schulz, “Turning large language models into cognitive\n",
       "models,” 2023.\n",
       "and\n",
       ", “Using cognitive psychology to understand GPT-3,” Proceedings of the\n",
       "National Academy of Sciences, 2023, 120 (6), e2218523120.\n",
       "31\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_e7c34_row31_col0\" class=\"data row31 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row31_col1\" class=\"data row31 col1\" >32</td>\n",
       "      <td id=\"T_e7c34_row31_col2\" class=\"data row31 col2\" >Brand, James, Ayelet Israeli, and Donald Ngwe, “Using GPT for Market\n",
       "Research,” Working paper, 2023.\n",
       "Bubeck,\n",
       "S´ebastien,\n",
       "Varun Chandrasekaran,\n",
       "Ronen Eldan,\n",
       "Johannes\n",
       "Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi\n",
       "Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\n",
       "and Yi Zhang, “Sparks of Artificial General Intelligence: Early experiments with\n",
       "GPT-4,” 2023.\n",
       "Burns, C, H Ye, D Klein, and J Steinhardt, “Discovering latent knowledge in\n",
       "language models without supervision,” in “International Conference on Learning\n",
       "Representations (ICLR)” 2023.\n",
       "Buyalskaya, Anastasia, Hung Ho, Katherine L. Milkman, Xiaomin Li,\n",
       "Angela L. Duckworth, and Colin Camerer, “What can machine learning\n",
       "teach us about habit formation? Evidence from exercise and hygiene,” Proceedings\n",
       "of the National Academy of Sciences, 2023, 120 (17), e2216115120.\n",
       "Cai, Alice, Steven R Rick, Jennifer L Heyman, Yanxia Zhang, Alexandre\n",
       "Filipowicz, Matthew Hong, Matt Klenk, and Thomas Malone, “Desig-\n",
       "nAID: Using Generative AI and Semantic Diversity for Design Inspiration,” in\n",
       "“Proceedings of The ACM Collective Intelligence Conference” CI ’23 Association\n",
       "for Computing Machinery New York, NY, USA 2023, p. 1–11.\n",
       "Camerer, Colin, Anna Dreber, Felix Holzmeister, Teck-Hua Ho, Jurgen\n",
       "Huber, Magnus Johannesson, Michael Kirchler, Gideon Nave, Brian A.\n",
       "Nosek, Thomas Pfeiffer, Adam Altmejd, Nick Buttrick, Taizan Chan,\n",
       "Yiling Chen, Eskil Forsell, Anup Gampa, Emma Heikensten, Lily Hum-\n",
       "mer, Taisuke Imai, Siri Isaksson, Dylan Manfredi, Julia Rose, Eric-Jan\n",
       "Wagenmakers, and Hang Wu, “Evaluating the Replicability of Social Science\n",
       "Experiments in Nature and Science between 2010 and 2015,” Nature Human Be-\n",
       "haviour, Aug 2018, 2 (9), 637–644.\n",
       "32\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_e7c34_row32_col0\" class=\"data row32 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row32_col1\" class=\"data row32 col1\" >33</td>\n",
       "      <td id=\"T_e7c34_row32_col2\" class=\"data row32 col2\" >Cheng, Myra, Tiziano Piccardi, and Diyi Yang, “CoMPosT: Characterizing\n",
       "and Evaluating Caricature in LLM Simulations,” ArXiv, 2023, abs/2310.11501.\n",
       "Chickering,\n",
       "David Maxwell, “Optimal structure identification with greedy\n",
       "search,” Journal of machine learning research, 2002, 3 (Nov), 507–554.\n",
       "Cinelli, Carlos, Andrew Forney, and Judea Pearl, “A crash course in good\n",
       "and bad controls,” Sociological Methods & Research, 2022, p. 00491241221099552.\n",
       "Engzell, Per, “A universe of uncertainty hiding in plain sight,” Proceedings of the\n",
       "National Academy of Sciences, 2023, 120 (2), e2218530120.\n",
       "Enke, Benjamin and Cassidy Shubatt, “Quantifying Lottery Choice Complex-\n",
       "ity,” Working Paper 31677, National Bureau of Economic Research September\n",
       "2023.\n",
       "Fish, Sara, Paul G¨olz, David C Parkes, Ariel D Procaccia, Gili Rusak, Itai\n",
       "Shapira, and Manuel W¨uthrich, “Generative Social Choice,” arXiv preprint\n",
       "arXiv:2309.01291, 2023.\n",
       "Girotra, Karan, Lennart Meincke, Christian Terwiesch, and Karl T Ul-\n",
       "rich, “Ideas are dimes a dozen: Large language models for idea generation in\n",
       "innovation,” Available at SSRN 4526071, 2023.\n",
       "Gurnee, Wes and Max Tegmark, “Language Models Represent Space and Time,”\n",
       "2023.\n",
       "Haavelmo, Trygve, “The statistical implications of a system of simultaneous equa-\n",
       "tions,” Econometrica, Journal of the Econometric Society, 1943, pp. 1–12.\n",
       ", “The probability approach in econometrics,” Econometrica:\n",
       "Journal of the\n",
       "Econometric Society, 1944, pp. iii–115.\n",
       "Handel, Benjamin and Joshua Schwartzstein, “Frictions or Mental Gaps:\n",
       "What’s Behind the Information We (Don’t) Use and When Do We Care?,” Journal\n",
       "of Economic Perspectives, February 2018, 32 (1), 155–178.\n",
       "33\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_e7c34_row33_col0\" class=\"data row33 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row33_col1\" class=\"data row33 col1\" >34</td>\n",
       "      <td id=\"T_e7c34_row33_col2\" class=\"data row33 col2\" >Hern´an, Miguel A. and James M. Robins, Causal Inference: What If, Boca\n",
       "Raton: Chapman & Hall/CRC, 2020.\n",
       "Horton, John J, “Large language models as simulated economic agents: What\n",
       "can we learn from homo silicus?,” Technical Report, National Bureau of Economic\n",
       "Research 2023.\n",
       "Imai, Kosuke, Dustin Tingley, and Teppei Yamamoto, “Experimental De-\n",
       "signs for Identifying Causal Mechanisms,” Journal of the Royal Statistical Society\n",
       "Series A: Statistics in Society, 11 2012, 176 (1), 5–51.\n",
       "Jahani, Eaman, Samuel P. Fraiberger, Michael Bailey, and Dean Eckles,\n",
       "“Long ties, disruptive life events, and economic prosperity,” Proceedings of the\n",
       "National Academy of Sciences, 2023, 120 (28), e2211062120.\n",
       "Jumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael\n",
       "Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates,\n",
       "Augustin ˇZ´ıdek, Anna Potapenko et al., “Highly accurate protein structure\n",
       "prediction with AlphaFold,” Nature, 2021, 596 (7873), 583–589.\n",
       "J¨oreskog, Karl G., “A GENERAL METHOD FOR ESTIMATING A LINEAR\n",
       "STRUCTURAL EQUATION SYSTEM*,” ETS Research Bulletin Series, 1970,\n",
       "1970 (2), i–41.\n",
       "Lerner, Jennifer S., Deborah A. Small, and George Loewenstein, “Heart\n",
       "Strings and Purse Strings: Carryover Effects of Emotions on Economic Decisions,”\n",
       "Psychological Science, 2004, 15 (5), 337–341. PMID: 15102144.\n",
       "Li, Peiyao, Noah Castelo, Zsolt Katona, and Miklos Sarvary, “Frontiers:\n",
       "Determining the Validity of Large Language Models for Automated Perceptual\n",
       "Analysis,” Marketing Science, 2024, 0 (0), null.\n",
       "Ludwig, Jens and Sendhil Mullainathan, “Machine Learning as a Tool for\n",
       "Hypothesis Generation,” Working Paper 31017, National Bureau of Economic Re-\n",
       "search March 2023.\n",
       "34\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_e7c34_row34_col0\" class=\"data row34 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row34_col1\" class=\"data row34 col1\" >35</td>\n",
       "      <td id=\"T_e7c34_row34_col2\" class=\"data row34 col2\" >Maskin, Eric S. and John G. Riley, “Auction Theory with Private Values,” The\n",
       "American Economic Review, 1985, 75 (2), 150–155.\n",
       "Mastroianni, Adam M., Daniel T. Gilbert, Gus Cooney, and Timothy D.\n",
       "Wilson, “Do conversations end when people want them to?,” Proceedings of the\n",
       "National Academy of Sciences, 2021, 118 (10), e2011809118.\n",
       "Mei, Qiaozhu, Yutong Xie, Walter Yuan, and Matthew O. Jackson, “A Tur-\n",
       "ing test of whether AI chatbots are behaviorally similar to humans,” Proceedings\n",
       "of the National Academy of Sciences, 2024, 121 (9), e2313925121.\n",
       "Merchant, Amil, Simon Batzner, Samuel S Schoenholz, Muratahan Aykol,\n",
       "Gowoon Cheon, and Ekin Dogus Cubuk, “Scaling deep learning for materials\n",
       "discovery,” Nature, 2023, pp. 1–6.\n",
       "Mullainathan, Sendhil and Ashesh Rambachan, “From Predictive Algorithms\n",
       "to Automatic Generation of Anomalies,” Technical Report May 2023. Available at:\n",
       "https://ssrn.com/abstract=4443738 or http://dx.doi.org/10.2139/ssrn.\n",
       "4443738.\n",
       "Park, Joon Sung, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Mor-\n",
       "ris, Percy Liang, and Michael S Bernstein, “Generative agents: Interactive\n",
       "simulacra of human behavior,” arXiv preprint arXiv:2304.03442, 2023.\n",
       "Patel, R. and E. Pavlick, “Mapping language models to grounded conceptual\n",
       "spaces,” in “Proceedings of the International Conference on Learning Representa-\n",
       "tions” 2021, p. 79.\n",
       "Pearl, J., M. Glymour, and N.P. Jewell, Causal Inference in Statistics: A\n",
       "Primer, Wiley, 2016.\n",
       "Pearl, Judea, “Causal inference in statistics: An overview,” Statistics Surveys,\n",
       "2009, 3 (none), 96 – 146.\n",
       ", Causality, Cambridge university press, 2009.\n",
       "35\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_e7c34_row35_col0\" class=\"data row35 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row35_col1\" class=\"data row35 col1\" >36</td>\n",
       "      <td id=\"T_e7c34_row35_col2\" class=\"data row35 col2\" >Peterson, Joshua C., David D. Bourgin, Mayank Agrawal, Daniel Reich-\n",
       "man, and Thomas L. Griffiths, “Using large-scale experiments and machine\n",
       "learning to discover theories of human decision-making,” Science, 2021, 372 (6547),\n",
       "1209–1214.\n",
       "Rajkumar, Karthik, Guillaume Saint-Jacques, Iavor Bojinov, Erik Bryn-\n",
       "jolfsson, and Sinan Aral, “A causal test of the strength of weak ties,” Science,\n",
       "2022, 377 (6612), 1304–1310.\n",
       "Rosenbusch, Hannes, Claire E. Stevenson, and Han L. J. van der Maas,\n",
       "“How Accurate are GPT-3’s Hypotheses About Social Science Phenomena?,” Dig-\n",
       "ital Society, July 2023, 2 (2), 26.\n",
       "Rosseel, Yves, “lavaan: An R Package for Structural Equation Modeling,” Journal\n",
       "of Statistical Software, 2012, 48 (2), 1–36.\n",
       "Sacerdote, Bruce, “Peer Effects with Random Assignment: Results for Dartmouth\n",
       "Roommates*,” The Quarterly Journal of Economics, 05 2001, 116 (2), 681–704.\n",
       "Salganik, Matthew J., Ian Lundberg, Alexander T. Kindel, Caitlin E.\n",
       "Ahearn, Khaled Al-Ghoneim, Abdullah Almaatouq, Drew M. Altschul,\n",
       "Jennie E. Brand, Nicole Bohme Carnegie, Ryan James Compton,\n",
       "Debanjan Datta, Thomas Davidson, Anna Filippova, Connor Gilroy,\n",
       "Brian J. Goode,\n",
       "Eaman Jahani,\n",
       "Ridhi Kashyap,\n",
       "Antje Kirchner,\n",
       "Stephen McKay, Allison C. Morgan, Alex Pentland, Kivan Polimis,\n",
       "Louis Raes, Daniel E. Rigobon, Claudia V. Roberts, Diana M. Stanescu,\n",
       "Yoshihiko Suhara, Adaner Usmani, Erik H. Wang, Muna Adem, Ab-\n",
       "dulla Alhajri, Bedoor AlShebli, Redwane Amin, Ryan B. Amos, Lisa P.\n",
       "Argyle, Livia Baer-Bositis, Moritz B¨uchi, Bo-Ryehn Chung, William\n",
       "Eggert, Gregory Faletto, Zhilin Fan, Jeremy Freese, Tejomay Gadgil,\n",
       "Josh Gagn´e, Yue Gao, Andrew Halpern-Manners, Sonia P. Hashim, So-\n",
       "nia Hausen, Guanhua He, Kimberly Higuera, Bernie Hogan, Ilana M.\n",
       "Horwitz, Lisa M. Hummel, Naman Jain, Kun Jin, David Jurgens,\n",
       "36\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_e7c34_row36_col0\" class=\"data row36 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row36_col1\" class=\"data row36 col1\" >37</td>\n",
       "      <td id=\"T_e7c34_row36_col2\" class=\"data row36 col2\" >Patrick Kaminski, Areg Karapetyan, E. H. Kim, Ben Leizman, Naijia\n",
       "Liu, Malte M¨oser, Andrew E. Mack, Mayank Mahajan, Noah Man-\n",
       "dell, Helge Marahrens, Diana Mercado-Garcia, Viola Mocz, Katari-\n",
       "ina Mueller-Gastell, Ahmed Musse, Qiankun Niu, William Nowak,\n",
       "Hamidreza Omidvar, Andrew Or, Karen Ouyang, Katy M. Pinto,\n",
       "Ethan Porter, Kristin E. Porter, Crystal Qian, Tamkinat Rauf, Anahit\n",
       "Sargsyan, Thomas Schaffner, Landon Schnabel, Bryan Schonfeld, Ben\n",
       "Sender, Jonathan D. Tang, Emma Tsurkov, Austin van Loon, Onur\n",
       "Varol, Xiafei Wang, Zhi Wang, Julia Wang, Flora Wang, Saman-\n",
       "tha Weissman, Kirstie Whitaker, Maria K. Wolters, Wei Lee Woon,\n",
       "James Wu, Catherine Wu, Kengran Yang, Jingwen Yin, Bingyu Zhao,\n",
       "Chenyun Zhu, Jeanne Brooks-Gunn, Barbara E. Engelhardt, Moritz\n",
       "Hardt, Dean Knox, Karen Levy, Arvind Narayanan, Brandon M. Stew-\n",
       "art, Duncan J. Watts, and Sara McLanahan, “Measuring the predictability\n",
       "of life outcomes with a scientific mass collaboration,” Proceedings of the National\n",
       "Academy of Sciences, 2020, 117 (15), 8398–8403.\n",
       "Santurkar, Shibani, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang,\n",
       "and Tatsunori Hashimoto, “Whose Opinions Do Language Models Reflect?,”\n",
       "2023.\n",
       "Schelling, Thomas C, “Models of segregation,” The American economic review,\n",
       "1969, 59 (2), 488–493.\n",
       ", “Dynamic models of segregation,” Journal of mathematical sociology, 1971, 1 (2),\n",
       "143–186.\n",
       "Scherrer, Nino, Claudia Shi, Amir Feder, and David Blei, “Evaluating the\n",
       "moral beliefs encoded in llms,” Advances in Neural Information Processing Sys-\n",
       "tems, 2024, 36.\n",
       "Simon, Herbert A., The Sciences of the Artificial, 3rd Edition number 0262691914.\n",
       "In ‘MIT Press Books.’, The MIT Press, September 1996.\n",
       "37\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_e7c34_row37_col0\" class=\"data row37 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row37_col1\" class=\"data row37 col1\" >38</td>\n",
       "      <td id=\"T_e7c34_row37_col2\" class=\"data row37 col2\" >Turing, A. M., “On Computable Numbers, with an Application to the Entschei-\n",
       "dungsproblem,” Proceedings of the London Mathematical Society, 1937, s2-42 (1),\n",
       "230–265.\n",
       "T¨ornberg, Petter, Diliara Valeeva, Justus Uitermark, and Christopher\n",
       "Bail, “Simulating Social Media Using Large Language Models to Evaluate Alter-\n",
       "native News Feed Algorithms,” 2023.\n",
       "Wager, Stefan and Susan Athey, “Estimation and Inference of Heterogeneous\n",
       "Treatment Effects using Random Forests,” Journal of the American Statistical\n",
       "Association, 2018, 113 (523), 1228–1242.\n",
       "Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi,\n",
       "Quoc Le, and Denny Zhou, “Chain of Thought Prompting Elicits Reasoning\n",
       "in Large Language Models,” CoRR, 2022, abs/2201.11903.\n",
       "Wright, Sewall, “The method of path coefficients,” The annals of mathematical\n",
       "statistics, 1934, 5 (3), 161–215.\n",
       "Zheng, Stephan, Alexander Trott, Sunil Srinivasa, David C Parkes, and\n",
       "Richard Socher, “The AI Economist: Taxation policy design via two-level deep\n",
       "multiagent reinforcement learning,” Science advances, 2022, 8 (18), eabk2607.\n",
       "38\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_e7c34_row38_col0\" class=\"data row38 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row38_col1\" class=\"data row38 col1\" >39</td>\n",
       "      <td id=\"T_e7c34_row38_col2\" class=\"data row38 col2\" >A\n",
       "Implementation details\n",
       "The first step in the system’s process is to query an LLM for the roles of the relevant\n",
       "agents in the scenario. When we say “query an LLM,” we mean this quite literally.\n",
       "We have written a scenario-neutral prompt that the system provides to an LLM with\n",
       "the scenario added to the prompt. The prompt is scenario-neutral because we can\n",
       "reuse it for any scenario. The prompt takes the following format:\n",
       "In the following scenario: “{scenario description}”, Who are the in-\n",
       "dividual human agents in a simple simulation of this scenario?\n",
       "where {scenario description} is replaced with the scenario of interest. The LLM\n",
       "then returns a list of agents relevant to the scenario, and we have various checking\n",
       "mechanisms to ensure the LLM’s response is valid.\n",
       "The system contains over 50 pre-written scenario-neutral prompts to gather all\n",
       "the information needed to generate the SCM, run the experiment, and analyze the\n",
       "results. These prompts have placeholders for the necessary information aggregated\n",
       "in the system’s memory as it progresses through the different parts of the process.\n",
       "A.1\n",
       "Constructing variables and drawing causal paths\n",
       "The system builds SCMs variable-by-variable. It queries an LLM for an outcome\n",
       "involving the agents in the social scenario of interest.\n",
       "We refer to outcomes as\n",
       "endogenous variables because their values are realized during the experiment. This\n",
       "contrasts exogenous variables, the causes, whose values are determined before the\n",
       "experiment.\n",
       "The system queries the LLM for a list of possible exogenous causes of the en-\n",
       "dogenous variable, generating a hypothesis as an SCM.27 Exogenous variables serve\n",
       "as inputs to the experiment, whose values can be deterministically manipulated to\n",
       "identify causal effects. The system assumes that when an exogenous variable causes\n",
       "an endogenous variable, a single causal path is proposed from the exogenous variable\n",
       "27There is growing evidence that LLMs can be quite good at coming up with ideas and generating\n",
       "hypotheses (Girotra et al., 2023; Rosenbusch et al., 2023).\n",
       "39\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_e7c34_row39_col0\" class=\"data row39 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row39_col1\" class=\"data row39 col1\" >40</td>\n",
       "      <td id=\"T_e7c34_row39_col2\" class=\"data row39 col2\" >to the endogenous variable. More formally, the system always generates SCMs as a\n",
       "simple linear model. The system currently generates all SCMs with one endogenous\n",
       "variable and as many exogenous causes as a researcher desires. We do little optimiza-\n",
       "tion here, although the system can test for interaction terms. In future iterations\n",
       "of the system, a researcher could choose outcomes and causes they are interested\n",
       "in, score hypotheses by interestingness, and generate more complex hypotheses with\n",
       "mediating endogenous variables.28\n",
       "A.1.1\n",
       "Endogenous outcomes\n",
       "For each endogenous variable, the system generates an operationalization, a type, the\n",
       "units, the possible levels, the explicit questions that need to be asked to measure the\n",
       "variable’s realized value, and how the answers to those questions will be aggregated\n",
       "to get the final data for analysis. Examples of all information collected about the\n",
       "variables in an SCM are provided in Table A.3. Each piece of information about a\n",
       "variable is stored by the system and is then used to determine subsequent informa-\n",
       "tion in consecutive scenario-neutral prompts. This is a kind of “chain-of-thoughts\n",
       "prompting”, or the process of breaking down a complex prompt into a series of sim-\n",
       "pler prompts. This method can dramatically improve the quality and robustness of\n",
       "an LLM’s performance (Wei et al., 2022).\n",
       "The first piece of information determined for each endogenous variable is the\n",
       "operationalization. That is, how the possible realizations of said variable can be\n",
       "directly mapped to measurable outcomes that can be observed and quantified. Sup-\n",
       "pose the outcome variable is whether or not a deal occurred from the SCM in\n",
       "Figure 2b.29 The system could operationalize this as a binary variable, where ‘‘1’’\n",
       "means a deal occurred and ‘‘0’’ does not. It then stores this information and\n",
       "uses it in a scenario-neutral prompt to choose the variable type.\n",
       "All variables are determined to be one of five mutually exclusive “types.” These\n",
       "28Parallel and crossover experimental designs can be used to identify mediating causal relation-\n",
       "ships (Imai et al., 2012). These experiments require few assumptions, which are often more plausible\n",
       "when researchers have more control over the experiment, as they usually do with LLMs.\n",
       "29We continue the practice from Section 2 of using typewriter text to denote example infor-\n",
       "mation from the system.\n",
       "40\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_e7c34_row40_col0\" class=\"data row40 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row40_col1\" class=\"data row40 col1\" >41</td>\n",
       "      <td id=\"T_e7c34_row40_col2\" class=\"data row40 col2\" >are continuous, ordinal, nominal, binary, or count. By selecting a unique type for\n",
       "each variable, the system can accommodate different distributions when estimating\n",
       "the fitted SCM after the experiment.\n",
       "Each variable also has units. The units are the specific measure or standard used\n",
       "to represent the variable’s quantified value. This information is used to improve the\n",
       "robustness and consistency of the system’s output when querying the LLM for other\n",
       "information about a variable.\n",
       "The levels of the variable represent all of the values the variable can realize in\n",
       "a short list. They can take on different forms depending on the variable type, but\n",
       "they all follow a general pattern where they are defined by the range and nature of\n",
       "a variable’s possible values.30\n",
       "To measure the endogenous outcome, the system generates survey questions for\n",
       "one of the agents.\n",
       "For example, to measure whether or not a deal occurred,\n",
       "the system could ask the buyer or the seller, “Did you agree to buy the mug?”\n",
       "Or, if the endogenous variable was the final price of the mug, the system could\n",
       "ask one of the agents, “How much did you sell the mug for?” Even though the\n",
       "simulations have yet to be conducted, the system generates survey questions. As\n",
       "with pre-registration, this reduces unneeded degrees of freedom in the data collection\n",
       "process after the experiment.\n",
       "Most endogenous variables are measured with only one question. In this case,\n",
       "the answer to this question is the only information needed to quantify the variable.\n",
       "Sometimes, it takes more than one survey question to measure a variable. Maybe the\n",
       "variable is the average satisfaction of the buyer and the seller; a variable\n",
       "that requires two separate measurements to quantify. In this case, the system gener-\n",
       "ates separate measurement questions to elicit the buyer’s and the seller’s satisfaction.\n",
       "Then, the system averages the answers to the questions to measure the variable.\n",
       "30For binary variables, the levels are the two possible outcomes. For ordinal variables, the levels\n",
       "include all possible values that the ordinal variable could take on as determined by its operational-\n",
       "ization.\n",
       "The levels are selected for count and continuous variables by segmenting the range of\n",
       "possible values into discrete intervals. In cases where the variable does not have a defined maxi-\n",
       "mum or minimum, categories such as “above X” or “below Y” are included to ensure all possible\n",
       "values are covered.\n",
       "41\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_e7c34_row41_col0\" class=\"data row41 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row41_col1\" class=\"data row41 col1\" >42</td>\n",
       "      <td id=\"T_e7c34_row41_col2\" class=\"data row41 col2\" >We pre-programmed a menu of 6 mechanical aggregation methods: finding the\n",
       "minimum, maximum, average, mode, median, or sum of a list of values. If the system\n",
       "needs to combine the answers to multiple questions to measure a variable, it queries\n",
       "an LLM to select the appropriate aggregation method. Then, the system uses a\n",
       "pre-written Python function to perform said aggregation. We refrain from asking\n",
       "the LLM to perform mathematical functions whenever possible, as they often make\n",
       "mistakes.\n",
       "A.1.2\n",
       "Exogenous causes\n",
       "Besides the explicit measurement questions and data aggregation method, the system\n",
       "collects the same information for the exogenous variables as it does for the endogenous\n",
       "variables. For exogenous variables, these two pieces of information are unnecessary\n",
       "for measurement. In each simulation of the social scenario, a different combination\n",
       "of the values of the exogenous variables is initialized. This is how the system induces\n",
       "variation in an experiment, so the treatments are always known to the system ex-\n",
       "ante.\n",
       "Causal variables can have one of two possible “scopes.” The scope can be specific\n",
       "to an individual agent or the scenario as a whole. This scope determines how the\n",
       "system induces variation in the exogenous variables—at the agent or scenario level.\n",
       "Individual-level variables are further designated as either public or private. If private,\n",
       "the variable’s values are only provided to one agent; if public, they are treated as\n",
       "common knowledge to all agents in the scenario.\n",
       "The system induces variation in the exogenous variables by transforming them\n",
       "into manageable proxy attributes for the agents. The system queries an LLM to cre-\n",
       "ate a second-person phrasing of the operationalized variable provided to the agent\n",
       "(or agents, depending on the scope). For instance, with the buyer’s budget vari-\n",
       "able, the attribute could be “your budget” for the buyer. These attributes will be\n",
       "assigned to the agents, which we discuss in Section A.2.\n",
       "With the proxy attribute for the variable, the system queries an LLM for possible\n",
       "values the attribute can take on. These are the induced variations—the treatment\n",
       "42\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_e7c34_row42_col0\" class=\"data row42 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row42_col1\" class=\"data row42 col1\" >43</td>\n",
       "      <td id=\"T_e7c34_row42_col2\" class=\"data row42 col2\" >conditions for the simulated experiments. By default, the system uses the levels, or a\n",
       "value within each level, of the variable for the possible variation values. For example,\n",
       "these could be {$5, $10, $20, $40} for the buyer’s budget.\n",
       "A.2\n",
       "Building hypothesis-driven agents\n",
       "In conventional social science research, human subjects are catch as catch can. Here,\n",
       "we have to construct them from scratch. By “construct” we mean that we prompt\n",
       "an LLM to be a person with a set of attributes. This is quite literal; for example,\n",
       "we could construct an agent in a negotiating scenario with the following prompt:\n",
       "“You are a buyer in a negotiation scenario with a seller. You are negoti-\n",
       "ating over a mug. You have a budget of $20.”\n",
       "We can construct an agent with any set of attributes we want, which raises the\n",
       "question of what attributes we should use.\n",
       "We already have the attributes that will be varied to test the SCM, but there are\n",
       "many others we could include. Some work has explored the endowing of agents with\n",
       "many different attributes, but it is unclear what is optimal, sufficient, or even neces-\n",
       "sary.31 We take a minimalist approach, endowing our agents with goals, constraints,\n",
       "roles, names, and any relevant proxy attributes for the exogenous variables. In the\n",
       "future, we could integrate large numbers of diverse agents, perhaps constructed to\n",
       "be representative of some specific population.\n",
       "A.2.1\n",
       "Assigning agents attributes\n",
       "The system collects information for agents independently, similar to its one-at-a-time\n",
       "approach with the variables in the SCM. The system randomly selects an agent,\n",
       "31The methods have varied, ranging from endowing agents with interesting attributes (Argyle et\n",
       "al., 2023; Horton, 2023) to using American National Election Study data to create “real” people\n",
       "(T¨ornberg et al., 2023) to demonstrating that endowing demographic information does not nec-\n",
       "essarily represent a population of interest (Atari et al., 2023; Santurkar et al., 2023). There is a\n",
       "balance to be struck. While attributes can provide a rich and nuanced simulation, they can also\n",
       "lead to redundancy, inefficiency, and unexpected interactions. In contrast, too few attributes might\n",
       "result in an oversimplified and unrealistic portrayal of social interactions.\n",
       "43\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_e7c34_row43_col0\" class=\"data row43 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row43_col1\" class=\"data row43 col1\" >44</td>\n",
       "      <td id=\"T_e7c34_row43_col2\" class=\"data row43 col2\" >determines its attributes, and then moves on to the next agent.32 Examples of buyer\n",
       "and seller agents with their attributes are provided in Figure A.1.\n",
       "Figure A.1: Example agents generated by the system for “two people bargaining\n",
       "over a mug”\n",
       "Notes: In all simulations, agents are endowed with a randomly generated name, role, goal, con-\n",
       "straint, and proxy attributes for the exogenous variables. To simulate the experiment for the agents\n",
       "in this figure, the system will generate four versions of the seller and four versions of the buyer,\n",
       "each with one of the values for the exogenously varied attributes (assuming there are four possible\n",
       "values for “Your sentimental attachment”). That is 4 × 4 = 16 treatments.\n",
       "For each agent, the system queries the LLM for a random name. Agents perform\n",
       "better in simulations with identifiers to address one another, although this feature\n",
       "can be disabled. An agent’s name can also be varied as a proposed exogenous cause.\n",
       "The system then queries an LLM again, this time for a goal and then a constraint,\n",
       "which we discuss in the following subsection.\n",
       "Finally, the system cross-checks the values of the proxy attributes between the\n",
       "agents to ensure they overlap appropriately. For example, if the two exogenous vari-\n",
       "ables in the SCM were the buyer’s budget and the seller’s minimum acceptable\n",
       "32The system already has the agent’s roles from the construction of the SCM.\n",
       "44\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_e7c34_row44_col0\" class=\"data row44 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row44_col1\" class=\"data row44 col1\" >45</td>\n",
       "      <td id=\"T_e7c34_row44_col2\" class=\"data row44 col2\" >price, the system would check to make sure that the seller’s minimum acceptable\n",
       "price is not invariably higher than the buyer’s budget. We let the LLM deter-\n",
       "mine if these attribute values overlap appropriately. If any discrepancies are found,\n",
       "the system queries the LLM again to resolve them with new values for the proxy\n",
       "attributes. Otherwise, the simulated experiment would waste time and resources\n",
       "because the induced variations were not supported across reasonable values. For ex-\n",
       "ample, if the buyer’s budget was always below the seller’s minimum acceptable\n",
       "price, then they might never make a deal.\n",
       "A.2.2\n",
       "The importance of agent goals\n",
       "Unlike, say, economic agents, whose goals are expressed via explicit utility func-\n",
       "tions, the LLM agent’s goals are expressed in natural language. In the context of\n",
       "our bargaining scenario, an example goal generated by our system for the seller\n",
       "is to sell the mug at the highest price possible. An example constraint is\n",
       "to not accept a price below your minimum selling price. These goals and\n",
       "constraints are oriented towards value, but they do not have to be; these are merely\n",
       "the ones generated by the system. A constraint could just have easily been do not\n",
       "ruin your reputation with your negotiating partner.\n",
       "We do not take a prescriptive stance on what these goals should be. We let the\n",
       "system decide what is reasonable. These goals can, of course, also be the object of\n",
       "study in their own right; researchers can vary them or choose their own, but they\n",
       "are seemingly fundamental to any social science for reasons laid out in Simon (1996).\n",
       "Therefore, explicit goals are a requirement for agents in our system.\n",
       "A.3\n",
       "Simulation design and execution\n",
       "LLMs are designed to produce text. And since an independent LLM powers each\n",
       "agent, one agent must finish speaking before the next begins. So, in any multi-agent\n",
       "simulation, there must be a speaking order, which raises the question of how the\n",
       "system should determine this speaking order. Unfortunately, most human conver-\n",
       "sations do not have an obvious order; people collectively figure out how to interact.\n",
       "45\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_e7c34_row45_col0\" class=\"data row45 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row45_col1\" class=\"data row45 col1\" >46</td>\n",
       "      <td id=\"T_e7c34_row45_col2\" class=\"data row45 col2\" >We centralize this process, but we could imagine a consensus protocol for who speaks\n",
       "next.\n",
       "In more straightforward settings with only two agents (e.g., two people bargaining\n",
       "over a mug), the only possible conversational order is for the agents to alternate\n",
       "speaking. As the number of agents in interaction increases beyond two, the number\n",
       "of possible speaking orders grows factorially. For example, with three agents, there\n",
       "are 3! = 6 ways to order them; with 4 agents, 4! = 24 orderings, and so on. However,\n",
       "the number of possible orderings of the agents is only part of the complexity.\n",
       "Who speaks next in a given conversation is a product of the participants’ per-\n",
       "sonalities, the setting of the conversation, the social dynamics between the speakers,\n",
       "the emotional state of the participants, and many other factors.\n",
       "They are also\n",
       "adaptive—often, the speaking order changes throughout a conversation. For exam-\n",
       "ple, in a court proceeding, the judge usually guides the interaction—signaling who\n",
       "speaks between the lawyers, witnesses, and the jury. Each contributes at various\n",
       "and irregular intervals depending on both the type and stage of the proceeding. In a\n",
       "family of two parents and two children, the order of who speaks next varies greatly.\n",
       "It might depend on the parents’ moods or how annoying the children have been that\n",
       "day. In contrast, the teacher is typically the main speaker in a high school classroom,\n",
       "although this varies depending on the classroom activity, such as a lecture versus a\n",
       "group discussion. No simple universal formula exists for who speaks next in such\n",
       "diverse settings.\n",
       "Like the aggregation methods for outcomes determined by multiple measurement\n",
       "questions, we designed a menu of six interaction protocols. The system queries an\n",
       "LLM to select the appropriate protocol for a given scenario. Figure A.2 provides the\n",
       "menu, and we discuss each in turn.\n",
       "A.3.1\n",
       "Turn-taking protocols\n",
       "The first interaction protocol is the ordered protocol (Figure A.2, option 1), where\n",
       "the agents speak in a predetermined order and continue repeatedly speaking in that\n",
       "order until the simulation is complete. Next is the random protocol. An agent is\n",
       "46\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_e7c34_row46_col0\" class=\"data row46 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row46_col1\" class=\"data row46 col1\" >47</td>\n",
       "      <td id=\"T_e7c34_row46_col2\" class=\"data row46 col2\" >Figure A.2: Menu of interaction protocols for the system to choose from for a given\n",
       "scenario.\n",
       "Notes: (1) The agents speak in a predetermined order. (2) The agents speak in a random order. (3)\n",
       "A central agent alternates speaking with non-central agents in a predetermined order. (4) A central\n",
       "agent alternates speaking with non-central agents in random order. (5) A separate LLM (whom\n",
       "we call the coordinator) determines who speaks next based on the conversation. (6) Each agent\n",
       "responds privately to the conversation so far, and the coordinator realizes one of the responses.\n",
       "randomly selected to speak first (Figure A.2, option 2).\n",
       "Then, each subsequent\n",
       "speaker is randomly selected, with the only restriction being that no agent can speak\n",
       "twice in a row.\n",
       "In more complex scenarios with a central agent—an agent that speaks more than\n",
       "all others—like an auction with an auctioneer or a teacher in a classroom, the system\n",
       "can choose the central-ordered or central-random protocols (Figure A.2, options\n",
       "3 and 4). The former features a central agent who interacts alternately with a series\n",
       "of non-central agents, following a predetermined order among the non-central agents.\n",
       "The latter also has a central agent alternating with the non-central agents but in\n",
       "random order. Whenever there is an order of agents or a central agent, we also query\n",
       "47\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_e7c34_row47_col0\" class=\"data row47 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row47_col1\" class=\"data row47 col1\" >48</td>\n",
       "      <td id=\"T_e7c34_row47_col2\" class=\"data row47 col2\" >the system to determine this order.\n",
       "Finally, we designed two interaction protocols that provide more flexibility. These\n",
       "interaction protocols involve a separate LLM-powered agent: “the coordinator.” The\n",
       "coordinator can read through transcripts of the conversations and make decisions\n",
       "about the simulations when necessary. It can also answer measurement questions\n",
       "after the experiment. The agents are not aware of the coordinator. The use of the\n",
       "coordinator is the only part of the system that needs quasi-omniscient supervision.\n",
       "Fortunately, LLMs perform so well that they can be used to automate this role.\n",
       "In the coordinator-before protocol (Figure A.2, option 5), the coordinator is\n",
       "given the transcript of the conversation after each agent speaks. Then, it selects the\n",
       "next speaker.\n",
       "In the coordinator-after protocol (Figure A.2, option 6), after each agent\n",
       "speaks, all the agents respond, but only the coordinator can see the responses along\n",
       "with the transcript of the conversation up to that point.\n",
       "Then, the coordinator\n",
       "chooses the response to “realize” as the real response.\n",
       "The realized response is\n",
       "added to the conversation’s transcript, and the rest are deleted as if they had never\n",
       "been made. The only limitation in either of the coordinator protocols is that no\n",
       "agent can speak twice in a row.\n",
       "A.3.2\n",
       "Executing the experimental simulations\n",
       "The system runs each experimental simulation in parallel, subject to the computa-\n",
       "tional constraints of the researcher’s machine. When the exogenous variable’s values\n",
       "present too many combinations to sample from, a subset is randomly selected. In\n",
       "every simulation, agents are provided with a description of the scenario, their unique\n",
       "private attributes, the other agents’ roles, any public or scenario-level attributes,\n",
       "and access to the transcript of the conversation. Then, they interact according to\n",
       "the chosen interaction protocol. However, none of the protocols specify when the\n",
       "simulation should end.\n",
       "It is not obvious how to construct an optimal, nor even good, stopping rule.\n",
       "Human conversations are unpredictable and do not always end when we expect them\n",
       "48\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_e7c34_row48_col0\" class=\"data row48 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row48_col1\" class=\"data row48 col1\" >49</td>\n",
       "      <td id=\"T_e7c34_row48_col2\" class=\"data row48 col2\" >to or want them to (Mastroianni et al., 2021). An analogous issue is the halting\n",
       "problem in computer science, which is the problem of determining when, if ever,\n",
       "an arbitrary computer program will stop. Turing (1937) proved that no universal\n",
       "algorithm exists to solve the halting problem.\n",
       "We implemented a two-tier mechanism to determine when to stop each simulation.\n",
       "These apply to all interaction protocols. After each agent speaks, the coordinator\n",
       "receives the transcript and decides if the conversation should continue—a yes or no\n",
       "decision. Additionally, simulations are limited to 20 statements across all agents in\n",
       "the scenario, not including the coordinator.33 Agents are provided a live count of\n",
       "the remaining statements during the conversation.\n",
       "A.3.3\n",
       "Post-simulation survey and data collection\n",
       "After the experiment, the system conducts a post-experiment survey. As determined\n",
       "during the SCM construction, the system asks the relevant agents or the coordinator\n",
       "the survey questions to measure the outcome variable in each simulation. The system\n",
       "then takes this question’s raw answer and saves it as an observation along with the\n",
       "values of the exogenous variables. If there is no reasonable answer to the question,\n",
       "say, if the outcome is conditional, then the system will report an NA for the variable’s\n",
       "value.\n",
       "Once the system has the answer to the survey question, it queries an LLM with\n",
       "the survey question, the agent’s response, and information about the variable’s type\n",
       "to determine its correct numerical value as a string. If the variable is a count or\n",
       "continuous variable, it is converted into an integer or a float.\n",
       "If the variable is\n",
       "ordinal or binary, the system queries an LLM to map it to a whole-number integer\n",
       "sequence. If multiple survey questions determine a variable, the system aggregates\n",
       "the answers to the questions using the method selected during the SCM construction\n",
       "phase. Then, it converts the aggregated value to the appropriate type. After parsing\n",
       "33Limiting the number of turns in the simulation is partially a convenience. As of the time of\n",
       "running the simulations for this paper, GPT-4 has a maximum token limit of 8,192 tokens, and the\n",
       "system must provide each agent with the entire conversation up to that point each time they need\n",
       "to speak.\n",
       "49\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_e7c34_row49_col0\" class=\"data row49 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row49_col1\" class=\"data row49 col1\" >50</td>\n",
       "      <td id=\"T_e7c34_row49_col2\" class=\"data row49 col2\" >the data for each outcome, the system has a data frame with one column of numerical\n",
       "values for each variable in the SCM.\n",
       "A.4\n",
       "Path estimation & model fit\n",
       "With a complete dataset and the proposed SCM, the system can estimate the linear\n",
       "SCM without further queries to an LLM. The system uses the R package lavaan to\n",
       "estimate all paths in the model (Rosseel, 2012).34 The system can standardize all\n",
       "estimates, estimate interactions and non-linear terms, and view various summary\n",
       "statistics for each variable. It can also provide likelihood ratio, Wald, and Lagrange\n",
       "Multiplier tests to evaluate the model fit and compare path estimates. The system\n",
       "can do any statistical estimation or test that is built into lavaan.\n",
       "A.5\n",
       "Follow-on experiments\n",
       "Although we have not yet automated this process, the system can perform follow-\n",
       "on experiments. Insignificant exogenous variables from the first experiment can be\n",
       "dropped. Then, the system could query an LLM for new exogenous variables based\n",
       "on what might be interesting, given the already tested causal paths. The system\n",
       "would use the same agents and interaction protocol, but the agents would vary\n",
       "on the new exogenous variables and the old ones that were significant in the first\n",
       "experiment. Theoretically, the system can run follow-on experiments ad infinitum,\n",
       "and we can imagine future models that could be very good at proposing potential\n",
       "causal relationships.\n",
       "B\n",
       "Hypotheses as structural causal models\n",
       "Hypotheses stated in natural language can be ambiguous, making it challenging to\n",
       "discern precise implied causal relationships. Suppose a researcher is interested in\n",
       "34For those familiar with lavaan and Python, the system automatically generates the correctly\n",
       "formatted string in lavaan syntax using a Python dictionary that stores the structure of the SCM\n",
       "in key-value pairs.\n",
       "50\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_e7c34_row50_col0\" class=\"data row50 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row50_col1\" class=\"data row50 col1\" >51</td>\n",
       "      <td id=\"T_e7c34_row50_col2\" class=\"data row50 col2\" >Figure A.3: Valid graphical interpretations of the same natural language\n",
       "hypothesis.\n",
       "Buyer\n",
       "Budget\n",
       "Seller\n",
       "Attach\n",
       "Deal\n",
       "Occurs\n",
       "(a) Independent causes\n",
       "Buyer\n",
       "Budget\n",
       "Seller\n",
       "Attach\n",
       "Deal\n",
       "Occurs\n",
       "(b) Mediation\n",
       "Buyer\n",
       "Budget\n",
       "Seller\n",
       "Attach\n",
       "Deal\n",
       "Occurs\n",
       "(c) Alternative mediation\n",
       "Notes: Each directed acyclic graph (DAG) is a valid causal interpretation of the following natu-\n",
       "ral language hypothesis: “The buyer’s budget and the seller’s sentimental attachment to the mug\n",
       "causally affect whether a deal occurs.” In contrast, each DAG is unique in its declaration of the\n",
       "causal relationships. In DAGs, each arrow represents a direct causal relationship, and the absence\n",
       "of an arrow between two variables indicates no causal relationship. If a variable is not included in\n",
       "the graph, then there is no stated causal relationship about this variable. While DAGs are unam-\n",
       "biguous in their causal claims about which variables cause which other variables, they do not make\n",
       "any claims about the functional form of the relationships between variables.\n",
       "two-person bargaining scenarios with a buyer and a seller. And she has the following\n",
       "natural language hypothesis about two people bargaining over a mug: “the buyer’s\n",
       "budget and the seller’s sentimental attachment to the mug causally affect whether\n",
       "a deal occurs.”\n",
       "Figure A.3 offers three ways we can interpret this causal state-\n",
       "ment: (A.3a) the budget and the sentimental attachment could independently affect\n",
       "whether a deal occurs, (A.3b) the budget could mediate the relationship between the\n",
       "attachment and the outcome, or (A.3c), the mediation could be reversed.35\n",
       "For (A.3a), an example could be an online marketplace where the buyer and seller\n",
       "cannot communicate. When the buyer has a higher budget, she is more likely to buy\n",
       "the mug. If the seller is more sentimentally attached to the mug, he may raise the\n",
       "price and, therefore, lower the probability of a deal. However, without any form\n",
       "of communication, these causal variables would not affect each other. For (A.3b),\n",
       "if the buyer and the seller can communicate and the seller realizes that the buyer\n",
       "35This list of interpretations is not exhaustive.\n",
       "51\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_e7c34_row51_col0\" class=\"data row51 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row51_col1\" class=\"data row51 col1\" >52</td>\n",
       "      <td id=\"T_e7c34_row51_col2\" class=\"data row51 col2\" >is willing to spend more, he might become more attached to the mug and value it\n",
       "higher because of the increased potential sale price. Finally, for (A.3c), the mediated\n",
       "relationship could be reversed. If the buyer sees that the seller is attached to the\n",
       "mug, this may cause her to increase her budget, which increases the probability of\n",
       "a deal. The ambiguity of stating even simple hypotheses makes natural language\n",
       "insufficient for our purposes.\n",
       "The graphs in Figure A.3 are directed acyclic graphs (DAGs) and represent causal\n",
       "relationships. DAGs unambiguously state whether a variable is a direct cause of\n",
       "another variable—the direction of the arrow indicates the direction of the causal\n",
       "relationship (Hern´an and Robins, 2020).\n",
       "The absence of an arrow between two\n",
       "variables indicates no causal relationship. If a variable is not included in the graph,\n",
       "then there is no stated causal relationship involving this variable.\n",
       "While DAGs are clear in their claims about which variables cause others, they\n",
       "do not make any statements about the functional form of the relationships between\n",
       "variables. In contrast, structural causal models unambiguously state the causal re-\n",
       "lationships between variables and the functional forms of these relationships (Pearl\n",
       "et al., 2016).\n",
       "Structural causal models (SCM), as first explored by Wright (1934), represent\n",
       "hypotheses as sets of equations. Suppose we assume the relationships between the\n",
       "variables in Figure A.3 are linear. We can write an SCM for each of the DAGs.\n",
       "Figure A.3a can be stated as:\n",
       "DealOccurs = β1BuyerBudget + β2SellerAttachment + ϵ;\n",
       "(1)\n",
       "Figure A.3b as:\n",
       "BuyerBudget = β0SellerAttachment + η\n",
       "(2)\n",
       "DealOccurs = β1BuyerBudget + β2SellerAttachment + ϵ;\n",
       "(3)\n",
       "and Figure A.3c as:\n",
       "SellerAttachment = β0BuyerBudget + η\n",
       "(4)\n",
       "DealOccurs = β1BuyerBudget + β2SellerAttachment + ϵ.\n",
       "(5)\n",
       "The set of equations that represent the causal relationships between variables\n",
       "make the SCM. We could also write each SCM with interaction terms for some or\n",
       "52\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_e7c34_row52_col0\" class=\"data row52 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row52_col1\" class=\"data row52 col1\" >53</td>\n",
       "      <td id=\"T_e7c34_row52_col2\" class=\"data row52 col2\" >all of the causes or even use other types of link functions, and these would all be\n",
       "equally valid representations of the corresponding DAGs.\n",
       "53\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_e7c34_row53_col0\" class=\"data row53 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row53_col1\" class=\"data row53 col1\" >54</td>\n",
       "      <td id=\"T_e7c34_row53_col2\" class=\"data row53 col2\" >C\n",
       "Additional figures and tables\n",
       "Figure A.4: Fitted SCM with interaction terms for “two people bargaining over a\n",
       "mug.”\n",
       "deal-for-mug\n",
       "µ = 0.50\n",
       "σ2 = 0.25\n",
       "sell-love-mug\n",
       "µ = 3.00\n",
       "σ2 = 2.00\n",
       "buyers-budget\n",
       "-x-\n",
       "sell-love-mug\n",
       "µ = 36.67\n",
       "σ2 = 826.22\n",
       "buyers-budget\n",
       "-x-\n",
       "sell-min-mug\n",
       "µ = 148.02\n",
       "σ2 = 16787.95\n",
       "sell-min-mug\n",
       "µ = 12.11\n",
       "σ2 = 49.43\n",
       "sell-min-mug\n",
       "-x-\n",
       "sell-love-mug\n",
       "µ = 36.33\n",
       "σ2 = 837.11\n",
       "buyers-budget\n",
       "µ = 12.22\n",
       "σ2 = 47.95\n",
       "0.032\n",
       "(0.007)\n",
       "-0.045\n",
       "(0.007)\n",
       "-0.094\n",
       "(0.032)\n",
       "-0.000\n",
       "(0.000)\n",
       "0.002\n",
       "(0.002)\n",
       "0.004\n",
       "(0.002)\n",
       "Notes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\n",
       "dardized path estimate and standard error. There were 405 simulations with these agents: [‘buyer’,\n",
       "‘seller’].\n",
       "54\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_e7c34_row54_col0\" class=\"data row54 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row54_col1\" class=\"data row54 col1\" >55</td>\n",
       "      <td id=\"T_e7c34_row54_col2\" class=\"data row54 col2\" >Figure A.5: Fitted SCM with interaction terms for “a judge is setting bail for a\n",
       "criminal defendant who committed 50,000 dollars in tax fraud.”\n",
       "bail-amt\n",
       "µ = 54428.57\n",
       "σ2 = 186000000.00\n",
       "num-judge-cases\n",
       "-x-\n",
       "def-remorse\n",
       "µ = 29.57\n",
       "σ2 = 865.10\n",
       "def-crim-hist\n",
       "µ = 4.71\n",
       "σ2 = 17.06\n",
       "def-crim-hist\n",
       "-x-\n",
       "num-judge-cases\n",
       "µ = 46.47\n",
       "σ2 = 4053.35\n",
       "def-crim-hist\n",
       "-x-\n",
       "def-remorse\n",
       "µ = 14.14\n",
       "σ2 = 232.12\n",
       "def-remorse\n",
       "µ = 3.00\n",
       "σ2 = 2.00\n",
       "num-judge-cases\n",
       "µ = 9.86\n",
       "σ2 = 60.98\n",
       "303.4\n",
       "(545.5)\n",
       "383.9\n",
       "(282.6)\n",
       "-29.6\n",
       "(1180.9)\n",
       "-1.301\n",
       "(26.231)\n",
       "77.0\n",
       "(144.8)\n",
       "-150.8\n",
       "(76.6)\n",
       "Notes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\n",
       "dardized path estimate and standard error. There were 245 simulations with these agents: [‘judge’,\n",
       "‘defendant’, ‘defense attorney’, ‘prosecutor’].\n",
       "55\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_e7c34_row55_col0\" class=\"data row55 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row55_col1\" class=\"data row55 col1\" >56</td>\n",
       "      <td id=\"T_e7c34_row55_col2\" class=\"data row55 col2\" >Figure A.6: Fitted SCM with interaction terms for “a person is interviewing for a\n",
       "job as a lawyer.”\n",
       "hire-decision\n",
       "µ = 0.62\n",
       "σ2 = 0.23\n",
       "inter-friendly\n",
       "-x-\n",
       "job-app-height\n",
       "µ = 2130.00\n",
       "σ2 = 1600775.00\n",
       "job-app-height\n",
       "µ = 177.50\n",
       "σ2 = 131.25\n",
       "bar-exam-pass\n",
       "-x-\n",
       "job-app-height\n",
       "µ = 88.75\n",
       "σ2 = 7942.19\n",
       "bar-exam-pass\n",
       "-x-\n",
       "inter-friendly\n",
       "µ = 6.00\n",
       "σ2 = 61.00\n",
       "bar-exam-pass\n",
       "µ = 0.50\n",
       "σ2 = 0.25\n",
       "inter-friendly\n",
       "µ = 12.00\n",
       "σ2 = 50.00\n",
       "1.704\n",
       "(1.053)\n",
       "-0.013\n",
       "(0.074)\n",
       "0.005\n",
       "(0.007)\n",
       "0.005\n",
       "(0.010)\n",
       "-0.006\n",
       "(0.006)\n",
       "0.000\n",
       "(0.000)\n",
       "Notes: Each variable is given with its mean and variance. The edges are labeled with their un-\n",
       "standardized path estimate and standard error. There were 80 simulations with these agents: [‘job\n",
       "applicant’, ‘employer’].\n",
       "56\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_e7c34_row56_col0\" class=\"data row56 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row56_col1\" class=\"data row56 col1\" >57</td>\n",
       "      <td id=\"T_e7c34_row56_col2\" class=\"data row56 col2\" >Figure A.7: Fitted SCM with interaction terms for “3 bidders participating in an\n",
       "auction for a piece of art starting at fifty dollars.”\n",
       "final-art-price\n",
       "µ = 186.53\n",
       "σ2 = 3867.92\n",
       "bid1-max-budget\n",
       "-x-\n",
       "bid2-max-budg\n",
       "µ = 40000.00\n",
       "σ2 = 900000000.00\n",
       "bid1-max-budget\n",
       "µ = 200.00\n",
       "σ2 = 10000.00\n",
       "bid2-max-budg\n",
       "-x-\n",
       "bid3-max-budg\n",
       "µ = 40000.00\n",
       "σ2 = 900000000.00\n",
       "bid3-max-budg\n",
       "µ = 200.00\n",
       "σ2 = 10000.00\n",
       "bid1-max-budget\n",
       "-x-\n",
       "bid3-max-budg\n",
       "µ = 40000.00\n",
       "σ2 = 900000000.00\n",
       "bid2-max-budg\n",
       "µ = 200.00\n",
       "σ2 = 10000.00\n",
       "0.136\n",
       "(0.044)\n",
       "0.120\n",
       "(0.044)\n",
       "0.171\n",
       "(0.044)\n",
       "0.001\n",
       "(0.000)\n",
       "0.000\n",
       "(0.000)\n",
       "0.000\n",
       "(0.000)\n",
       "Notes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\n",
       "dardized path estimate and standard error. There were 343 simulations with these agents: [‘bidder\n",
       "1’, ‘bidder 2’, ‘bidder 3’, ‘auctioneer’].\n",
       "57\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_e7c34_row57_col0\" class=\"data row57 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row57_col1\" class=\"data row57 col1\" >58</td>\n",
       "      <td id=\"T_e7c34_row57_col2\" class=\"data row57 col2\" >Table A.1: GPT-4’s predictions for the path estimates for the experiments in\n",
       "Section 3 at temperature 0.\n",
       "Scenario\n",
       "(Outcome)\n",
       "Exogenous\n",
       "Variable\n",
       "Path\n",
       "Estimate\n",
       "(SE)\n",
       "GPT-4\n",
       "Guess\n",
       "Two-\n",
       "tailed\n",
       "T-Test\n",
       "GPT-4\n",
       "Sign\n",
       "Correct\n",
       "| Predicted\n",
       "Experiment|\n",
       "Estimates\n",
       "Mug\n",
       "Bargaining\n",
       "(Deal Made)\n",
       "Buyer’s\n",
       "Budget\n",
       "0.037*\n",
       "(0.003)\n",
       "0.05*\n",
       "p < 0.001\n",
       "Yes\n",
       "1.35\n",
       "Seller’s Min\n",
       "Price\n",
       "-0.035*\n",
       "(0.002)\n",
       "-0.07*\n",
       "p < 0.001\n",
       "Yes\n",
       "2.00\n",
       "Seller’s\n",
       "Attachment\n",
       "-0.025*\n",
       "(0.012)\n",
       "0.02\n",
       "p < 0.001\n",
       "No\n",
       "0.80\n",
       "Art Auction\n",
       "(Final Price)\n",
       "Bidder 1\n",
       "Budget\n",
       "0.35*\n",
       "(0.015)\n",
       "0.5*\n",
       "p < 0.001\n",
       "Yes\n",
       "1.43\n",
       "Bidder 2\n",
       "Valuation\n",
       "0.29*\n",
       "(0.015)\n",
       "0.5*\n",
       "p < 0.001\n",
       "Yes\n",
       "1.72\n",
       "Bidder 3\n",
       "Valuation\n",
       "0.31*\n",
       "(0.015 )\n",
       "0.5*\n",
       "p < 0.001\n",
       "Yes\n",
       "1.610\n",
       "Bail Hearing\n",
       "(Bail\n",
       "Amount)\n",
       "Defendant’s\n",
       "Previous\n",
       "Convictions\n",
       "521.53*\n",
       "(206.567)\n",
       "5000*\n",
       "p < 0.001\n",
       "Yes\n",
       "9.59\n",
       "Judge Cases\n",
       "That Day\n",
       "-74.632\n",
       "(109.263)\n",
       "-200\n",
       "p = 0.252\n",
       "Yes\n",
       "2.68\n",
       "Defendant’s\n",
       "Remorse\n",
       "-1153.061\n",
       "(603.325)\n",
       "-3000*\n",
       "p = 0.002\n",
       "Yes\n",
       "2.60\n",
       "Lawyer\n",
       "Interview\n",
       "(Gets Job)\n",
       "Passed Bar\n",
       "0.750*\n",
       "(0.068)\n",
       "0.6*\n",
       "p = 0.03\n",
       "Yes\n",
       "0.80\n",
       "Interviewer\n",
       "Friendliness\n",
       "-0.002\n",
       "(0.005)\n",
       "0.2\n",
       "p < 0.001\n",
       "No\n",
       "100.00\n",
       "Applicant’s\n",
       "Height\n",
       "0.003\n",
       "(0.003)\n",
       "0.1\n",
       "p < 0.001\n",
       "Yes\n",
       "33.33\n",
       "Notes: The table provides GPT-4’s prediction for the path estimate for each experiment in Section 3\n",
       "From left to right, column 1 provides the scenario and outcome, column 2 provides the causal variable\n",
       "name, column 3 the path estimate and its standard error, and column 4 shows the LLM’s prediction\n",
       "for the path estimate and whether it was predicted to be statistically significant. Column 5 gives\n",
       "the p-value of a two-tailed t-test comparing the predictions to the results, column 6 is whether the\n",
       "predicted sign of the estimate was correct, and column 7 is the magnitude of the difference between\n",
       "the predicted and actual estimate.\n",
       "58\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_e7c34_row58_col0\" class=\"data row58 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row58_col1\" class=\"data row58 col1\" >59</td>\n",
       "      <td id=\"T_e7c34_row58_col2\" class=\"data row58 col2\" >Table A.2: GPT-4’s predictions for the path estimates for the experiments in\n",
       "Section 3 at temperature 1.\n",
       "Scenario\n",
       "(Outcome)\n",
       "Exogenous\n",
       "Variable\n",
       "Path\n",
       "Estimate\n",
       "(SE)\n",
       "GPT-4\n",
       "Guess\n",
       "Two-\n",
       "tailed\n",
       "T-Test\n",
       "GPT-4\n",
       "Sign\n",
       "Correct\n",
       "(SE)\n",
       "| Predicted\n",
       "Experiment|\n",
       "Estimates\n",
       "Mug\n",
       "Bargaining\n",
       "(Deal Made)\n",
       "Buyer’s\n",
       "Budget\n",
       "0.037*\n",
       "(0.003)\n",
       "0.117*\n",
       "(0.016)\n",
       "p < 0.001\n",
       "Yes\n",
       "3.16\n",
       "Seller’s Min\n",
       "Price\n",
       "-0.035*\n",
       "(0.002)\n",
       "0.008*\n",
       "(0.018)\n",
       "p = 0.019\n",
       "No\n",
       "0.23\n",
       "Seller’s\n",
       "Attachment\n",
       "-0.025*\n",
       "(0.012)\n",
       "0.062\n",
       "(0.013)\n",
       "p < 0.001\n",
       "No\n",
       "2.48\n",
       "Art Auction\n",
       "(Final Price)\n",
       "Bidder 1\n",
       "Budget\n",
       "0.35*\n",
       "(0.015)\n",
       "1.279*\n",
       "(0.501)\n",
       "p = 0.064\n",
       "Yes\n",
       "3.65\n",
       "Bidder 2\n",
       "Valuation\n",
       "0.29*\n",
       "(0.015)\n",
       "1.263*\n",
       "(0.501)\n",
       "p = 0.053\n",
       "Yes\n",
       "4.36\n",
       "Bidder 3\n",
       "Valuation\n",
       "0.31*\n",
       "(0.015 )\n",
       "1.269*\n",
       "(0.501)\n",
       "p = 0.056\n",
       "Yes\n",
       "4.09\n",
       "Bail Hearing\n",
       "(Bail\n",
       "Amount)\n",
       "Defendant’s\n",
       "Previous\n",
       "Convictions\n",
       "521.53*\n",
       "(206.567)\n",
       "1785.192*\n",
       "(157.347)\n",
       "p < 0.001\n",
       "Yes\n",
       "3.42\n",
       "Judge Cases\n",
       "That Day\n",
       "-74.632\n",
       "(109.263)\n",
       "644.316*\n",
       "(79.919)\n",
       "p < 0.001\n",
       "No\n",
       "8.63\n",
       "Defendant’s\n",
       "Remorse\n",
       "-1153.061\n",
       "(603.325)\n",
       "-879.945*\n",
       "(92.700)\n",
       "p = 0.09\n",
       "Yes\n",
       "0.76\n",
       "Lawyer\n",
       "Interview\n",
       "(Gets Job)\n",
       "Passed Bar\n",
       "0.750*\n",
       "(0.068)\n",
       "0.408*\n",
       "(0.018)\n",
       "p = 0.998\n",
       "Yes\n",
       "0.54\n",
       "Interviewer\n",
       "Friendliness\n",
       "-0.002\n",
       "(0.005)\n",
       "0.236*\n",
       "(0.015)\n",
       "p = 0.999\n",
       "No\n",
       "118\n",
       "Applicant’s\n",
       "Height\n",
       "0.003\n",
       "(0.003)\n",
       "0.108\n",
       "(0.009)\n",
       "p = 0.999\n",
       "Yes\n",
       "36\n",
       "Notes: The table provides GPT-4’s prediction for the path estimate for each experiment in Section 3\n",
       "Each prediction is the average of 100 prompts at temperature 1. From left to right, column 1 provides\n",
       "the scenario and outcome, column 2 provides the causal variable name, column 3 the path estimate\n",
       "and its standard error, and column 4 shows the LLM’s average prediction for the path estimate\n",
       "and whether it was predicted to be statistically significant more than 50% of the time. The given\n",
       "standard error is for the mean of the predictions, not the LLM’s prediction for the standard error.\n",
       "Column 5 gives the p-value of a two-tailed t-test comparing the average prediction to the results,\n",
       "column 6 is whether the predicted sign of the estimate was correct more than 50% of the time, and\n",
       "column 7 is the magnitude of the difference between the predicted and actual estimate.\n",
       "59\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_e7c34_row59_col0\" class=\"data row59 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row59_col1\" class=\"data row59 col1\" >60</td>\n",
       "      <td id=\"T_e7c34_row59_col2\" class=\"data row59 col2\" >Figure A.8: Fitted SCM for auction with bidder’s reservation prices and second\n",
       "highest bid as exogenous variables.\n",
       "final-art-price\n",
       "µ = 186.53\n",
       "σ2 = 3867.92\n",
       "bid1-max-budget\n",
       "µ = 200.00\n",
       "σ2 = 10000.00\n",
       "bid2-max-budg\n",
       "µ = 200.00\n",
       "σ2 = 10000.00\n",
       "bid3-max-budg\n",
       "µ = 200.00\n",
       "σ2 = 10000.00\n",
       "2nd-highest-budget\n",
       "µ = 180.99\n",
       "σ2 = 4565.99\n",
       "0.047\n",
       "(0.009)\n",
       "0.039\n",
       "(0.008)\n",
       "0.03\n",
       "(0.009)\n",
       "final-art-price\n",
       "µ = 186.53\n",
       "σ2 = 3867.92\n",
       "0.826\n",
       "(0.018)\n",
       "Notes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\n",
       "dardized path estimate and standard error. There were 343 simulations with these agents: [‘bidder\n",
       "1’, ‘bidder 2’, ‘bidder 3’, ‘auctioneer’].\n",
       "Figure A.9: Fitted SCM for auction and second highest bid as exogenous variables.\n",
       "final-art-price\n",
       "µ = 186.53\n",
       "σ2 = 3867.92\n",
       "2nd-highest-budget\n",
       "µ = 180.99\n",
       "σ2 = 4565.99\n",
       "0.912\n",
       "(0.009)\n",
       "Notes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\n",
       "dardized path estimate and standard error. There were 343 simulations with these agents: [‘bidder\n",
       "1’, ‘bidder 2’, ‘bidder 3’, ‘auctioneer’].\n",
       "60\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "      <td id=\"T_e7c34_row60_col0\" class=\"data row60 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row60_col1\" class=\"data row60 col1\" >61</td>\n",
       "      <td id=\"T_e7c34_row60_col2\" class=\"data row60 col2\" >Figure A.10: Comparison of the LLM’s predictions to the theoretical predictions\n",
       "and all experimental results for the auction scenario.\n",
       "Bidder 3\n",
       "Reservation:\n",
       " 50\n",
       "Bidder 3\n",
       "Reservation:\n",
       " 100\n",
       "Bidder 3\n",
       "Reservation:\n",
       " 150\n",
       "Bidder 3\n",
       "Reservation:\n",
       " 200\n",
       "Bidder 3\n",
       "Reservation:\n",
       " 250\n",
       "Bidder 3\n",
       "Reservation:\n",
       " 300\n",
       "Bidder 3\n",
       "Reservation:\n",
       " 350\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 350\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 300\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 250\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 200\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 150\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 100\n",
       "Bidder 2\n",
       "Reservation:\n",
       " 50\n",
       "100 200 300\n",
       "100 200 300\n",
       "100 200 300\n",
       "100 200 300\n",
       "100 200 300\n",
       "100 200 300\n",
       "100 200 300\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "100\n",
       "200\n",
       "300\n",
       "Bidder 1\n",
       "Reservation Price\n",
       "Final Clearing Price\n",
       "Auction Theory\n",
       "Predict yi | β^\n",
       "Predict yi\n",
       "Experiment\n",
       "Notes: The columns correspond to the different reservation values for bidder 3 in a given simulation,\n",
       "and the rows correspond to the different reservation values for bidder 2. The y-axis is the clearing\n",
       "price, and the x-axis lists bidder 1’s reservation price. The black triangles track the observed clearing\n",
       "price in each simulated experiment, the black line shows the predictions made by auction theory\n",
       "(MSET heory = 128), the blue line indicates the LLM’s predictions without the fitted SCM—the\n",
       "predict-yi task (MSEyi = 8628), and the red curve is the LLM’s predictions with the fitted SCM—\n",
       "the predict-yi|ˆβ−i task (MSEyi| ˆβ−i = 1505).\n",
       "61\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "      <td id=\"T_e7c34_row61_col0\" class=\"data row61 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row61_col1\" class=\"data row61 col1\" >62</td>\n",
       "      <td id=\"T_e7c34_row61_col2\" class=\"data row61 col2\" >Figure A.11: Prompt used to elicity LLM predictions for the Predict-ˆβ task.\n",
       "I have just run an experiment to estimate the paths in the SCM from the\n",
       "TIKZ diagram below, which is delineated by triple backticks.\n",
       "We ran the\n",
       "experiment on multiple instances of GPT-4, once for each combination of the\n",
       "different “Attribute Treatments” in the accompanying table. This table also\n",
       "includes information about the variables and the individual agents involved in\n",
       "the scenario. Your task is to predict the point estimates for the paths in the\n",
       "SCMs as accurately as possible based on the experiments. You can see the\n",
       "summary statistics of the treatment variables below each variable name in the\n",
       "Tikz Diagram. We want to know how good you are at predicting the outcomes\n",
       "of experiments run on you. Make sure you consider the correct units for both\n",
       "the cause and the outcome for each path. Please output your answer in the\n",
       "following form and do not include any other text: {’predictions’: dictionary of\n",
       "point estimate predictions for each path} {’sig’: dictionary of whether or not\n",
       "each path is significant} ‘‘‘Figure X and Table X’’’\n",
       "Notes: For each experiment, we input the accompanying table and the TIKZ diagram into the LLM\n",
       "between the triple backticks. For example, for the bargaining scenario, these are Figure 2b and\n",
       "Table 2a.\n",
       "62\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c34_level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "      <td id=\"T_e7c34_row62_col0\" class=\"data row62 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_e7c34_row62_col1\" class=\"data row62 col1\" >63</td>\n",
       "      <td id=\"T_e7c34_row62_col2\" class=\"data row62 col2\" >Table A.3: Example of the information generated for each variable in an SCM.\n",
       "Information Type\n",
       "Deal Occurred\n",
       "(Endogenous)\n",
       "Buyer’s Budget\n",
       "(Exogenous)\n",
       "Seller’s Attachment\n",
       "(Exogenous)\n",
       "Operationalization\n",
       "1 if a deal\n",
       "occurs, 0\n",
       "otherwise\n",
       "Max amount the\n",
       "buyer will\n",
       "spend\n",
       "Seller’s emotional\n",
       "attachment level\n",
       "on a scale\n",
       "Variable Type\n",
       "Binary\n",
       "Continuous\n",
       "Ordinal\n",
       "Units\n",
       "Binary\n",
       "Dollars\n",
       "Levels of\n",
       "attachment\n",
       "Levels\n",
       "{0, 1}\n",
       "{$0-$5, ...,\n",
       "$40+}\n",
       "{Low, ..., High}\n",
       "Explicit\n",
       "Measurement\n",
       "Questions\n",
       "Buyer:\n",
       "‘‘Did\n",
       "a deal\n",
       "occur?’’\n",
       "-\n",
       "-\n",
       "Data Aggregation\n",
       "Method\n",
       "Single Value\n",
       "-\n",
       "-\n",
       "Scenario or\n",
       "Individual\n",
       "-\n",
       "Individual\n",
       "Individual\n",
       "Varied Attribute\n",
       "Proxies\n",
       "-\n",
       "‘‘Your budget’’\n",
       "‘‘Your attachment\n",
       "level’’\n",
       "Attribute\n",
       "Treatments\n",
       "-\n",
       "{$3, ..., $45}\n",
       "{no attachment,\n",
       "...,\n",
       "extreme attachment}\n",
       "Notes: Each row shows a different piece of information generated for the variables in the SCM.\n",
       "The first column represents the type of information, the second column represents the information\n",
       "for the endogenous variable, and the third and fourth columns represent the information for the\n",
       "exogenous variables. This is example information based on the SCM in Figure A.3a.\n",
       "63\n",
       "</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "ScenarioList([Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 1, 'text': 'Automated Social Science:\\nLanguage Models as Scientist and Subjects∗\\nBenjamin S. Manning†\\nMIT\\nKehang Zhu†\\nHarvard\\nJohn J. Horton\\nMIT & NBER\\nApril 26, 2024\\nAbstract\\nWe present an approach for automatically generating and testing, in silico,\\nsocial scientific hypotheses. This automation is made possible by recent ad-\\nvances in large language models (LLM), but the key feature of the approach\\nis the use of structural causal models. Structural causal models provide a lan-\\nguage to state hypotheses, a blueprint for constructing LLM-based agents, an\\nexperimental design, and a plan for data analysis. The fitted structural causal\\nmodel becomes an object available for prediction or the planning of follow-on\\nexperiments. We demonstrate the approach with several scenarios: a nego-\\ntiation, a bail hearing, a job interview, and an auction. In each case, causal\\nrelationships are both proposed and tested by the system, finding evidence\\nfor some and not others. We provide evidence that the insights from these\\nsimulations of social interactions are not available to the LLM purely through\\ndirect elicitation. When given its proposed structural causal model for each\\nscenario, the LLM is good at predicting the signs of estimated effects, but\\nit cannot reliably predict the magnitudes of those estimates. In the auction\\nexperiment, the in silico simulation results closely match the predictions of\\nauction theory, but elicited predictions of the clearing prices from the LLM\\nare inaccurate. However, the LLM’s predictions are dramatically improved if\\nthe model can condition on the fitted structural causal model. In short, the\\nLLM knows more than it can (immediately) tell.\\n∗Thanks to generous support from Drew Houston and his AI for Augmentation and Productivity\\nseed grant. Thanks to Jordan Ellenberg, Benjamin Lira Luttges, David Holtz, Bruce Sacerdote,\\nPaul R¨ottger, Mohammed Alsobay, Ray Duch, Matt Schwartz, David Autor, and Dean Eckles\\nfor their helpful feedback. Author’s contact information, code, and data are currently or will be\\navailable at http://www.benjaminmanning.io/.\\n†Both authors contributed equally to this work.\\n1\\narXiv:2404.11794v2  [econ.GN]  25 Apr 2024\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 2, 'text': '1\\nIntroduction\\nThere is much work on efficiently estimating econometric models of human behavior\\nbut comparatively little work on efficiently generating and testing those models to\\nestimate. Previously, developing such models and hypotheses to test was exclusively\\na human task. This is changing as researchers have begun to explore automated\\nhypothesis generation through the use of machine learning.1 But even with novel\\nmachine-generated hypotheses, there is still the problem of testing.\\nA potential\\nsolution is simulation. Researchers have shown that Large Language Models (LLM)\\ncan simulate humans as experimental subjects with surprising degrees of realism.2\\nTo the extent that these simulation results carry over to human subjects in out-of-\\nsample tasks, they provide another option for testing (Horton, 2023). In this paper,\\nwe combine these ideas—automated hypothesis generation and automated in silico\\nhypothesis testing—by using LLMs for both purposes. We demonstrate that such\\nautomation is possible. We evaluate the approach by comparing results to a setting\\nwhere the real-world predictions are well known and test to see if an LLM can be\\nused to generate information that it cannot access through direct elicitation.\\nThe key innovation in our approach is the use of structural causal models to orga-\\nnize the research process. Structural causal models are mathematical representations\\nof cause and effect (Pearl, 2009b; Wright, 1934) and have long offered a language\\nfor expressing hypotheses.3 What is novel in our paper is the use of these models\\nas a blueprint for the design of agents and experiments. In short, each explanatory\\nvariable describes something about a person or scenario that has to vary for the effect\\nto be identified, so the system “knows” it needs to generate agents or scenarios that\\n1A few examples include generative adversarial networks to formulate new hypotheses (Ludwig\\nand Mullainathan, 2023), algorithms to find anomalies in formal theories (Mullainathan and Ram-\\nbachan, 2023), reinforcement learning to propose tax policies (Zheng et al., 2022), random forests\\nto identify heterogenous treatment effects (Wager and Athey, 2018), and several others (Buyalskaya\\net al., 2023; Cai et al., 2023; Enke and Shubatt, 2023; Girotra et al., 2023; Peterson et al., 2021).\\n2(Aher et al., 2023; Argyle et al., 2023; Bakker et al., 2022; Binz and Schulz, 2023b; Brand et\\nal., 2023; Bubeck et al., 2023; Fish et al., 2023; Mei et al., 2024; Park et al., 2023)\\n3In an unfortunate clash of naming conventions, some disciplines have alternative definitions\\nfor the term “structural” when discussing formal models. Here, structural does not refer to the\\ndefinition traditionally used in economics. See Appendix B for a more detailed explanation.\\n2\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 3, 'text': 'vary on that dimension—a straightforward transition from stated theory to experi-\\nmental design and data generation. Furthermore, the structural causal model offers\\na pre-specified plan for estimation (Haavelmo, 1943, 1944; J¨oreskog, 1970).\\nWe built an open-source computational system implementing this structural causal\\nmodel-based approach. The system can automatically generate hypotheses, design\\nexperiments, run those experiments on independent LLM-powered agents, and ana-\\nlyze the results. We use this system to explore several social scenarios: (1) two people\\nbargaining over a mug, (2) a bail hearing for tax fraud, (3) a lawyer interviewing\\nfor a job, and (4) an open ascending price auction with private values for a piece\\nof art. We allow the system to propose the hypotheses for the first two scenarios\\nand then run the experimental simulations without intervention. For (3) and (4),\\nwe demonstrate the system’s ability to accommodate human input at any point by\\nselecting the hypotheses ourselves and editing some of the agents, but otherwise, we\\nallow the system to proceed autonomously.\\nThough yet to be optimized for novelty, the system formulates and tests multiple\\nfalsifiable hypotheses—from which it generates several findings. The probability of\\na deal increased as the seller’s sentimental attachment to the mug decreased, and\\nboth the buyer’s and the seller’s reservation prices mattered. A remorseful defendant\\nwas granted lower bail but was not so fortunate if his criminal history was exten-\\nsive. However, the judge’s case count before the hearing—which was hypothesized\\nto matter—did not affect the final bail amount. The candidate passing the bar exam\\nwas the only important factor in her getting the job. Neither the candidate’s height\\nnor the interviewer’s friendliness affected the outcome.\\nThe auction scenario is particularly illuminating. An increase in the bidders’\\nreservation prices caused an increase in the clearing price, a clearing price that is\\nalways close to the second-highest reservation amongst the bidders. These simula-\\ntion results closely match the theory (Maskin and Riley, 1985) and what has been\\nobserved empirically (Athey et al., 2011).\\nNone of the findings from the system’s experiments are “counterintuitive,” but\\nit is important to emphasize they were the result of empiricism, not just model\\nintrospection.\\nHowever, this does raise the question of whether the simulations\\n3\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 4, 'text': 'are even necessary.4\\nInstead of simulation, could an LLM simply do a “thought\\nexperiment” about the proposed in silico experiment and achieve the same insight?\\nTo test this idea, we describe the experiments that will be simulated and ask the\\nLLM to predict the results—both the path estimates and point predictions. The\\npath estimates being the coefficients in the linear structural causal model. To make\\nthis concrete, suppose we had the simple linear model y = Xβ to describe some\\nscenario, and we ran an experiment to estimate ˆβ. We describe the scenario and the\\nexperiment to the LLM and ask it to predict yi given a particular Xi (a “predict-yi”\\ntask). Separately, we ask it to predict ˆβ (a “predict-ˆβ” task). Later, we examine\\nhow the LLM does on the predict-yi task when it has access to the fitted structural\\ncausal model (i.e., ˆβ).\\nIn the predict-yi task, we prompt the LLM to predict the outcome yi given each\\npossible combination of the Xi’s from the auction experiment. Direct elicitation of\\nthe predictions for yi in the auction experiment is wildly inaccurate. The predictions\\nare even further from the theory than the empirical results.\\nIn the predict-ˆβ task, the LLM is asked to predict the fitted structural causal\\nmodel’s path estimates for all four experiments, provided with contextual information\\nabout each scenario. On average, the LLM predicts the path estimates are 13.2 times\\nlarger than the experimental results. Its predictions are overestimates for 10 out of\\n12 of the paths, although they are generally in the correct direction.\\nWe repeat the predict-yi task, but this time, we provide the LLM with the ex-\\nperimental path estimates. For each Xi, we fit the structural causal model using\\nall but the ith observation and then ask the LLM to predict yi given Xi and this\\nfitted model. In this “predict-yi|ˆβ−i” task, the predictions are far better than in the\\npredict-yi task without the fitted model. The mean squared error is six times lower,\\nand the predictions are much closer to those made by the theory, but they are still\\nfurther from the theory than they are to the simulations.\\nWe design and implement an approach to automated social science because LLMs\\npossess latent information about human behavior that can be systematically explored\\nand extracted (Burns et al., 2023; Scherrer et al., 2024). These models are trained to\\n4Performing these experiments required a substantial software infrastructure.\\n4\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 5, 'text': 'predict the next token in a sequence of text from a massive human-generated corpus.\\nFrom this straightforward objective, the models develop a remarkably sophisticated\\nmodel of the world, at least as captured in text (Bubeck et al., 2023; Gurnee and\\nTegmark, 2023; Patel and Pavlick, 2021). And while there are many situations where\\nLLMs are imperfect proxies for humans (Cheng et al., 2023; Santurkar et al., 2023),\\nthere is also a growing body of work demonstrating that experiments with LLMs as\\nsubjects can predict human behavior in never-before-seen tasks (Binz and Schulz,\\n2023a; Li et al., 2024). Rapid and automated exploration of these models’ behavior\\ncould be a powerful tool to efficiently generate new insights about humans. Our\\ncontribution is to demonstrate that it is possible to create such a tool: a system that\\ncan simulate the entire social scientific process without human input at any step.\\nThe remainder of this paper is structured as follows: Section 2 provides an\\noverview of the system. Section 3 provides some results generated using our system.\\nSection 4 explores an LLM’s capacity to predict the results in Section 3. Section\\n5 discusses the advantages of using SCMs over other methods for studying causal\\nrelationships in simulations of social interactions. The paper concludes in Section 6.\\n2\\nOverview of the system\\nTo perform this automated social science, we needed to build a system. The system\\nintentionally mirrors the experimental social scientific process. These steps are, in\\nbroad strokes:\\n1. Social scientists start by selecting a topic or domain to study (e.g., misinfor-\\nmation, auctions, bargaining, etc).\\n2. Within the domain, they identify interesting outcomes and some causes that\\nmight affect the outcomes. These variables and their proposed relationships\\nare the hypotheses.\\n3. They design an experiment to test these hypotheses by inducing variation in\\nthe causes and measuring the outcomes.\\n5\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 6, 'text': '4. After designing the experiment, social scientists determine how they will ana-\\nlyze the data in a pre-analysis plan.\\n5. Next, they recruit participants, run the experiment, and collect the data.\\n6. Finally, they analyze the data per the pre-analysis plan to estimate the rela-\\ntionships between the proposed causes and outcomes.\\nWhile any given social scientist might not follow this sequence exactly, whatever\\ntheir approach may be, the first two steps should always guide the later steps—the\\ndevelopment of the hypothesis guides the experimental design and model estimation.\\nOf course, many social scientists must often omit steps 3-5 when a controlled exper-\\niment is not possible, but they typically have some notion of the experiment they\\nwould like to run.\\nTo build our system, we formalized a sequence of these steps analogous to those\\nlisted above. The system executes them autonomously. Since the system uses AI\\nagents instead of human subjects, it can always design and execute an experiment.\\nStructural causal models (SCM) are essential to the design of the system because\\nthey make unambiguous causal statements, which allow for unambiguous estimation\\nand experimental design.5 Algorithms can determine precisely which variables must\\nbe exogenously manipulated to identify the effect of a given cause (Pearl, 2009b). If\\nthe first two steps in the social scientific process are building the SCM, the last four\\ncan be directly determined subject to the SCM. Such precision makes automation\\npossible as the system only relies on a few key early decisions. Otherwise, the space\\nof possible choices for the latter steps would explode, making automation infeasible.\\nThe system is implemented in Python and uses GPT-4 for all LLM queries.\\nIts decisions are editable at every step.\\nThe overview in this section is a high-\\nlevel description of the system, but there are many more specific design choices and\\nprogramming details in Appendix A. For the purposes of most readers, the high-\\n5We use simple linear SCMs unless stated otherwise. This assumption is not necessarily correct\\nbut offers an unequivocal starting point to generate hypotheses. Functional assumptions can be\\ntested by comparing fitted SCMs with various forms using data generated from a known causal\\nstructure. Section B in the appendix provides a more detailed explanation of SCMs.\\n6\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 7, 'text': 'level overview should be sufficient to understand the system’s process, the results we\\npresent in Section 3, and the additional analyses in Sections 4 and 5.\\nThe system takes as input some scenario of social scientific interest: a negotia-\\ntion, a bail decision, a job interview, an auction, and so on. Starting with (1) this\\ninput, the system (2) generates outcomes of interest and their potential causes, (3)\\ncreates agents that vary on the exogenous dimensions of said causes, (4) designs an\\nexperiment, (5) executes the experiment with LLM-powered agents simulating hu-\\nmans, (6) surveys the agents to measure the outcomes, (7) analyzes the results of\\nthe experiment to assess the hypotheses, which can be used to plan a follow-on ex-\\nperiment. Figure 1 illustrates these steps, and we will briefly explore each in greater\\ndepth.\\nFigure 1: An overview of the automated system.\\nNotes: Each step in the process corresponds to an analogous step in the social scientific process as\\ndone by humans. The development of the hypothesis guides the experimental design, execution, and\\nmodel estimation. Researchers can edit the system’s decisions at any step in the process.\\nThe first step is to generate hypotheses as SCMs based on the social scenario, the\\nscenario being the only necessary input to the system. This is done by querying an\\n7\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 8, 'text': 'LLM for the relevant agents and then interesting outcomes, their potential causes,\\nand methods to operationalize and measure both.6\\nWe use Typewriter text to\\nindicate example output from the system. Suppose the social scenario is “two people\\nbargaining over a mug.” The LLM may generate whether a deal occurs for the\\nmug as an outcome, and operationalizes the outcome as a binary variable with\\na ‘‘1’’ when a deal occurs and a ‘‘0’’ when it does not.\\nIt then gener-\\nates potential exogenous causes and their operationalizations: the buyer’s budget,\\nwhich is operationalized as the buyer’s willingness to pay in dollars. The\\nsystem takes each of these variables, constructs an SCM (see the second step in Fig-\\nure 1), and stores the relevant information about the operationalizations associated\\nwith each variable.78 From this point on, the SCM serves as a blueprint for the rest\\nof the process, namely the automatic instantiation of agents, their interaction, and\\nthe estimation of the linear paths.\\nThe second step is to construct the relevant agents—the Buyer and the Seller\\nin Figure 1, step 3. By “construct,” we mean that the system prompts indepen-\\ndent LLMs to be people with sets of attributes. These attributes are the exogenous\\ndimensions of the SCM, dimensions that are varied in each simulation. I.e., the dif-\\nferent experimental conditions. For the current scenario, a Budget is provided to the\\nbuyer that can take on values of {$5, $10, $20, $40}. By simulating interactions\\nof agents that vary on the exogenous dimensions of the SCM, the data generated can\\nbe used to fit the SCM.\\nNext, the system generates survey questions to gather data about the outcomes\\n6When we say “query an LLM,” we mean this literally. We have written a prompt that the\\nsystem provides to an LLM with the scenario.\\nFor example, the prompt used to generate the\\nrelevant agents is: In the following scenario: “{scenario}”, who are the individual human agents in\\na simple simulation of this scenario? Where “{scenario}” is replaced with the scenario of interest.\\nThe LLM then returns a list of agents, which are stored in the system and can be used in follow-on\\nprompts, prompts that generate things like the outcomes and proposed causes. The system contains\\nover 50 pre-written scenario-neutral prompts to gather all the information needed to generate the\\nSCM, run the experiment, and analyze the results.\\n7The system generates several other pieces of information about each variable, which help guide\\nthe experimental design and data analysis. See Appendix A for further details.\\n8The graph in the second step of Figure 1 is a directed acyclic graph (DAG). For convenience,\\nwe will use DAGs to represent SCMs throughout the paper and assume they imply a simple linear\\nmodel unless stated otherwise.\\n8\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 9, 'text': 'from the agents automatically once each simulation is complete. An LLM can easily\\ngenerate these questions when provided with information about the variables in the\\nSCM (e.g., asking the buyer, “Did a deal happen?”). All LLM-powered agents in\\nour system have “memory.” They store what happened during the simulation in\\ntext, making it easy to ask them questions about what happened.\\nFourth, the system determines how the agents should interact. LLMs are designed\\nto generate text in sequence. Since independent LLMs power each agent, one agent\\nmust finish speaking before the next begins. This necessitates a turn-taking protocol\\nto simulate the conversation. We programmed a menu of six ordering protocols,\\nfrom which an LLM is queried to select the most appropriate for a given scenario.\\nWe describe each protocol in Appendix A, and they are presented in Figure A.2,\\nbut in our bargaining scenario with two agents, there are only two possible ways for\\nthe agents to alternate speaking. In this case, the system selects: speaking order:\\n(1) Buyer, (2) Seller, (step 4, Figure 1). The speaking order can be flexible in\\nmore complex simulations with more agents, such as an auction or a bail hearing.\\nNow, the system runs the experiment. The conditions are simulated in parallel\\n(step 5 in Figure 1), each with a different value for the exogenous dimensions of the\\nSCM—the possible budgets for the buyer.\\nThe system must also determine when to stop the simulations. There is no obvious\\nrule for when a conversation should end.\\nLike the halting problem in computer\\nscience—it is impossible to write a universal algorithm that can determine whether\\na given program will complete (Turing, 1937)—such a rule for conversations does\\nnot exist. We set two stopping conditions for the simulations. After each agent\\nspeaks in a simulation, an external LLM is prompted with the transcript of the\\nconversation and asked if the conversation should continue. If yes, the next agent\\nspeaks; otherwise, the simulation ends. Additionally, we limit the total number of\\nagent statements to twenty. One could imagine doing something more sophisticated\\nboth with the social interactions and the stopping conditions in the future. This\\nis even a place for possible experimentation as the structure of social interactions\\ncan impact various outcomes of interest (Jahani et al., 2023; Rajkumar et al., 2022;\\nSacerdote, 2001).\\n9\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 10, 'text': 'Finally, the system gathers the data for analysis. Outcomes are measured by\\nasking the agents the survey questions (Figure 1, step 6) as determined before the\\nexperiment. The data is then used to estimate the linear SCM. For our negotiation,\\nthat would be a simple linear model with a single path estimate (i.e., linear coef-\\nficient) for the effect of the buyer’s budget on the probability of a deal—the final\\nstep in Figure 1. Note that an SCM specifies, ex-ante, the exact statistical analyses\\nto be conducted after the experiment—akin to a pre-analysis plan. This step of the\\nsystem’s process is, therefore, mechanical.\\nThe system, as outlined, is automated from start to finish—the SCM and its\\naccompanying metadata serve as a blueprint for the rest of the process. Once there\\nis a fitted SCM, this process can be repeated. Although we have not automated\\nthe transition from one experiment to the next, the system can generate new causal\\nvariables, induce variations, and run another experiment based on the results of the\\nfirst.\\n3\\nResults of experiments\\nWe present results for four social scenarios explored using the system. In the first two\\nscenarios, our involvement in the system’s process was restricted to entering the de-\\nscription of the scenario and then the entire process was automated. In the third and\\nfourth scenarios, we selected the hypotheses and edited some of the agents, but the\\nsystem designed and executed the experiments. We intervened in the latter scenarios\\nnot because the system is incapable of simulating these scenarios autonomously, but\\nto demonstrate the system’s capacity to accommodate human input at any point\\nwhile still generating exciting results.\\n3.1\\nBargaining over a mug\\nWe first use the system to simulate “two people bargaining over a mug”—this phrase\\nbeing in quotes because it was the only input needed for the system to simulate the\\nfollowing process. The system selected a buyer and seller as the relevant agents,\\n10\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 11, 'text': 'the outcome as whether a deal occurs, and the buyer’s budget, the seller’s mini-\\nmum acceptable price, and the seller’s emotional attachment to the mug as potential\\ncauses.\\nTable 2a provides the information generated by the system about the SCM and\\nthe experimental design. The topmost row, simulation details, provides high-level\\ninformation about the structure of the simulation.\\nThe remaining rows provide\\ninformation about the variables in the SCM and how they were operationalized. The\\nsystem automatically generated all this information by iteratively querying the LLM.\\nThe three exogenous variables were operationalized as the buyer’s budget in dol-\\nlars, the seller’s minimum acceptable price in dollars, and the seller’s emotional\\nattachment as an ordinal scale from “no emotional attachment” to “extreme emo-\\ntional attachment.” The system chose nine values (the “Attribute Treatments” in\\nTable 2a) to vary for each of the first two causes and five for the seller’s feelings of\\nlove towards the mug (one for each level of the scale). This led to 9 × 9 × 5 = 405\\nexperimental runs of the simulated conversation between the buyer and seller.\\nFigure 2b provides the fitted SCM. The outcome variable is given with its mean\\nand variance. The raw path estimates and their standard errors are shown on the\\narrows. For ordinal variables (e.g., the seller’s feelings of love), we treat the levels as\\nnumerical values. The buyer and seller reached a deal for the mug in half of the sim-\\nulations, and all three causes had a statistically significant effect on the probability\\nof a deal.\\nA one-dollar increase in the buyer’s budget caused an average increase of 3.7\\npercentage points in the probability of a deal (ˆβ* = 0.51, p < 0.001).9 A one-dollar\\nincrease in the seller’s minimum acceptable price caused an average decrease of 3.5\\npercentage points in the probability of a deal occurring (ˆβ* = −0.49, p < 0.001).\\nFinally, a one-unit increase in the ordinal scale of the seller’s love for the mug, such\\nas going from moderate emotional attachment to high emotional attachment, caused\\nan average decrease of 2.5 percentage points in the probability of a deal (ˆβ* = −0.07,\\np = 0.044).\\n9We report standardized effect size estimates with ˆβ*. Standardized effect sizes being “a one\\nstandard deviation increase in X causes a ˆβ* standard deviation increase in Y.”\\n11\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 12, 'text': 'Figure 2: Experimental design and fitted SCM for “two people bargaining over a\\nmug.”\\nSIMULATION DETAILS\\nAgents: Buyer, Seller\\nSimulations Run: 9 × 9 × 5 = 405\\nSpeaking Order: Buyer, Seller, Buyer, ...repeat\\nVARIABLE INFORMATION\\nWhether or not a deal occurs\\nMeasurement\\nQuestion:\\ncoordinator:\\n“Did the\\nbuyer and seller explicitly agree on the price of the mug\\nduring their interaction?”\\nVariable Type: Binary\\nBuyer’s Budget\\nAttribute Treatments: [‘3’, ‘6’, ‘7’, ‘8’, ‘10’, ‘13’,\\n‘18’, ‘20’, ‘25’]\\nProxy Attribute: Your budget for the mug\\nVariable Type: Continuous\\nSeller’s minimum acceptable price\\nAttribute Treatments: [‘3’, ‘5’, ‘7’, ‘8’, ‘10’, ‘13’,\\n‘18’, ‘20’, ‘25’]\\nProxy Attribute: Your minimum acceptable price for\\nthe mug\\nVariable Type: Continuous\\nSeller’s feelings of love towards the mug\\nAttribute Treatments: [‘no emotional attachment’,\\n‘slight emotional attachment’, ‘moderate emotional at-\\ntachment’, ‘high emotional attachment’, ‘extreme emo-\\ntional attachment’]\\nProxy Attribute: Your feelings of love for the mug\\nVariable Type: Ordinal\\n(a) Information for experimental design\\nDeal\\nOccurs\\nµ = 0.5\\nσ2 = 0.25\\nBuyer\\nBudget\\nSeller Min\\nSeller Love\\n0.037\\n(0.003)\\n-0.035\\n(0.002)\\n-0.025\\n(0.012)\\n(b) Fitted SCM\\nNotes: Figure 2a provides the information automatically generated by the system to execute the\\nexperiment for its proposed hypothesis. This includes the high level structure of the simulations,\\nhow the outcome is measured, and the treatment variations for each of the causes. The fitted SCM\\nin Figure 2b shows the results of the experiment. The outcome is given with its mean and variance.\\nThe edges are labeled with their unstandardized path estimate and standard error. We assume a\\nsimple linear model for the SCM, such that the above graph can also be written as DealOccurs =\\n0.037BuyerBudget −0.035MinPrice −0.025SellerLove.\\n12\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 13, 'text': '3.2\\nA bail hearing\\nNext, we explore “a judge is setting bail for a criminal defendant who committed\\n50,000 dollars in tax fraud.”\\nTable 3a shows that the system selected a judge,\\ndefendant, defense attorney, and prosecutor as the relevant agents. In this scenario,\\nthe system selected a more flexible interaction protocol than the one used in the\\nprevious experiment. The judge was chosen as a center agent and, in order, the\\nprosecutor, defense attorney, and defendant as the non-center agents. This means\\nthe judge spoke first in every simulation, alternating with the other agents: judge,\\nprosecutor, judge, defense attorney, judge, defendant, and so on. As described in\\nSection A.3, we call this the “center-ordered” interaction protocol.\\nFigure 3: Experimental design and fitted SCM for “a judge is setting bail for a\\ncriminal defendant who committed 50,000 dollars in tax fraud.”\\nSIMULATION DETAILS\\nAgents: Judge, Defendant, Defense attorney, Prosecutor\\nSimulations Run: 7 × 7 × 5 = 243\\nSpeaking Order: Judge, Prosecutor, Judge,\\nDefense Attorney, Judge, Defendant, ... repeat\\nVARIABLE INFORMATION\\nBail amount set by the judge\\nMeasurement Question: Judge: “What was the bail\\namount you set for the defendant?”\\nVariable Type: Continuous\\nDefendant’s criminal history\\nAttribute Treatments: [‘0’, ‘1’, ‘2’, ‘3’, ‘6’, ‘9’, ‘12’]\\nProxy Attribute: Number of your prior convictions\\nVariable Type: Count\\nPrior case count for judge that day\\nAttribute Treatments: [‘0’, ‘2’, ‘5’, ‘9’, ‘12’, ‘18’,\\n‘23’]\\nProxy Attribute: Number of cases you have already\\nheard today\\nVariable Type: Count\\nDefendant’s level of remorse\\nAttribute Treatments: [‘no expressed remorse’, ‘low\\nexpressed remorse’, ‘moderate expressed remorse’, ‘high\\nexpressed remorse’, ‘extreme expressed remorse’]\\nProxy Attribute: Your level of expressed remorse\\nVariable Type: Ordinal\\n(a) Information for experimental design\\nBail\\nAmount\\nµ =\\n54428.57\\nσ2 = 1.9e7\\nCriminal\\nHistory\\nJudge Case\\nCount\\nDefendant’s\\nRemorse\\n521.53\\n(206.567)\\n-74.632\\n(109.263)\\n-1153.061\\n(603.325)\\n(b) Fitted SCM\\nNotes: Figure 3a provides the information automatically generated by the system to execute the\\nexperiment for its proposed hypothesis. Figure 3b shows the fitted SCM from the experiment.\\n13\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 14, 'text': 'The system chose the outcome to be the final bail amount, and the three pro-\\nposed causes are the defendant’s criminal history, the number of cases the judge has\\nalready heard that day, and the defendant’s level of remorse. The number of cases\\nthe judge already heard that day and the defendant’s level of remorse are opera-\\ntionalized literally, as the count of cases the judge has heard and five ordinal levels\\nof possible outward expressions of remorsefulness. The defendant’s criminal history\\nis operationalized as the number of previous convictions.\\nIn the fitted SCM in Figure 3b, only the defendant’s criminal history had a\\nsignificant effect on the final bail amount with each additional conviction causing an\\naverage increase of $521.53 in bail (ˆβ* = 0.16, p = 0.012). It is unclear whether\\nthe defendant’s remorse affected the final bail amount. The effect size was small but\\nnon-trivial with borderline significance (ˆβ* = −0.12, and p = 0.056).\\nWhen we estimated the SCM with interactions, the interaction between the\\njudge’s case count and the defendant’s remorse was nontrivial (ˆβ* = −0.32, p =\\n0.047). In this specification (Figure A.5), none of the other interactions or the stand-\\nalone causes have a significant effect, including the defendant’s criminal history.\\n3.3\\nInterviewing for a job as a lawyer\\nIn our third simulated experiment, we chose the scenario “a person interviewing for\\na job as a lawyer.” The system determined that a job applicant and an employer\\nwere the agents. Unlike the previous simulations, we manually selected the variables\\nin the SCM. Table 4a shows that these were the employer’s hiring decision as the\\noutcome and whether the applicant passed the bar, the interviewer’s friendliness,\\nand the job applicant’s height as the potential causes.\\nThe system operationalized the causes as a binary variable for passing the bar,\\nthe job applicant’s height in centimeters, and the interviewer’s friendliness as the\\nproposed number of friendly phrases to use during the simulation. Since one of the\\ncauses is a binary variable, the only potential cause in all our scenarios of this type,\\nthe sample size for the experimental simulations of this scenario is smaller (n = 80).\\nBy default, the system runs a factorial experimental design for all proposed values\\n14\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 15, 'text': 'Figure 4: Experimental design and fitted SCM for “a person is interviewing for a\\njob as a lawyer.”\\nSIMULATION DETAILS\\nAgents: Interviewer, Job Applicant\\nSimulations Run: 2 × 5 × 8 = 405\\nSpeaking Order: Interviewer, Job Applicant,\\nInterviewer, ...repeat\\nVARIABLE INFORMATION\\nEmployer’s Decision\\nMeasurement Question: Employer: “Have you de-\\ncided to hire the job applicant?”\\nVariable Type: Binary\\nWhether Applicant Passed Exam\\nAttribute Treatments: [‘Passed’, ‘Not’]\\nProxy Attribute: Your bar exam status\\nVariable Type: Binary\\nInterviewer’s level of friendliness\\nAttribute Treatments: [‘2’, ‘7’, ‘12’, ‘17’, ‘22’]\\nProxy Attribute: Number of positive phrases to use\\nduring interview\\nVariable Type: Count\\nJob applicant’s height\\nAttribute Treatments:\\n[‘160’, ‘165’, ‘170’, ‘175’,\\n‘180’, ‘185’, ‘190’, ‘195’]\\nProxy Attribute: Your height in centimeters\\nVariable Type: Continous\\n(a) Information for experimental design\\nEmployer\\nDecision\\nµ = 0.62\\nσ2 = 0.24\\nPassed Bar\\nInterviewer\\nFriend-\\nliness\\nApplicant\\nHeight\\n0.75\\n(0.068)\\n-0.002\\n(0.005)\\n0.003\\n(0.003)\\n(b) Fitted SCM\\nNotes: Figure 4a provides the information automatically generated by the system to execute the\\nexperiment for the proposed hypothesis. Figure 4b shows the fitted SCM from the experiment.\\n15\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 16, 'text': 'of each cause. With only two possible values for the job applicant passing the bar\\n(as opposed to 5 varied treatment values for the interviewer’s friendliness and 8 for\\nthe applicant’s height), this limits the possible combinations of the causal variables\\nto 2 × 5 × 8 = 80. A researcher could run more simulations to increase the sample\\nsize if so desired.\\nWe can see in Figure 4b that only the applicant passing the bar has a clear causal\\neffect on whether the applicant gets the job. This is the largest standardized effect we\\nsee across the simulations in the four scenarios (ˆβ* = 0.78, p < 0.001). On average,\\nwhether or not the applicant passes the bar increases the probability she gets the job\\nby 75 percentage points. When we test for interactions, none are significant (Figure\\nA.6).\\n3.4\\nAn auction for a piece of art\\nFinally, we explored the scenario of “3 bidders participating in an auction for a piece\\nof art starting at fifty dollars.” Table 5a shows that the causes are each bidder’s\\nmaximum budget for the piece of art, and the outcome is the final price of the piece\\nof art—all of which we selected.\\nAll four variables are operationalized in dollars. To maintain symmetry in the\\nsimulations, we also manually selected the same proxy attribute for the three bidders:\\n“your maximum budget for the piece of art.”\\nEach bidder had the same seven\\npossible values for their attribute, leading to 73 = 343 simulations of the auction. It\\nis important to note that these budgets are private values. Unless a bidder publically\\nreveals their budget, the other bidders do not know what it is.\\nLike the tax fraud scenario, the system chose the center-ordered interaction pro-\\ntocol for these simulations. The auctioneer was selected as the central agent, and\\nthe other agents were bidder 1, bidder 2, and bidder 3, who alternated with the\\nauctioneer in that order.\\nFigure 5b provides the results.\\nAll three causal variables had a positive and\\nstatistically significant effect on the final price. A one-dollar increase in any of the\\nbidder’s budgets caused a $0.35, $0.29, and $0.31 increase in the final price for the\\n16\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 17, 'text': 'Figure 5: Experimental design and fitted SCM for “3 bidders participating in an\\nauction for a piece of art starting at fifty dollars.”\\nSIMULATION DETAILS\\nAgents: Bidder 1, Bidder 2, Bidder 3, Auctioneer\\nSimulations Run: 7 × 7 × 7 = 343\\nSpeaking Order: Auctioneer, Bidder 1, Auctioneer,\\nBidder 2, Auctioneer, Bidder 3, ... repeat\\nVARIABLE INFORMATION\\nFinal price\\nMeasurement Question:\\nAuctioneer:\\n“What was\\nthe final bid for the piece of art at the end of the auc-\\ntion?”\\nVariable Type: Continuous\\nBidder 1’s maximum budget\\nAttribute Treatments: [‘$50’, ‘$100’, ‘$150’, ‘$200’,\\n‘$250’, ‘$300’, ‘$350’]\\nProxy Attribute: Your max budget for the art\\nVariable Type: Continuous\\nBidder 2’s maximum budget\\nAttribute Treatments: [‘$50’, ‘$100’, ‘$150’, ‘$200’,\\n‘$250’, ‘$300’, ‘$350’]\\nProxy Attribute: Your max budget for the art\\nVariable Type: Continuous\\nBidder 3’s maximum budget\\nAttribute Treatments: [‘$50’, ‘$100’, ‘$150’, ‘$200’,\\n‘$250’, ‘$300’, ‘$350’]\\nProxy Attribute: Your max budget for the art\\nVariable Type: Continuous\\n(a) Information for experimental design\\nFinal Price\\nµ = 186.53\\nσ2 = 3879.23\\nBidder 1\\nBudget\\nBidder 2\\nBudget\\nBudder\\n3 Budget\\n0.35\\n(0.015)\\n0.29\\n(0.015)\\n0.31\\n(0.015)\\n(b) Fitted SCM\\nNotes: Figure 5a provides the information automatically generated by the system to execute the\\nexperiment for the proposed hypothesis. Figure 5b shows the fitted SCM from the experiment.\\n17\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 18, 'text': 'piece of art for each respective bidder (ˆβ* = 0.57, p < 0.001; ˆβ* = 0.47, p < 0.001;\\nˆβ* = 0.5 p < 0.001). These quantities make sense as each bidder has a 1\\n3 chance of\\nbeing marginal.\\n4\\nLLM predictions for paths and points\\nIt is worth reiterating that the results in the previous section were not generated\\nby directly prompting an LLM but rather through experimentation. Although the\\nexperiments were fast and inexpensive, they were not free–in total, they took about\\n5 hours to run and cost over $1,000. This raises the question of whether the simu-\\nlations were even necessary. Could an LLM do a “thought experiment” (i.e., make\\na prediction based on a prompt) about a proposed in silico experiment and achieve\\nthe same insight? If so, we should just prompt the LLM to come up with an SCM\\nand elicit its predictions about the relationships between the variables.\\nTo test this idea, we describe some of the simulations to the LLM and ask it to\\npredict the results—path estimates and point predictions.10 Specifically, we modeled\\neach scenario as y = Xβ, where y is an n × 1 vector and X is a n × k matrix.\\nHere, n is the number of simulations, and k is the number of proposed causes. The\\nexperiments from Section 3 provided us with estimates for ˆβ (a k × 1 vector). We\\ndescribe the scenario and the experiment to the LLM and ask it to independently\\npredict yi given each Xi (a predict-yi task) as well as to predict ˆβ (a predict-ˆβ task).\\nThe LLM’s yi predictions are highly inaccurate compared to those from auction\\ntheory, which predicts that the clearing price will be the second highest valuation in\\nan open-ascending price auction with private values (Maskin and Riley, 1985). The\\nLLM is also unable to accurately predict the path estimates (ˆβ) of the fitted SCM.\\nFinally, we examine how the LLM does on the predict-yi task when provided with an\\nSCM fit on all of the data except for the corresponding Xi (the predict-yi|ˆβ−i task).\\nWhile the additional information dramatically improves the LLM’s predictions, they\\nare still less accurate than those made by auction theory.\\n10All predictions are made by the LLM once at temperature 0. When we elicit these predictions\\nmany times at higher temperatures, the results are similar.\\n18\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 19, 'text': '4.1\\nPredicting yi\\nFor various bidder reservation price combinations in the auction experiment, we\\nsupply the LLM with a prompt detailing the simulation and experimental design.11\\nWe then ask the LLM to predict the clearing price for the auction. This gives us a\\npoint prediction for each simulated auction (i.e., each unique row Xi in X) used to\\ngenerate the fitted SCM in Figure 5b.\\nFigure 6 presents a comparison of the LLMs predictions, the simulated experi-\\nments, and the predictions made by auction theory.12 The columns correspond to\\nthe different reservation values for bidder 3 in a given simulation, and the rows cor-\\nrespond to the different reservation values for bidder 2. The y-axis is the final bid\\nprice, and the x-axis lists bidder 1’s reservation price. The black triangles track the\\nobserved clearing price in each simulated experiment, the black line shows the pre-\\ndictions made by auction theory, and the blue line indicates the LLM’s predictions\\nwithout the fitted SCM—the predict-yi task.\\nThe LLM performs poorly at the predict-yi task.\\nThe blue line is often far\\nfrom the black triangles and sometimes remains constant or even decreases as the\\nsecond-highest reservation price across the agents increases.\\nIn contrast, auction\\ntheory is highly accurate in its predictions of the final bid price in the experiment—\\nthe black line often perfectly tracks the black triangles.13 The mean squared error\\n(MSE) of the LLM’s predictions in the predict-yi task (MSEyi = 8628) is an order of\\nmagnitude higher than that of the theoretical predictions (MSETheory = 128), and\\nthe predictions are even further from the theory than they are from the empirical\\nresults (MSEyi−Theory = 8915).14\\n11In 80/343 simulations, the agents made the maximum number of statements (20) allowed by\\nthe system before the auction ended. We remove these observations because, without additional\\ninformation, auction theory does not make predictions about partially completed auctions.\\n12We provide only a subset of the results in the main text as it is difficult to visualize all of them\\nin a single figure. Figure A.10 shows the full set of predictions. The results are generally the same.\\n13There are a few observations where the empirical clearing price is slightly above or below the\\ntheory prediction. In most cases where it was off, this was due to the auctioneer incrementing the\\nbid price above the second-highest reservation price in the last round.\\n14MSE is reported for all predictions, not just the subset shown in Figure 6.\\n19\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 20, 'text': 'Figure 6: Comparison of the LLM’s predictions to the theoretical predictions and a\\nsubset of experimental results for the auction scenario.\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nPred. yi\\nPred. yi | β^\\n−i\\nAuc. Theory\\nBidder 3\\nReservation: 150\\nBidder 3\\nReservation: 200\\nBidder 3\\nReservation: 250\\nBidder 3\\nReservation: 300\\nBidder 2\\nReservation:\\n 200\\nBidder 2\\nReservation:\\n 150\\nBidder 2\\nReservation:\\n 100\\nBidder 2\\nReservation:\\n 50\\n100\\n200\\n300\\n400\\n100\\n200\\n300\\n400\\n100\\n200\\n300\\n400\\n100\\n200\\n300\\n400\\n100\\n200\\n300\\n100\\n200\\n300\\n100\\n200\\n300\\n100\\n200\\n300\\nBidder 1\\nReservation Price\\nFinal Clearing Price\\nExperiment\\nNotes: The columns correspond to the different reservation values for bidder 3 in a given simulation,\\nand the rows correspond to the different reservation values for bidder 2. The y-axis is the clearing\\nprice, and the x-axis lists bidder 1’s reservation price. The black triangles track the observed clearing\\nprice in each simulated experiment, the black line shows the predictions made by auction theory\\n(MSET heory = 128), the blue line indicates the LLM’s predictions without the fitted SCM—the\\npredict-yi task (MSEyi = 8628), and the red line is the LLM’s predictions with the fitted SCM—the\\npredict-yi|ˆβ−i task (MSEyi| ˆβ−i = 1505).\\n20\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 21, 'text': '4.2\\nPredicting ˆβ\\nWe prompted the LLM to predict the path estimates and whether they would be\\nstatistically significant for the simulated experiments in Section 3. This is the predict-\\nˆβ task. We then compare the LLM’s predictions to the fitted SCMs. With four\\nexperiments and three causes in each, we generate 12 predictions.\\nWe provide the LLM with extensive information to make its predictions for each\\nexperiment.15 This information includes the proposed SCM, the operationalizations\\nof the variables, the number of simulations, and the possible treatment values. Each\\nprediction is elicited once at temperature 0.\\nThe predictions are shown in Table A.1. They were, on average, 13.2 times larger\\nthan the actual estimates, and 10/12 of the predictions were overestimates. Even\\nwhen we remove the largest overestimate, the average magnitude of the ratio between\\nthe predicted and actual estimates is still 5.3. The sign of the estimate was correct\\nin 10/12 predictions, and 10/12 correctly guessed whether or not the estimate would\\nbe statistically significant. When we repeat the predictions at a higher temperature\\nand take their average, the results are similar (see Table A.2).\\n4.3\\nPredicting yi|ˆβ−i\\nThe LLM was, on average, off by an order of magnitude for both the predict-yi task\\nand the predict-ˆβ task, but maybe it can do better with more information. For each\\nXi in the auction simulations, we use the data from the experiment to estimate ˆβ−i,\\nthe path estimates from the SCM excluding the ith observation. We then prompt\\nthe LLM to predict the outcome for each Xi given ˆβ−i.\\nThe red line in Figure 6 provides these new predictions.\\nThe LLM’s predic-\\ntions are much closer to the actual outcomes when it has access to a fitted SCM\\n(MSEyi|ˆβ−i = 1505) as opposed to when it does not (MSEyi = 8628), even though\\nall the predictions are out of sample and every Xi is unique.\\nHowever, the LLM’s predictions on the predict-yi|ˆβ−i task are still not as accurate\\n15See Figure A.11 in the appendix for the full prompt.\\n21\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 22, 'text': 'as the predictions made by auction theory (MSETheory = 128).16 They are also still\\nfurther from the theory than they are from the empirical results (MSEyi|ˆβ−i−Theory =\\n1761). There is clearly room for improvement. That improvement is feasible with\\nthe system: there exists an SCM perfectly consistent with auction theory. Only one\\nexogenous variable was missing: the second-highest reservation price of the bidders.\\nIf allowed to generate and test enough potential causes, our system could have se-\\nlected this variable as a possible cause by itself. In this case, the fitted SCM would\\nhave matched the theoretical predictions.17\\n5\\nIdentifying causal structure ex-ante\\nThe SCM-based approach offers a promising new method for studying simulated be-\\nhavior at scale. However, it is not the only option for such rapid exploration. Others\\nhave designed large, quasi-unstructured simulations demonstrating exciting results.\\nFor example, Park et al. (2023) endows a group of LLM agents with personas and\\nmemory systems and then allows them to freely interact in a simulated community\\nfor an extended period. Despite no explicit instructions to do so, the agents in the\\nsimulation produce many human-like behaviors, such as throwing parties, going on\\ndates, and making friends.\\nWhile impressive and informative, a problem with such open-ended social simu-\\nlations is that selecting and analyzing outcomes can be difficult. To unveil insights,\\nresearchers may need to comb through thousands of lines of unstructured text. If\\nthey are interested in casual relationships, they may need to infer the causal struc-\\nture ex-post, which can be problematic. In contrast, the SCM framework describes\\nexactly what needs to be measured as a downstream outcome subject to the exoge-\\nnous manipulations of the cause. Identification is guaranteed. In this section, we\\n16It is also less accurate than the mechanical predictions made by the fitted SCM using the same\\nprocedure MSEMechanistic:yi| ˆβ−i = 725. Maybe the LLM cannot do the math, is still conditioning\\non other information beyond the path estimates when making its predictions, or, like humans, is\\nignoring relevant information when making choices (Handel and Schwartzstein, 2018).\\n17When we do fit this SCM (see Figure A.9), the coefficient is close to one (β = 0.912), and\\nalmost all the variance in the outcome is explained (R2 = 0.977).\\n22\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 23, 'text': 'discuss how assuming or searching for causal structure in observational data, the\\ntype generated from massive open-ended simulations can lead to misidentification\\nand how using SCMs avoids this problem.\\n5.1\\nAssuming causal structure from data\\nAll estimates in the fitted SCMs in Section 3 are unbiased. We know this because\\nthe data comes from an experiment, and we randomized on the causal variables.\\nA nice feature of a perfectly randomized experiment is that we can get unbiased\\nmeasurements of any downstream endogenous outcome relative to the exogenous\\nmanipulations.18 I.e., the coefficients on the fitted SCM are identified. For example,\\nin the bargaining experiment, perhaps we are interested in the length of the con-\\nversation as an outcome, even though it was not a part of the original SCM. The\\nconversation length can be operationalized as the sum of the number of statements\\nmade by all agents, and we can use the transcript from the finished experiment to\\nmeasure it. We can then fit an SCM with the data and get unbiased estimates of\\nthe effect of the exogenous variables on the conversation’s length.\\nFigure 7a shows this fitted SCM using the data from the experiment in Section 3.\\nBoth the buyer’s budget and the seller’s minimum price have a significant effect on\\nthe length of the conversation (p < 0.001; p = 0.026), but the seller’s emotional\\nattachment does not (p = 0.147).\\nSuppose we did not know the actual causal structure of these scenarios or that the\\ndata came from an experiment. All we have are the data for the original three causes,\\nthe conversation length, and whether a deal was made (the original outcome). If we\\nwant to estimate the causal relationships between these variables, we would have to\\nmake untestable assumptions. For example, one could reasonably presume that the\\nbuyer’s budget, the seller’s minimum price, the seller’s emotional attachment, and\\nwhether a deal was made all causally affect the length of the conversation.\\nFigure 7b provides the fitted SCM for this proposed causal structure.\\nOnly\\n18When we say “downstream,” we mean any variable whose value is realized after the agents\\nbegin interacting in the simulated conversations.\\n23\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 24, 'text': 'Figure 7: Comparison of the true and misspecified SCMs.\\nConvo\\nLength\\nBuyer\\nBudget\\nSeller\\nMin\\nSeller\\nLove\\n-0.111\\n(0.031)\\n0.069\\n(0.031)\\n0.222\\n(0.153)\\n(a) Correctly specified SCM\\nConvo\\nLength\\nDeal\\nOccurs\\nBuyer\\nBudget\\nSeller\\nMin\\nSeller\\nLove\\n-0.051\\n(0.039)\\n0.012\\n(0.037)\\n-1.622\\n(0.615)\\n0.182\\n(0.153)\\n(b) Misspecified SCM\\nNotes: Statistically significant paths are marked in red (α = 0.05). Each path is given with its\\nestimated coefficient and standard error in parentheses. Both SCMs are estimated using the data\\nfrom the bargaining scenario in Section 3. Subfigure (a) provides a correctly specified SCM from\\na randomized experiment. Subfigure (b) shows a misspecified SCM based on an assumed structure.\\nThe path estimates of the buyer’s budget and the seller’s minimum price go from significant in the\\ncorrectly specified SCM to insignificant and far closer to zero in the misspecified SCM.\\nwhether a deal was made was estimated to have a significant effect on the length\\nof the conversation (p = 0.008). But we know this is wrong. We have the true\\ncausal structure in Figure 7a from a perfectly randomized experiment, and both\\nthe buyer’s and the seller’s reservation prices had a significant effect on the length\\nof the conversation. Here, they are insignificant and far closer to zero (p = 0.189;\\np = 0.755).\\nWhether or not the deal occurred is a bad control that biases the\\nestimates—it is probably codetermined with the length of the conversation.19\\nThe informed econometrician may presume that she would never make such a\\nmistake, but many researchers are not so savvy.20 We were unsure of it until we\\nhad unbiased estimates from the correctly specified SCM as a reference. There are\\nalso many kinds of bad controls, and many of them are less obvious than those in\\n19We cannot be sure about the causal relationship between the length of the conversation and\\nwhether a deal was made because neither is exogenously varied in the experiment. All we know\\nis that controlling for whether or not a deal occurs induces bias, as we have the experiment as a\\nreference.\\n20LLMs are definitely not yet savvy enough to avoid this mistake.\\n24\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 25, 'text': 'this example (Cinelli et al., 2022). It is easy to misspecify a model when the data\\nis observational and has many variables, even when their relationships may seem\\nobvious.\\nThe SCM-based approach avoids the bad controls. The generation of the data is\\nbased on the causal structure. There is no need to instrument endogenous variables\\nand presume their causal relationships. Exogenous variation is explicitly induced in\\nthe SCM to identify the causal relationships ex-ante. Even if we do not know how a\\nnew outcome is incorporated into the causal structure, we can always reference how\\nit is affected by the exogenous variables by fitting a simple linear SCM.\\n5.2\\nSearching for causal structure in data\\nAnother strategy for identifying causal relationships when the underlying structure is\\nunknown is to let the data speak for itself. For example, we could use an algorithm to\\nfind the model that makes the data most likely. There are many ways to do this, none\\nof which can always, or even consistently, identify the correct causal relationships\\nfrom observational data (Pearl, 2009a). These algorithms take as input potential\\nvariables of interest (a graph with no edges, only nodes) and data for these variables.\\nThey output a proposed DAG that best fits the data.21\\nThe simplest algorithm is to generate all possible DAGs for existing variables and\\nthen evaluate each model based on some criteria (e.g., maximum likelihood, Bayesian\\ninformation criterion, etc.).22 Another method is to add edges that maximize the\\ncriteria greedily. This approach can be further improved by penalizing the model\\nfor complexity (based on additional criteria) and removing edges until the model is\\ngreedily optimized. The second approach is the Greedy Equivalence Search (GES)\\nalgorithm (Chickering, 2002), which we used on the data and from all the experiments\\n21These algorithms often do not presume a functional form, so we refer refer to hypotheses as\\nDAGs, not SCMs, in this section.\\n22The number of possible DAGs grows exponentially with the number of nodes. For example,\\nfor n = 1, 2, 3, and 4 nodes, there are 1, 3, 25, and 543 possible DAGs. This is a combinatorial\\nexplosion, and it is not feasible to evaluate all potential models for a large number of nodes, which\\npresents further problems for this approach.\\n25\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 26, 'text': 'in Section 3.23\\nIn some experiments, the algorithm incorrectly identified the causal structure.\\nFigure 8 provides the DAG identified by the GES algorithm for the tax fraud scenario.\\nAs a reminder, the original causal variables are the defendant’s previous convictions,\\nthe judge’s number of cases heard that day, and the defendant’s level of remorse,\\nand the outcome is the bail amount. The algorithm has no information about which\\nvariables are exogenously varied, just the raw data.\\nFigure 8: Incorrect causal structure identified by the GES algorithm for the tax\\nfraud experiment.\\nBail\\nAmount\\nCrime\\nHistory\\nRemorse\\nNum\\nCases\\nNotes: The Greedy Equivalence Search (GES) algorithm can incorrectly identify the causal structure\\nof observational data. In the tax fraud scenario, we know from Figure 3b and the accompanying\\nexperiment that an increase in the defendant’s previous convictions caused an increase in the av-\\nerage bail amount. However, the algorithm identified the causal relationship as equally likely in\\neither direction. Without the correctly specified DAG, a researcher would have to assume the causal\\nstructure of the data, which can be problematic.\\nThe GES algorithm identified the defendant’s criminal history and the bail amount\\nas the only variables in the scenario with any causal relationship. This is partially\\ncorrect—we know from the experiment that an increase in the defendant’s previous\\nconvictions caused an increase in the average bail amount. However, the algorithm\\nidentified the causal relationship as equally likely in either direction.\\nThere was\\nno more evidence in the data that the defendant’s criminal history caused the bail\\namount than the bail amount caused the defendant’s criminal history. And while we\\nknow that the former is correct from our experiment, a researcher using the algo-\\n23The GES algorithm is not perfectly stable; different runs on the same data can produce different\\nresults, which is its own problem.\\n26\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 27, 'text': 'rithm without the correctly specified DAG would not. They would have to make an\\nassumption, which, as we have shown, can be problematic.\\nThe SCM-based approach avoids search problems, as we never need to search\\nfor the causal structure given the data. Instead, we generate the data based on a\\nproposed causal structure. Even if we want to measure a new outcome on the existing\\nexperimental data, we have already identified the sources of exogenous variation.\\nWe should note that problems with searching for or assuming causal structures\\nfrom data are not new. Pearl (2009a) makes a similar point many times. However,\\nsocial scientists have never had the tools to induce exogenous variation and explore\\ncausal relationships at scale in many different scenarios.\\n6\\nConclusion\\nThis paper demonstrates an approach to automated in silico hypothesis generation\\nand testing made possible through the use of SCMs. We implemented the approach\\nby building a computational system with LLMs and provided evidence that simu-\\nlations can elicit information from an LLM that was not ex-ante available to the\\nmodel. We also showed that such simulations produce results that are highly con-\\nsistent with theoretical predictions made by the relevant economic theory. In this\\nfinal section, we will discuss why such systems could be useful and identify areas for\\nfuture research.\\n6.1\\nControlled experimentation at scale\\nHow might systems like the one presented in this paper be useful for social science\\nresearch? One view is that these simulations are simple dress rehearsals for “real”\\nsocial science. A more expansive and exciting view is that these simulations would\\nyield insights that sometimes generalize to the real world.\\nThis is a view that sees these agents as a step forward in representing humans\\nfar beyond classical methods in agent-based modeling, such as those used to explore\\nhow individual preferences can lead to surprising social patterns (Schelling, 1969,\\n27\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 28, 'text': '1971).24 This view would mirror recent advances in the use of machine learning for\\nprotein folding (Jumper et al., 2021) and material discovery (Merchant et al., 2023).\\nThe system presented in this paper can generate these controlled experimental\\nsimulations en masse with prespecified plans for data collection and analysis. That\\ncontrasts most academic social science research as currently practiced (Almaatouq\\net al., 2022).25 This contrast is important. In the social sciences, context can heavily\\ninfluence results. Outcomes that hold true for one population may not for another.\\nEven within the same population, a change in environment can nullify or flip re-\\nsults (Lerner et al., 2004). Studying humans is also expensive and time-consuming,\\nwhich makes rapid, inexpensive, and replicable exploration valuable. There is still,\\nof course, the fundamental jump from simulations to human subjects.\\n6.2\\nInteractivity\\nThe system allows a scientist to monitor its entire process.\\nShould a researcher\\ndisagree with or be uncertain about a decision made by the system, they can probe\\nthe system regarding its choice. This allows the researcher to either (1) understand\\nwhy the decision was made, (2) ask the system to come up with a different option\\nfor that decision, or (3) input their own custom choice for that decision.\\nA researcher can even ignore much of the automation process and fill in the details\\nthemselves. They can choose the variables of interest, their operationalizations, the\\nattributes of the agents, how the agents interact, or customize the statistical analysis,\\namong other decision points. Different parts of the system can also accommodate\\ndifferent types of LLMs simultaneously. For example, a researcher could use GPT-\\n4 to generate hypotheses and Llama-2-70B to power the agents’ simulated social\\ninteractions.\\n24See Horton (2023) for a full discussion on the differences between traditional agent-based mod-\\neling and the use of LLM-powered agents. This position reflects our views as it was written recently\\nby some of the authors of this paper.\\n25When a group of social scientists has the same data set on some human behavior or outcome,\\nthey can reach very different conclusions when analyzing it independently (Engzell, 2023; Salganik\\net al., 2020).\\n28\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 29, 'text': '6.3\\nReplicability\\nReplicating social science experiments with human subjects can be difficult (Camerer\\net al., 2018). Despite the use of preregistrations, the exact procedures used in exper-\\niments are often unclear (Engzell, 2023). In contrast, the system allows for nearly\\nfrictionless communication and replication of the experimental design.\\nThe system’s entire procedure is exportable as a JSON file with the fitted SCM.26\\nThis JSON includes every decision the system makes, including natural language\\nexplanations for the choices and the transcripts from each simulation. These JSONs\\ncan be saved or uploaded at any point in the system’s process. A researcher could run\\nexperiments and post the JSON and results online. Other scientists could inspect,\\nreplicate the experiment, or extend the work.\\n6.4\\nFuture research\\nWhile designing our system, we encountered several areas for new research. First is\\nthe problem of “which attributes” to endow an LLM-powered agent beyond those im-\\nmediately relevant to the proposed exogenous variables. For example, demographic\\ninformation, personalities, and other traits are not included in the agent’s attributes\\nunless they are a part of the SCM. To improve the fidelity of the simulations, it\\nmight make sense to add some or all of these attributes to the agents. However, it\\nis unclear how to optimize this process.\\nSecond, we encountered the problem of engineering social interactions between\\nLLM agents. LLMs are designed to exchange text in sequence, necessitating a pro-\\ntocol for turn-taking that reflects the natural ebb and flow of human conversation.\\nIn an initial attempt to address this problem, we created a menu of flexible agent-\\nordering mechanisms. We also introduced an additional LLM-powered agent into our\\nversion of the system whom we dub the ‘coordinator.” The coordinator functions\\nas a quasi-omniscient assistant who can read through transcripts and make choices\\n26A JSON (JavaScript Object Notation) is a data format that is easy for humans to read and\\nwrite and easy for machines to parse and generate. It is commonly used for transmitting data in\\nweb applications, as a configuration and data storage format, and for serializing and transmitting\\nstructured data over a network.\\n29\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 30, 'text': 'about the speaking order of other agents in the simulations. There are probably\\nbetter ways to determine the speaking order of agents.\\nA related problem is the question of when to stop the simulations. Like Turing’s\\nhalting problem, there is likely no universal rule for when conversations should end,\\nbut there are probably better rules than those we have implemented. A Markov\\nmodel approximating the distribution of agents speaking, estimated from real con-\\nversation data, might provide more naturalistic results for simulating and ending\\ninteractions, but that is an idea for future work.\\nLastly, if we can build a system that can automate one iteration of the scientific\\nprocess and determine a follow-on experiment, a clear next step is to set up an\\nintelligently automated research program. This would involve using outcomes from\\nthe simulations to inform continuous cycles of experimentation. Then, a researcher\\ncould intelligently explore a given scenario’s parameter space. How to optimize this\\nexploration amongst so many possible variables will be an important problem to\\nsolve.\\nAs presented in this paper, the system provides only one possible implementation\\nof the SCM-based approach. We made many subjective decisions. Other researchers\\nmight implement the approach with different design choices.\\nThere is room for\\nimprovement and exploration.\\n30\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 31, 'text': 'References\\nAher, Gati V, Rosa I Arriaga, and Adam Tauman Kalai, “Using large lan-\\nguage models to simulate multiple humans and replicate human subject studies,”\\nin “International Conference on Machine Learning” PMLR 2023, pp. 337–371.\\nAlmaatouq, Abdullah, Thomas L. Griffiths, Jordan W. Suchow, Mark E.\\nWhiting, James Evans, and Duncan J. Watts, “Beyond Playing 20 Ques-\\ntions with Nature: Integrative Experiment Design in the Social and Behavioral\\nSciences,” Behavioral and Brain Sciences, 2022, p. 1–55.\\nArgyle, Lisa P, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christo-\\npher Rytting, and David Wingate, “Out of one, many: Using language models\\nto simulate human samples,” Political Analysis, 2023, 31 (3), 337–351.\\nAtari, M., M. J. Xue, P. S. Park, D. E. Blasi, and J. Henrich, “Which\\nHumans?,” Technical Report 09 2023. https://doi.org/10.31234/osf.io/5b26t.\\nAthey, Susan, Jonathan Levin, and Enrique Seira, “Comparing open and\\nSealed Bid Auctions: Evidence from Timber Auctions*,” The Quarterly Journal\\nof Economics, 02 2011, 126 (1), 207–257.\\nBakker, Michiel, Martin Chadwick, Hannah Sheahan, Michael Tessler,\\nLucy Campbell-Gillingham,\\nJan Balaguer,\\nNat McAleese,\\nAmelia\\nGlaese, John Aslanides, Matt Botvinick, and Christopher Summerfield,\\n“Fine-tuning language models to find agreement among humans with diverse pref-\\nerences,” in S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh,\\neds., Advances in Neural Information Processing Systems, Vol. 35 Curran Asso-\\nciates, Inc. 2022, pp. 38176–38189.\\nBinz, Marcel and Eric Schulz, “Turning large language models into cognitive\\nmodels,” 2023.\\nand\\n, “Using cognitive psychology to understand GPT-3,” Proceedings of the\\nNational Academy of Sciences, 2023, 120 (6), e2218523120.\\n31\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 32, 'text': 'Brand, James, Ayelet Israeli, and Donald Ngwe, “Using GPT for Market\\nResearch,” Working paper, 2023.\\nBubeck,\\nS´ebastien,\\nVarun Chandrasekaran,\\nRonen Eldan,\\nJohannes\\nGehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi\\nLi, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\\nand Yi Zhang, “Sparks of Artificial General Intelligence: Early experiments with\\nGPT-4,” 2023.\\nBurns, C, H Ye, D Klein, and J Steinhardt, “Discovering latent knowledge in\\nlanguage models without supervision,” in “International Conference on Learning\\nRepresentations (ICLR)” 2023.\\nBuyalskaya, Anastasia, Hung Ho, Katherine L. Milkman, Xiaomin Li,\\nAngela L. Duckworth, and Colin Camerer, “What can machine learning\\nteach us about habit formation? Evidence from exercise and hygiene,” Proceedings\\nof the National Academy of Sciences, 2023, 120 (17), e2216115120.\\nCai, Alice, Steven R Rick, Jennifer L Heyman, Yanxia Zhang, Alexandre\\nFilipowicz, Matthew Hong, Matt Klenk, and Thomas Malone, “Desig-\\nnAID: Using Generative AI and Semantic Diversity for Design Inspiration,” in\\n“Proceedings of The ACM Collective Intelligence Conference” CI ’23 Association\\nfor Computing Machinery New York, NY, USA 2023, p. 1–11.\\nCamerer, Colin, Anna Dreber, Felix Holzmeister, Teck-Hua Ho, Jurgen\\nHuber, Magnus Johannesson, Michael Kirchler, Gideon Nave, Brian A.\\nNosek, Thomas Pfeiffer, Adam Altmejd, Nick Buttrick, Taizan Chan,\\nYiling Chen, Eskil Forsell, Anup Gampa, Emma Heikensten, Lily Hum-\\nmer, Taisuke Imai, Siri Isaksson, Dylan Manfredi, Julia Rose, Eric-Jan\\nWagenmakers, and Hang Wu, “Evaluating the Replicability of Social Science\\nExperiments in Nature and Science between 2010 and 2015,” Nature Human Be-\\nhaviour, Aug 2018, 2 (9), 637–644.\\n32\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 33, 'text': 'Cheng, Myra, Tiziano Piccardi, and Diyi Yang, “CoMPosT: Characterizing\\nand Evaluating Caricature in LLM Simulations,” ArXiv, 2023, abs/2310.11501.\\nChickering,\\nDavid Maxwell, “Optimal structure identification with greedy\\nsearch,” Journal of machine learning research, 2002, 3 (Nov), 507–554.\\nCinelli, Carlos, Andrew Forney, and Judea Pearl, “A crash course in good\\nand bad controls,” Sociological Methods & Research, 2022, p. 00491241221099552.\\nEngzell, Per, “A universe of uncertainty hiding in plain sight,” Proceedings of the\\nNational Academy of Sciences, 2023, 120 (2), e2218530120.\\nEnke, Benjamin and Cassidy Shubatt, “Quantifying Lottery Choice Complex-\\nity,” Working Paper 31677, National Bureau of Economic Research September\\n2023.\\nFish, Sara, Paul G¨olz, David C Parkes, Ariel D Procaccia, Gili Rusak, Itai\\nShapira, and Manuel W¨uthrich, “Generative Social Choice,” arXiv preprint\\narXiv:2309.01291, 2023.\\nGirotra, Karan, Lennart Meincke, Christian Terwiesch, and Karl T Ul-\\nrich, “Ideas are dimes a dozen: Large language models for idea generation in\\ninnovation,” Available at SSRN 4526071, 2023.\\nGurnee, Wes and Max Tegmark, “Language Models Represent Space and Time,”\\n2023.\\nHaavelmo, Trygve, “The statistical implications of a system of simultaneous equa-\\ntions,” Econometrica, Journal of the Econometric Society, 1943, pp. 1–12.\\n, “The probability approach in econometrics,” Econometrica:\\nJournal of the\\nEconometric Society, 1944, pp. iii–115.\\nHandel, Benjamin and Joshua Schwartzstein, “Frictions or Mental Gaps:\\nWhat’s Behind the Information We (Don’t) Use and When Do We Care?,” Journal\\nof Economic Perspectives, February 2018, 32 (1), 155–178.\\n33\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 34, 'text': 'Hern´an, Miguel A. and James M. Robins, Causal Inference: What If, Boca\\nRaton: Chapman & Hall/CRC, 2020.\\nHorton, John J, “Large language models as simulated economic agents: What\\ncan we learn from homo silicus?,” Technical Report, National Bureau of Economic\\nResearch 2023.\\nImai, Kosuke, Dustin Tingley, and Teppei Yamamoto, “Experimental De-\\nsigns for Identifying Causal Mechanisms,” Journal of the Royal Statistical Society\\nSeries A: Statistics in Society, 11 2012, 176 (1), 5–51.\\nJahani, Eaman, Samuel P. Fraiberger, Michael Bailey, and Dean Eckles,\\n“Long ties, disruptive life events, and economic prosperity,” Proceedings of the\\nNational Academy of Sciences, 2023, 120 (28), e2211062120.\\nJumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael\\nFigurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates,\\nAugustin ˇZ´ıdek, Anna Potapenko et al., “Highly accurate protein structure\\nprediction with AlphaFold,” Nature, 2021, 596 (7873), 583–589.\\nJ¨oreskog, Karl G., “A GENERAL METHOD FOR ESTIMATING A LINEAR\\nSTRUCTURAL EQUATION SYSTEM*,” ETS Research Bulletin Series, 1970,\\n1970 (2), i–41.\\nLerner, Jennifer S., Deborah A. Small, and George Loewenstein, “Heart\\nStrings and Purse Strings: Carryover Effects of Emotions on Economic Decisions,”\\nPsychological Science, 2004, 15 (5), 337–341. PMID: 15102144.\\nLi, Peiyao, Noah Castelo, Zsolt Katona, and Miklos Sarvary, “Frontiers:\\nDetermining the Validity of Large Language Models for Automated Perceptual\\nAnalysis,” Marketing Science, 2024, 0 (0), null.\\nLudwig, Jens and Sendhil Mullainathan, “Machine Learning as a Tool for\\nHypothesis Generation,” Working Paper 31017, National Bureau of Economic Re-\\nsearch March 2023.\\n34\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 35, 'text': 'Maskin, Eric S. and John G. Riley, “Auction Theory with Private Values,” The\\nAmerican Economic Review, 1985, 75 (2), 150–155.\\nMastroianni, Adam M., Daniel T. Gilbert, Gus Cooney, and Timothy D.\\nWilson, “Do conversations end when people want them to?,” Proceedings of the\\nNational Academy of Sciences, 2021, 118 (10), e2011809118.\\nMei, Qiaozhu, Yutong Xie, Walter Yuan, and Matthew O. Jackson, “A Tur-\\ning test of whether AI chatbots are behaviorally similar to humans,” Proceedings\\nof the National Academy of Sciences, 2024, 121 (9), e2313925121.\\nMerchant, Amil, Simon Batzner, Samuel S Schoenholz, Muratahan Aykol,\\nGowoon Cheon, and Ekin Dogus Cubuk, “Scaling deep learning for materials\\ndiscovery,” Nature, 2023, pp. 1–6.\\nMullainathan, Sendhil and Ashesh Rambachan, “From Predictive Algorithms\\nto Automatic Generation of Anomalies,” Technical Report May 2023. Available at:\\nhttps://ssrn.com/abstract=4443738 or http://dx.doi.org/10.2139/ssrn.\\n4443738.\\nPark, Joon Sung, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Mor-\\nris, Percy Liang, and Michael S Bernstein, “Generative agents: Interactive\\nsimulacra of human behavior,” arXiv preprint arXiv:2304.03442, 2023.\\nPatel, R. and E. Pavlick, “Mapping language models to grounded conceptual\\nspaces,” in “Proceedings of the International Conference on Learning Representa-\\ntions” 2021, p. 79.\\nPearl, J., M. Glymour, and N.P. Jewell, Causal Inference in Statistics: A\\nPrimer, Wiley, 2016.\\nPearl, Judea, “Causal inference in statistics: An overview,” Statistics Surveys,\\n2009, 3 (none), 96 – 146.\\n, Causality, Cambridge university press, 2009.\\n35\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 36, 'text': 'Peterson, Joshua C., David D. Bourgin, Mayank Agrawal, Daniel Reich-\\nman, and Thomas L. Griffiths, “Using large-scale experiments and machine\\nlearning to discover theories of human decision-making,” Science, 2021, 372 (6547),\\n1209–1214.\\nRajkumar, Karthik, Guillaume Saint-Jacques, Iavor Bojinov, Erik Bryn-\\njolfsson, and Sinan Aral, “A causal test of the strength of weak ties,” Science,\\n2022, 377 (6612), 1304–1310.\\nRosenbusch, Hannes, Claire E. Stevenson, and Han L. J. van der Maas,\\n“How Accurate are GPT-3’s Hypotheses About Social Science Phenomena?,” Dig-\\nital Society, July 2023, 2 (2), 26.\\nRosseel, Yves, “lavaan: An R Package for Structural Equation Modeling,” Journal\\nof Statistical Software, 2012, 48 (2), 1–36.\\nSacerdote, Bruce, “Peer Effects with Random Assignment: Results for Dartmouth\\nRoommates*,” The Quarterly Journal of Economics, 05 2001, 116 (2), 681–704.\\nSalganik, Matthew J., Ian Lundberg, Alexander T. Kindel, Caitlin E.\\nAhearn, Khaled Al-Ghoneim, Abdullah Almaatouq, Drew M. Altschul,\\nJennie E. Brand, Nicole Bohme Carnegie, Ryan James Compton,\\nDebanjan Datta, Thomas Davidson, Anna Filippova, Connor Gilroy,\\nBrian J. Goode,\\nEaman Jahani,\\nRidhi Kashyap,\\nAntje Kirchner,\\nStephen McKay, Allison C. Morgan, Alex Pentland, Kivan Polimis,\\nLouis Raes, Daniel E. Rigobon, Claudia V. Roberts, Diana M. Stanescu,\\nYoshihiko Suhara, Adaner Usmani, Erik H. Wang, Muna Adem, Ab-\\ndulla Alhajri, Bedoor AlShebli, Redwane Amin, Ryan B. Amos, Lisa P.\\nArgyle, Livia Baer-Bositis, Moritz B¨uchi, Bo-Ryehn Chung, William\\nEggert, Gregory Faletto, Zhilin Fan, Jeremy Freese, Tejomay Gadgil,\\nJosh Gagn´e, Yue Gao, Andrew Halpern-Manners, Sonia P. Hashim, So-\\nnia Hausen, Guanhua He, Kimberly Higuera, Bernie Hogan, Ilana M.\\nHorwitz, Lisa M. Hummel, Naman Jain, Kun Jin, David Jurgens,\\n36\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 37, 'text': 'Patrick Kaminski, Areg Karapetyan, E. H. Kim, Ben Leizman, Naijia\\nLiu, Malte M¨oser, Andrew E. Mack, Mayank Mahajan, Noah Man-\\ndell, Helge Marahrens, Diana Mercado-Garcia, Viola Mocz, Katari-\\nina Mueller-Gastell, Ahmed Musse, Qiankun Niu, William Nowak,\\nHamidreza Omidvar, Andrew Or, Karen Ouyang, Katy M. Pinto,\\nEthan Porter, Kristin E. Porter, Crystal Qian, Tamkinat Rauf, Anahit\\nSargsyan, Thomas Schaffner, Landon Schnabel, Bryan Schonfeld, Ben\\nSender, Jonathan D. Tang, Emma Tsurkov, Austin van Loon, Onur\\nVarol, Xiafei Wang, Zhi Wang, Julia Wang, Flora Wang, Saman-\\ntha Weissman, Kirstie Whitaker, Maria K. Wolters, Wei Lee Woon,\\nJames Wu, Catherine Wu, Kengran Yang, Jingwen Yin, Bingyu Zhao,\\nChenyun Zhu, Jeanne Brooks-Gunn, Barbara E. Engelhardt, Moritz\\nHardt, Dean Knox, Karen Levy, Arvind Narayanan, Brandon M. Stew-\\nart, Duncan J. Watts, and Sara McLanahan, “Measuring the predictability\\nof life outcomes with a scientific mass collaboration,” Proceedings of the National\\nAcademy of Sciences, 2020, 117 (15), 8398–8403.\\nSanturkar, Shibani, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang,\\nand Tatsunori Hashimoto, “Whose Opinions Do Language Models Reflect?,”\\n2023.\\nSchelling, Thomas C, “Models of segregation,” The American economic review,\\n1969, 59 (2), 488–493.\\n, “Dynamic models of segregation,” Journal of mathematical sociology, 1971, 1 (2),\\n143–186.\\nScherrer, Nino, Claudia Shi, Amir Feder, and David Blei, “Evaluating the\\nmoral beliefs encoded in llms,” Advances in Neural Information Processing Sys-\\ntems, 2024, 36.\\nSimon, Herbert A., The Sciences of the Artificial, 3rd Edition number 0262691914.\\nIn ‘MIT Press Books.’, The MIT Press, September 1996.\\n37\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 38, 'text': 'Turing, A. M., “On Computable Numbers, with an Application to the Entschei-\\ndungsproblem,” Proceedings of the London Mathematical Society, 1937, s2-42 (1),\\n230–265.\\nT¨ornberg, Petter, Diliara Valeeva, Justus Uitermark, and Christopher\\nBail, “Simulating Social Media Using Large Language Models to Evaluate Alter-\\nnative News Feed Algorithms,” 2023.\\nWager, Stefan and Susan Athey, “Estimation and Inference of Heterogeneous\\nTreatment Effects using Random Forests,” Journal of the American Statistical\\nAssociation, 2018, 113 (523), 1228–1242.\\nWei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi,\\nQuoc Le, and Denny Zhou, “Chain of Thought Prompting Elicits Reasoning\\nin Large Language Models,” CoRR, 2022, abs/2201.11903.\\nWright, Sewall, “The method of path coefficients,” The annals of mathematical\\nstatistics, 1934, 5 (3), 161–215.\\nZheng, Stephan, Alexander Trott, Sunil Srinivasa, David C Parkes, and\\nRichard Socher, “The AI Economist: Taxation policy design via two-level deep\\nmultiagent reinforcement learning,” Science advances, 2022, 8 (18), eabk2607.\\n38\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 39, 'text': 'A\\nImplementation details\\nThe first step in the system’s process is to query an LLM for the roles of the relevant\\nagents in the scenario. When we say “query an LLM,” we mean this quite literally.\\nWe have written a scenario-neutral prompt that the system provides to an LLM with\\nthe scenario added to the prompt. The prompt is scenario-neutral because we can\\nreuse it for any scenario. The prompt takes the following format:\\nIn the following scenario: “{scenario description}”, Who are the in-\\ndividual human agents in a simple simulation of this scenario?\\nwhere {scenario description} is replaced with the scenario of interest. The LLM\\nthen returns a list of agents relevant to the scenario, and we have various checking\\nmechanisms to ensure the LLM’s response is valid.\\nThe system contains over 50 pre-written scenario-neutral prompts to gather all\\nthe information needed to generate the SCM, run the experiment, and analyze the\\nresults. These prompts have placeholders for the necessary information aggregated\\nin the system’s memory as it progresses through the different parts of the process.\\nA.1\\nConstructing variables and drawing causal paths\\nThe system builds SCMs variable-by-variable. It queries an LLM for an outcome\\ninvolving the agents in the social scenario of interest.\\nWe refer to outcomes as\\nendogenous variables because their values are realized during the experiment. This\\ncontrasts exogenous variables, the causes, whose values are determined before the\\nexperiment.\\nThe system queries the LLM for a list of possible exogenous causes of the en-\\ndogenous variable, generating a hypothesis as an SCM.27 Exogenous variables serve\\nas inputs to the experiment, whose values can be deterministically manipulated to\\nidentify causal effects. The system assumes that when an exogenous variable causes\\nan endogenous variable, a single causal path is proposed from the exogenous variable\\n27There is growing evidence that LLMs can be quite good at coming up with ideas and generating\\nhypotheses (Girotra et al., 2023; Rosenbusch et al., 2023).\\n39\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 40, 'text': 'to the endogenous variable. More formally, the system always generates SCMs as a\\nsimple linear model. The system currently generates all SCMs with one endogenous\\nvariable and as many exogenous causes as a researcher desires. We do little optimiza-\\ntion here, although the system can test for interaction terms. In future iterations\\nof the system, a researcher could choose outcomes and causes they are interested\\nin, score hypotheses by interestingness, and generate more complex hypotheses with\\nmediating endogenous variables.28\\nA.1.1\\nEndogenous outcomes\\nFor each endogenous variable, the system generates an operationalization, a type, the\\nunits, the possible levels, the explicit questions that need to be asked to measure the\\nvariable’s realized value, and how the answers to those questions will be aggregated\\nto get the final data for analysis. Examples of all information collected about the\\nvariables in an SCM are provided in Table A.3. Each piece of information about a\\nvariable is stored by the system and is then used to determine subsequent informa-\\ntion in consecutive scenario-neutral prompts. This is a kind of “chain-of-thoughts\\nprompting”, or the process of breaking down a complex prompt into a series of sim-\\npler prompts. This method can dramatically improve the quality and robustness of\\nan LLM’s performance (Wei et al., 2022).\\nThe first piece of information determined for each endogenous variable is the\\noperationalization. That is, how the possible realizations of said variable can be\\ndirectly mapped to measurable outcomes that can be observed and quantified. Sup-\\npose the outcome variable is whether or not a deal occurred from the SCM in\\nFigure 2b.29 The system could operationalize this as a binary variable, where ‘‘1’’\\nmeans a deal occurred and ‘‘0’’ does not. It then stores this information and\\nuses it in a scenario-neutral prompt to choose the variable type.\\nAll variables are determined to be one of five mutually exclusive “types.” These\\n28Parallel and crossover experimental designs can be used to identify mediating causal relation-\\nships (Imai et al., 2012). These experiments require few assumptions, which are often more plausible\\nwhen researchers have more control over the experiment, as they usually do with LLMs.\\n29We continue the practice from Section 2 of using typewriter text to denote example infor-\\nmation from the system.\\n40\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 41, 'text': 'are continuous, ordinal, nominal, binary, or count. By selecting a unique type for\\neach variable, the system can accommodate different distributions when estimating\\nthe fitted SCM after the experiment.\\nEach variable also has units. The units are the specific measure or standard used\\nto represent the variable’s quantified value. This information is used to improve the\\nrobustness and consistency of the system’s output when querying the LLM for other\\ninformation about a variable.\\nThe levels of the variable represent all of the values the variable can realize in\\na short list. They can take on different forms depending on the variable type, but\\nthey all follow a general pattern where they are defined by the range and nature of\\na variable’s possible values.30\\nTo measure the endogenous outcome, the system generates survey questions for\\none of the agents.\\nFor example, to measure whether or not a deal occurred,\\nthe system could ask the buyer or the seller, “Did you agree to buy the mug?”\\nOr, if the endogenous variable was the final price of the mug, the system could\\nask one of the agents, “How much did you sell the mug for?” Even though the\\nsimulations have yet to be conducted, the system generates survey questions. As\\nwith pre-registration, this reduces unneeded degrees of freedom in the data collection\\nprocess after the experiment.\\nMost endogenous variables are measured with only one question. In this case,\\nthe answer to this question is the only information needed to quantify the variable.\\nSometimes, it takes more than one survey question to measure a variable. Maybe the\\nvariable is the average satisfaction of the buyer and the seller; a variable\\nthat requires two separate measurements to quantify. In this case, the system gener-\\nates separate measurement questions to elicit the buyer’s and the seller’s satisfaction.\\nThen, the system averages the answers to the questions to measure the variable.\\n30For binary variables, the levels are the two possible outcomes. For ordinal variables, the levels\\ninclude all possible values that the ordinal variable could take on as determined by its operational-\\nization.\\nThe levels are selected for count and continuous variables by segmenting the range of\\npossible values into discrete intervals. In cases where the variable does not have a defined maxi-\\nmum or minimum, categories such as “above X” or “below Y” are included to ensure all possible\\nvalues are covered.\\n41\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 42, 'text': 'We pre-programmed a menu of 6 mechanical aggregation methods: finding the\\nminimum, maximum, average, mode, median, or sum of a list of values. If the system\\nneeds to combine the answers to multiple questions to measure a variable, it queries\\nan LLM to select the appropriate aggregation method. Then, the system uses a\\npre-written Python function to perform said aggregation. We refrain from asking\\nthe LLM to perform mathematical functions whenever possible, as they often make\\nmistakes.\\nA.1.2\\nExogenous causes\\nBesides the explicit measurement questions and data aggregation method, the system\\ncollects the same information for the exogenous variables as it does for the endogenous\\nvariables. For exogenous variables, these two pieces of information are unnecessary\\nfor measurement. In each simulation of the social scenario, a different combination\\nof the values of the exogenous variables is initialized. This is how the system induces\\nvariation in an experiment, so the treatments are always known to the system ex-\\nante.\\nCausal variables can have one of two possible “scopes.” The scope can be specific\\nto an individual agent or the scenario as a whole. This scope determines how the\\nsystem induces variation in the exogenous variables—at the agent or scenario level.\\nIndividual-level variables are further designated as either public or private. If private,\\nthe variable’s values are only provided to one agent; if public, they are treated as\\ncommon knowledge to all agents in the scenario.\\nThe system induces variation in the exogenous variables by transforming them\\ninto manageable proxy attributes for the agents. The system queries an LLM to cre-\\nate a second-person phrasing of the operationalized variable provided to the agent\\n(or agents, depending on the scope). For instance, with the buyer’s budget vari-\\nable, the attribute could be “your budget” for the buyer. These attributes will be\\nassigned to the agents, which we discuss in Section A.2.\\nWith the proxy attribute for the variable, the system queries an LLM for possible\\nvalues the attribute can take on. These are the induced variations—the treatment\\n42\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 43, 'text': 'conditions for the simulated experiments. By default, the system uses the levels, or a\\nvalue within each level, of the variable for the possible variation values. For example,\\nthese could be {$5, $10, $20, $40} for the buyer’s budget.\\nA.2\\nBuilding hypothesis-driven agents\\nIn conventional social science research, human subjects are catch as catch can. Here,\\nwe have to construct them from scratch. By “construct” we mean that we prompt\\nan LLM to be a person with a set of attributes. This is quite literal; for example,\\nwe could construct an agent in a negotiating scenario with the following prompt:\\n“You are a buyer in a negotiation scenario with a seller. You are negoti-\\nating over a mug. You have a budget of $20.”\\nWe can construct an agent with any set of attributes we want, which raises the\\nquestion of what attributes we should use.\\nWe already have the attributes that will be varied to test the SCM, but there are\\nmany others we could include. Some work has explored the endowing of agents with\\nmany different attributes, but it is unclear what is optimal, sufficient, or even neces-\\nsary.31 We take a minimalist approach, endowing our agents with goals, constraints,\\nroles, names, and any relevant proxy attributes for the exogenous variables. In the\\nfuture, we could integrate large numbers of diverse agents, perhaps constructed to\\nbe representative of some specific population.\\nA.2.1\\nAssigning agents attributes\\nThe system collects information for agents independently, similar to its one-at-a-time\\napproach with the variables in the SCM. The system randomly selects an agent,\\n31The methods have varied, ranging from endowing agents with interesting attributes (Argyle et\\nal., 2023; Horton, 2023) to using American National Election Study data to create “real” people\\n(T¨ornberg et al., 2023) to demonstrating that endowing demographic information does not nec-\\nessarily represent a population of interest (Atari et al., 2023; Santurkar et al., 2023). There is a\\nbalance to be struck. While attributes can provide a rich and nuanced simulation, they can also\\nlead to redundancy, inefficiency, and unexpected interactions. In contrast, too few attributes might\\nresult in an oversimplified and unrealistic portrayal of social interactions.\\n43\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 44, 'text': 'determines its attributes, and then moves on to the next agent.32 Examples of buyer\\nand seller agents with their attributes are provided in Figure A.1.\\nFigure A.1: Example agents generated by the system for “two people bargaining\\nover a mug”\\nNotes: In all simulations, agents are endowed with a randomly generated name, role, goal, con-\\nstraint, and proxy attributes for the exogenous variables. To simulate the experiment for the agents\\nin this figure, the system will generate four versions of the seller and four versions of the buyer,\\neach with one of the values for the exogenously varied attributes (assuming there are four possible\\nvalues for “Your sentimental attachment”). That is 4 × 4 = 16 treatments.\\nFor each agent, the system queries the LLM for a random name. Agents perform\\nbetter in simulations with identifiers to address one another, although this feature\\ncan be disabled. An agent’s name can also be varied as a proposed exogenous cause.\\nThe system then queries an LLM again, this time for a goal and then a constraint,\\nwhich we discuss in the following subsection.\\nFinally, the system cross-checks the values of the proxy attributes between the\\nagents to ensure they overlap appropriately. For example, if the two exogenous vari-\\nables in the SCM were the buyer’s budget and the seller’s minimum acceptable\\n32The system already has the agent’s roles from the construction of the SCM.\\n44\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 45, 'text': 'price, the system would check to make sure that the seller’s minimum acceptable\\nprice is not invariably higher than the buyer’s budget. We let the LLM deter-\\nmine if these attribute values overlap appropriately. If any discrepancies are found,\\nthe system queries the LLM again to resolve them with new values for the proxy\\nattributes. Otherwise, the simulated experiment would waste time and resources\\nbecause the induced variations were not supported across reasonable values. For ex-\\nample, if the buyer’s budget was always below the seller’s minimum acceptable\\nprice, then they might never make a deal.\\nA.2.2\\nThe importance of agent goals\\nUnlike, say, economic agents, whose goals are expressed via explicit utility func-\\ntions, the LLM agent’s goals are expressed in natural language. In the context of\\nour bargaining scenario, an example goal generated by our system for the seller\\nis to sell the mug at the highest price possible. An example constraint is\\nto not accept a price below your minimum selling price. These goals and\\nconstraints are oriented towards value, but they do not have to be; these are merely\\nthe ones generated by the system. A constraint could just have easily been do not\\nruin your reputation with your negotiating partner.\\nWe do not take a prescriptive stance on what these goals should be. We let the\\nsystem decide what is reasonable. These goals can, of course, also be the object of\\nstudy in their own right; researchers can vary them or choose their own, but they\\nare seemingly fundamental to any social science for reasons laid out in Simon (1996).\\nTherefore, explicit goals are a requirement for agents in our system.\\nA.3\\nSimulation design and execution\\nLLMs are designed to produce text. And since an independent LLM powers each\\nagent, one agent must finish speaking before the next begins. So, in any multi-agent\\nsimulation, there must be a speaking order, which raises the question of how the\\nsystem should determine this speaking order. Unfortunately, most human conver-\\nsations do not have an obvious order; people collectively figure out how to interact.\\n45\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 46, 'text': 'We centralize this process, but we could imagine a consensus protocol for who speaks\\nnext.\\nIn more straightforward settings with only two agents (e.g., two people bargaining\\nover a mug), the only possible conversational order is for the agents to alternate\\nspeaking. As the number of agents in interaction increases beyond two, the number\\nof possible speaking orders grows factorially. For example, with three agents, there\\nare 3! = 6 ways to order them; with 4 agents, 4! = 24 orderings, and so on. However,\\nthe number of possible orderings of the agents is only part of the complexity.\\nWho speaks next in a given conversation is a product of the participants’ per-\\nsonalities, the setting of the conversation, the social dynamics between the speakers,\\nthe emotional state of the participants, and many other factors.\\nThey are also\\nadaptive—often, the speaking order changes throughout a conversation. For exam-\\nple, in a court proceeding, the judge usually guides the interaction—signaling who\\nspeaks between the lawyers, witnesses, and the jury. Each contributes at various\\nand irregular intervals depending on both the type and stage of the proceeding. In a\\nfamily of two parents and two children, the order of who speaks next varies greatly.\\nIt might depend on the parents’ moods or how annoying the children have been that\\nday. In contrast, the teacher is typically the main speaker in a high school classroom,\\nalthough this varies depending on the classroom activity, such as a lecture versus a\\ngroup discussion. No simple universal formula exists for who speaks next in such\\ndiverse settings.\\nLike the aggregation methods for outcomes determined by multiple measurement\\nquestions, we designed a menu of six interaction protocols. The system queries an\\nLLM to select the appropriate protocol for a given scenario. Figure A.2 provides the\\nmenu, and we discuss each in turn.\\nA.3.1\\nTurn-taking protocols\\nThe first interaction protocol is the ordered protocol (Figure A.2, option 1), where\\nthe agents speak in a predetermined order and continue repeatedly speaking in that\\norder until the simulation is complete. Next is the random protocol. An agent is\\n46\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 47, 'text': 'Figure A.2: Menu of interaction protocols for the system to choose from for a given\\nscenario.\\nNotes: (1) The agents speak in a predetermined order. (2) The agents speak in a random order. (3)\\nA central agent alternates speaking with non-central agents in a predetermined order. (4) A central\\nagent alternates speaking with non-central agents in random order. (5) A separate LLM (whom\\nwe call the coordinator) determines who speaks next based on the conversation. (6) Each agent\\nresponds privately to the conversation so far, and the coordinator realizes one of the responses.\\nrandomly selected to speak first (Figure A.2, option 2).\\nThen, each subsequent\\nspeaker is randomly selected, with the only restriction being that no agent can speak\\ntwice in a row.\\nIn more complex scenarios with a central agent—an agent that speaks more than\\nall others—like an auction with an auctioneer or a teacher in a classroom, the system\\ncan choose the central-ordered or central-random protocols (Figure A.2, options\\n3 and 4). The former features a central agent who interacts alternately with a series\\nof non-central agents, following a predetermined order among the non-central agents.\\nThe latter also has a central agent alternating with the non-central agents but in\\nrandom order. Whenever there is an order of agents or a central agent, we also query\\n47\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 48, 'text': 'the system to determine this order.\\nFinally, we designed two interaction protocols that provide more flexibility. These\\ninteraction protocols involve a separate LLM-powered agent: “the coordinator.” The\\ncoordinator can read through transcripts of the conversations and make decisions\\nabout the simulations when necessary. It can also answer measurement questions\\nafter the experiment. The agents are not aware of the coordinator. The use of the\\ncoordinator is the only part of the system that needs quasi-omniscient supervision.\\nFortunately, LLMs perform so well that they can be used to automate this role.\\nIn the coordinator-before protocol (Figure A.2, option 5), the coordinator is\\ngiven the transcript of the conversation after each agent speaks. Then, it selects the\\nnext speaker.\\nIn the coordinator-after protocol (Figure A.2, option 6), after each agent\\nspeaks, all the agents respond, but only the coordinator can see the responses along\\nwith the transcript of the conversation up to that point.\\nThen, the coordinator\\nchooses the response to “realize” as the real response.\\nThe realized response is\\nadded to the conversation’s transcript, and the rest are deleted as if they had never\\nbeen made. The only limitation in either of the coordinator protocols is that no\\nagent can speak twice in a row.\\nA.3.2\\nExecuting the experimental simulations\\nThe system runs each experimental simulation in parallel, subject to the computa-\\ntional constraints of the researcher’s machine. When the exogenous variable’s values\\npresent too many combinations to sample from, a subset is randomly selected. In\\nevery simulation, agents are provided with a description of the scenario, their unique\\nprivate attributes, the other agents’ roles, any public or scenario-level attributes,\\nand access to the transcript of the conversation. Then, they interact according to\\nthe chosen interaction protocol. However, none of the protocols specify when the\\nsimulation should end.\\nIt is not obvious how to construct an optimal, nor even good, stopping rule.\\nHuman conversations are unpredictable and do not always end when we expect them\\n48\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 49, 'text': 'to or want them to (Mastroianni et al., 2021). An analogous issue is the halting\\nproblem in computer science, which is the problem of determining when, if ever,\\nan arbitrary computer program will stop. Turing (1937) proved that no universal\\nalgorithm exists to solve the halting problem.\\nWe implemented a two-tier mechanism to determine when to stop each simulation.\\nThese apply to all interaction protocols. After each agent speaks, the coordinator\\nreceives the transcript and decides if the conversation should continue—a yes or no\\ndecision. Additionally, simulations are limited to 20 statements across all agents in\\nthe scenario, not including the coordinator.33 Agents are provided a live count of\\nthe remaining statements during the conversation.\\nA.3.3\\nPost-simulation survey and data collection\\nAfter the experiment, the system conducts a post-experiment survey. As determined\\nduring the SCM construction, the system asks the relevant agents or the coordinator\\nthe survey questions to measure the outcome variable in each simulation. The system\\nthen takes this question’s raw answer and saves it as an observation along with the\\nvalues of the exogenous variables. If there is no reasonable answer to the question,\\nsay, if the outcome is conditional, then the system will report an NA for the variable’s\\nvalue.\\nOnce the system has the answer to the survey question, it queries an LLM with\\nthe survey question, the agent’s response, and information about the variable’s type\\nto determine its correct numerical value as a string. If the variable is a count or\\ncontinuous variable, it is converted into an integer or a float.\\nIf the variable is\\nordinal or binary, the system queries an LLM to map it to a whole-number integer\\nsequence. If multiple survey questions determine a variable, the system aggregates\\nthe answers to the questions using the method selected during the SCM construction\\nphase. Then, it converts the aggregated value to the appropriate type. After parsing\\n33Limiting the number of turns in the simulation is partially a convenience. As of the time of\\nrunning the simulations for this paper, GPT-4 has a maximum token limit of 8,192 tokens, and the\\nsystem must provide each agent with the entire conversation up to that point each time they need\\nto speak.\\n49\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 50, 'text': 'the data for each outcome, the system has a data frame with one column of numerical\\nvalues for each variable in the SCM.\\nA.4\\nPath estimation & model fit\\nWith a complete dataset and the proposed SCM, the system can estimate the linear\\nSCM without further queries to an LLM. The system uses the R package lavaan to\\nestimate all paths in the model (Rosseel, 2012).34 The system can standardize all\\nestimates, estimate interactions and non-linear terms, and view various summary\\nstatistics for each variable. It can also provide likelihood ratio, Wald, and Lagrange\\nMultiplier tests to evaluate the model fit and compare path estimates. The system\\ncan do any statistical estimation or test that is built into lavaan.\\nA.5\\nFollow-on experiments\\nAlthough we have not yet automated this process, the system can perform follow-\\non experiments. Insignificant exogenous variables from the first experiment can be\\ndropped. Then, the system could query an LLM for new exogenous variables based\\non what might be interesting, given the already tested causal paths. The system\\nwould use the same agents and interaction protocol, but the agents would vary\\non the new exogenous variables and the old ones that were significant in the first\\nexperiment. Theoretically, the system can run follow-on experiments ad infinitum,\\nand we can imagine future models that could be very good at proposing potential\\ncausal relationships.\\nB\\nHypotheses as structural causal models\\nHypotheses stated in natural language can be ambiguous, making it challenging to\\ndiscern precise implied causal relationships. Suppose a researcher is interested in\\n34For those familiar with lavaan and Python, the system automatically generates the correctly\\nformatted string in lavaan syntax using a Python dictionary that stores the structure of the SCM\\nin key-value pairs.\\n50\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 51, 'text': 'Figure A.3: Valid graphical interpretations of the same natural language\\nhypothesis.\\nBuyer\\nBudget\\nSeller\\nAttach\\nDeal\\nOccurs\\n(a) Independent causes\\nBuyer\\nBudget\\nSeller\\nAttach\\nDeal\\nOccurs\\n(b) Mediation\\nBuyer\\nBudget\\nSeller\\nAttach\\nDeal\\nOccurs\\n(c) Alternative mediation\\nNotes: Each directed acyclic graph (DAG) is a valid causal interpretation of the following natu-\\nral language hypothesis: “The buyer’s budget and the seller’s sentimental attachment to the mug\\ncausally affect whether a deal occurs.” In contrast, each DAG is unique in its declaration of the\\ncausal relationships. In DAGs, each arrow represents a direct causal relationship, and the absence\\nof an arrow between two variables indicates no causal relationship. If a variable is not included in\\nthe graph, then there is no stated causal relationship about this variable. While DAGs are unam-\\nbiguous in their causal claims about which variables cause which other variables, they do not make\\nany claims about the functional form of the relationships between variables.\\ntwo-person bargaining scenarios with a buyer and a seller. And she has the following\\nnatural language hypothesis about two people bargaining over a mug: “the buyer’s\\nbudget and the seller’s sentimental attachment to the mug causally affect whether\\na deal occurs.”\\nFigure A.3 offers three ways we can interpret this causal state-\\nment: (A.3a) the budget and the sentimental attachment could independently affect\\nwhether a deal occurs, (A.3b) the budget could mediate the relationship between the\\nattachment and the outcome, or (A.3c), the mediation could be reversed.35\\nFor (A.3a), an example could be an online marketplace where the buyer and seller\\ncannot communicate. When the buyer has a higher budget, she is more likely to buy\\nthe mug. If the seller is more sentimentally attached to the mug, he may raise the\\nprice and, therefore, lower the probability of a deal. However, without any form\\nof communication, these causal variables would not affect each other. For (A.3b),\\nif the buyer and the seller can communicate and the seller realizes that the buyer\\n35This list of interpretations is not exhaustive.\\n51\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 52, 'text': 'is willing to spend more, he might become more attached to the mug and value it\\nhigher because of the increased potential sale price. Finally, for (A.3c), the mediated\\nrelationship could be reversed. If the buyer sees that the seller is attached to the\\nmug, this may cause her to increase her budget, which increases the probability of\\na deal. The ambiguity of stating even simple hypotheses makes natural language\\ninsufficient for our purposes.\\nThe graphs in Figure A.3 are directed acyclic graphs (DAGs) and represent causal\\nrelationships. DAGs unambiguously state whether a variable is a direct cause of\\nanother variable—the direction of the arrow indicates the direction of the causal\\nrelationship (Hern´an and Robins, 2020).\\nThe absence of an arrow between two\\nvariables indicates no causal relationship. If a variable is not included in the graph,\\nthen there is no stated causal relationship involving this variable.\\nWhile DAGs are clear in their claims about which variables cause others, they\\ndo not make any statements about the functional form of the relationships between\\nvariables. In contrast, structural causal models unambiguously state the causal re-\\nlationships between variables and the functional forms of these relationships (Pearl\\net al., 2016).\\nStructural causal models (SCM), as first explored by Wright (1934), represent\\nhypotheses as sets of equations. Suppose we assume the relationships between the\\nvariables in Figure A.3 are linear. We can write an SCM for each of the DAGs.\\nFigure A.3a can be stated as:\\nDealOccurs = β1BuyerBudget + β2SellerAttachment + ϵ;\\n(1)\\nFigure A.3b as:\\nBuyerBudget = β0SellerAttachment + η\\n(2)\\nDealOccurs = β1BuyerBudget + β2SellerAttachment + ϵ;\\n(3)\\nand Figure A.3c as:\\nSellerAttachment = β0BuyerBudget + η\\n(4)\\nDealOccurs = β1BuyerBudget + β2SellerAttachment + ϵ.\\n(5)\\nThe set of equations that represent the causal relationships between variables\\nmake the SCM. We could also write each SCM with interaction terms for some or\\n52\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 53, 'text': 'all of the causes or even use other types of link functions, and these would all be\\nequally valid representations of the corresponding DAGs.\\n53\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 54, 'text': 'C\\nAdditional figures and tables\\nFigure A.4: Fitted SCM with interaction terms for “two people bargaining over a\\nmug.”\\ndeal-for-mug\\nµ = 0.50\\nσ2 = 0.25\\nsell-love-mug\\nµ = 3.00\\nσ2 = 2.00\\nbuyers-budget\\n-x-\\nsell-love-mug\\nµ = 36.67\\nσ2 = 826.22\\nbuyers-budget\\n-x-\\nsell-min-mug\\nµ = 148.02\\nσ2 = 16787.95\\nsell-min-mug\\nµ = 12.11\\nσ2 = 49.43\\nsell-min-mug\\n-x-\\nsell-love-mug\\nµ = 36.33\\nσ2 = 837.11\\nbuyers-budget\\nµ = 12.22\\nσ2 = 47.95\\n0.032\\n(0.007)\\n-0.045\\n(0.007)\\n-0.094\\n(0.032)\\n-0.000\\n(0.000)\\n0.002\\n(0.002)\\n0.004\\n(0.002)\\nNotes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\\ndardized path estimate and standard error. There were 405 simulations with these agents: [‘buyer’,\\n‘seller’].\\n54\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 55, 'text': 'Figure A.5: Fitted SCM with interaction terms for “a judge is setting bail for a\\ncriminal defendant who committed 50,000 dollars in tax fraud.”\\nbail-amt\\nµ = 54428.57\\nσ2 = 186000000.00\\nnum-judge-cases\\n-x-\\ndef-remorse\\nµ = 29.57\\nσ2 = 865.10\\ndef-crim-hist\\nµ = 4.71\\nσ2 = 17.06\\ndef-crim-hist\\n-x-\\nnum-judge-cases\\nµ = 46.47\\nσ2 = 4053.35\\ndef-crim-hist\\n-x-\\ndef-remorse\\nµ = 14.14\\nσ2 = 232.12\\ndef-remorse\\nµ = 3.00\\nσ2 = 2.00\\nnum-judge-cases\\nµ = 9.86\\nσ2 = 60.98\\n303.4\\n(545.5)\\n383.9\\n(282.6)\\n-29.6\\n(1180.9)\\n-1.301\\n(26.231)\\n77.0\\n(144.8)\\n-150.8\\n(76.6)\\nNotes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\\ndardized path estimate and standard error. There were 245 simulations with these agents: [‘judge’,\\n‘defendant’, ‘defense attorney’, ‘prosecutor’].\\n55\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 56, 'text': 'Figure A.6: Fitted SCM with interaction terms for “a person is interviewing for a\\njob as a lawyer.”\\nhire-decision\\nµ = 0.62\\nσ2 = 0.23\\ninter-friendly\\n-x-\\njob-app-height\\nµ = 2130.00\\nσ2 = 1600775.00\\njob-app-height\\nµ = 177.50\\nσ2 = 131.25\\nbar-exam-pass\\n-x-\\njob-app-height\\nµ = 88.75\\nσ2 = 7942.19\\nbar-exam-pass\\n-x-\\ninter-friendly\\nµ = 6.00\\nσ2 = 61.00\\nbar-exam-pass\\nµ = 0.50\\nσ2 = 0.25\\ninter-friendly\\nµ = 12.00\\nσ2 = 50.00\\n1.704\\n(1.053)\\n-0.013\\n(0.074)\\n0.005\\n(0.007)\\n0.005\\n(0.010)\\n-0.006\\n(0.006)\\n0.000\\n(0.000)\\nNotes: Each variable is given with its mean and variance. The edges are labeled with their un-\\nstandardized path estimate and standard error. There were 80 simulations with these agents: [‘job\\napplicant’, ‘employer’].\\n56\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 57, 'text': 'Figure A.7: Fitted SCM with interaction terms for “3 bidders participating in an\\nauction for a piece of art starting at fifty dollars.”\\nfinal-art-price\\nµ = 186.53\\nσ2 = 3867.92\\nbid1-max-budget\\n-x-\\nbid2-max-budg\\nµ = 40000.00\\nσ2 = 900000000.00\\nbid1-max-budget\\nµ = 200.00\\nσ2 = 10000.00\\nbid2-max-budg\\n-x-\\nbid3-max-budg\\nµ = 40000.00\\nσ2 = 900000000.00\\nbid3-max-budg\\nµ = 200.00\\nσ2 = 10000.00\\nbid1-max-budget\\n-x-\\nbid3-max-budg\\nµ = 40000.00\\nσ2 = 900000000.00\\nbid2-max-budg\\nµ = 200.00\\nσ2 = 10000.00\\n0.136\\n(0.044)\\n0.120\\n(0.044)\\n0.171\\n(0.044)\\n0.001\\n(0.000)\\n0.000\\n(0.000)\\n0.000\\n(0.000)\\nNotes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\\ndardized path estimate and standard error. There were 343 simulations with these agents: [‘bidder\\n1’, ‘bidder 2’, ‘bidder 3’, ‘auctioneer’].\\n57\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 58, 'text': 'Table A.1: GPT-4’s predictions for the path estimates for the experiments in\\nSection 3 at temperature 0.\\nScenario\\n(Outcome)\\nExogenous\\nVariable\\nPath\\nEstimate\\n(SE)\\nGPT-4\\nGuess\\nTwo-\\ntailed\\nT-Test\\nGPT-4\\nSign\\nCorrect\\n| Predicted\\nExperiment|\\nEstimates\\nMug\\nBargaining\\n(Deal Made)\\nBuyer’s\\nBudget\\n0.037*\\n(0.003)\\n0.05*\\np < 0.001\\nYes\\n1.35\\nSeller’s Min\\nPrice\\n-0.035*\\n(0.002)\\n-0.07*\\np < 0.001\\nYes\\n2.00\\nSeller’s\\nAttachment\\n-0.025*\\n(0.012)\\n0.02\\np < 0.001\\nNo\\n0.80\\nArt Auction\\n(Final Price)\\nBidder 1\\nBudget\\n0.35*\\n(0.015)\\n0.5*\\np < 0.001\\nYes\\n1.43\\nBidder 2\\nValuation\\n0.29*\\n(0.015)\\n0.5*\\np < 0.001\\nYes\\n1.72\\nBidder 3\\nValuation\\n0.31*\\n(0.015 )\\n0.5*\\np < 0.001\\nYes\\n1.610\\nBail Hearing\\n(Bail\\nAmount)\\nDefendant’s\\nPrevious\\nConvictions\\n521.53*\\n(206.567)\\n5000*\\np < 0.001\\nYes\\n9.59\\nJudge Cases\\nThat Day\\n-74.632\\n(109.263)\\n-200\\np = 0.252\\nYes\\n2.68\\nDefendant’s\\nRemorse\\n-1153.061\\n(603.325)\\n-3000*\\np = 0.002\\nYes\\n2.60\\nLawyer\\nInterview\\n(Gets Job)\\nPassed Bar\\n0.750*\\n(0.068)\\n0.6*\\np = 0.03\\nYes\\n0.80\\nInterviewer\\nFriendliness\\n-0.002\\n(0.005)\\n0.2\\np < 0.001\\nNo\\n100.00\\nApplicant’s\\nHeight\\n0.003\\n(0.003)\\n0.1\\np < 0.001\\nYes\\n33.33\\nNotes: The table provides GPT-4’s prediction for the path estimate for each experiment in Section 3\\nFrom left to right, column 1 provides the scenario and outcome, column 2 provides the causal variable\\nname, column 3 the path estimate and its standard error, and column 4 shows the LLM’s prediction\\nfor the path estimate and whether it was predicted to be statistically significant. Column 5 gives\\nthe p-value of a two-tailed t-test comparing the predictions to the results, column 6 is whether the\\npredicted sign of the estimate was correct, and column 7 is the magnitude of the difference between\\nthe predicted and actual estimate.\\n58\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 59, 'text': 'Table A.2: GPT-4’s predictions for the path estimates for the experiments in\\nSection 3 at temperature 1.\\nScenario\\n(Outcome)\\nExogenous\\nVariable\\nPath\\nEstimate\\n(SE)\\nGPT-4\\nGuess\\nTwo-\\ntailed\\nT-Test\\nGPT-4\\nSign\\nCorrect\\n(SE)\\n| Predicted\\nExperiment|\\nEstimates\\nMug\\nBargaining\\n(Deal Made)\\nBuyer’s\\nBudget\\n0.037*\\n(0.003)\\n0.117*\\n(0.016)\\np < 0.001\\nYes\\n3.16\\nSeller’s Min\\nPrice\\n-0.035*\\n(0.002)\\n0.008*\\n(0.018)\\np = 0.019\\nNo\\n0.23\\nSeller’s\\nAttachment\\n-0.025*\\n(0.012)\\n0.062\\n(0.013)\\np < 0.001\\nNo\\n2.48\\nArt Auction\\n(Final Price)\\nBidder 1\\nBudget\\n0.35*\\n(0.015)\\n1.279*\\n(0.501)\\np = 0.064\\nYes\\n3.65\\nBidder 2\\nValuation\\n0.29*\\n(0.015)\\n1.263*\\n(0.501)\\np = 0.053\\nYes\\n4.36\\nBidder 3\\nValuation\\n0.31*\\n(0.015 )\\n1.269*\\n(0.501)\\np = 0.056\\nYes\\n4.09\\nBail Hearing\\n(Bail\\nAmount)\\nDefendant’s\\nPrevious\\nConvictions\\n521.53*\\n(206.567)\\n1785.192*\\n(157.347)\\np < 0.001\\nYes\\n3.42\\nJudge Cases\\nThat Day\\n-74.632\\n(109.263)\\n644.316*\\n(79.919)\\np < 0.001\\nNo\\n8.63\\nDefendant’s\\nRemorse\\n-1153.061\\n(603.325)\\n-879.945*\\n(92.700)\\np = 0.09\\nYes\\n0.76\\nLawyer\\nInterview\\n(Gets Job)\\nPassed Bar\\n0.750*\\n(0.068)\\n0.408*\\n(0.018)\\np = 0.998\\nYes\\n0.54\\nInterviewer\\nFriendliness\\n-0.002\\n(0.005)\\n0.236*\\n(0.015)\\np = 0.999\\nNo\\n118\\nApplicant’s\\nHeight\\n0.003\\n(0.003)\\n0.108\\n(0.009)\\np = 0.999\\nYes\\n36\\nNotes: The table provides GPT-4’s prediction for the path estimate for each experiment in Section 3\\nEach prediction is the average of 100 prompts at temperature 1. From left to right, column 1 provides\\nthe scenario and outcome, column 2 provides the causal variable name, column 3 the path estimate\\nand its standard error, and column 4 shows the LLM’s average prediction for the path estimate\\nand whether it was predicted to be statistically significant more than 50% of the time. The given\\nstandard error is for the mean of the predictions, not the LLM’s prediction for the standard error.\\nColumn 5 gives the p-value of a two-tailed t-test comparing the average prediction to the results,\\ncolumn 6 is whether the predicted sign of the estimate was correct more than 50% of the time, and\\ncolumn 7 is the magnitude of the difference between the predicted and actual estimate.\\n59\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 60, 'text': 'Figure A.8: Fitted SCM for auction with bidder’s reservation prices and second\\nhighest bid as exogenous variables.\\nfinal-art-price\\nµ = 186.53\\nσ2 = 3867.92\\nbid1-max-budget\\nµ = 200.00\\nσ2 = 10000.00\\nbid2-max-budg\\nµ = 200.00\\nσ2 = 10000.00\\nbid3-max-budg\\nµ = 200.00\\nσ2 = 10000.00\\n2nd-highest-budget\\nµ = 180.99\\nσ2 = 4565.99\\n0.047\\n(0.009)\\n0.039\\n(0.008)\\n0.03\\n(0.009)\\nfinal-art-price\\nµ = 186.53\\nσ2 = 3867.92\\n0.826\\n(0.018)\\nNotes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\\ndardized path estimate and standard error. There were 343 simulations with these agents: [‘bidder\\n1’, ‘bidder 2’, ‘bidder 3’, ‘auctioneer’].\\nFigure A.9: Fitted SCM for auction and second highest bid as exogenous variables.\\nfinal-art-price\\nµ = 186.53\\nσ2 = 3867.92\\n2nd-highest-budget\\nµ = 180.99\\nσ2 = 4565.99\\n0.912\\n(0.009)\\nNotes: Each variable is given with its mean and variance. The edges are labeled with their unstan-\\ndardized path estimate and standard error. There were 343 simulations with these agents: [‘bidder\\n1’, ‘bidder 2’, ‘bidder 3’, ‘auctioneer’].\\n60\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 61, 'text': 'Figure A.10: Comparison of the LLM’s predictions to the theoretical predictions\\nand all experimental results for the auction scenario.\\nBidder 3\\nReservation:\\n 50\\nBidder 3\\nReservation:\\n 100\\nBidder 3\\nReservation:\\n 150\\nBidder 3\\nReservation:\\n 200\\nBidder 3\\nReservation:\\n 250\\nBidder 3\\nReservation:\\n 300\\nBidder 3\\nReservation:\\n 350\\nBidder 2\\nReservation:\\n 350\\nBidder 2\\nReservation:\\n 300\\nBidder 2\\nReservation:\\n 250\\nBidder 2\\nReservation:\\n 200\\nBidder 2\\nReservation:\\n 150\\nBidder 2\\nReservation:\\n 100\\nBidder 2\\nReservation:\\n 50\\n100 200 300\\n100 200 300\\n100 200 300\\n100 200 300\\n100 200 300\\n100 200 300\\n100 200 300\\n100\\n200\\n300\\n100\\n200\\n300\\n100\\n200\\n300\\n100\\n200\\n300\\n100\\n200\\n300\\n100\\n200\\n300\\n100\\n200\\n300\\nBidder 1\\nReservation Price\\nFinal Clearing Price\\nAuction Theory\\nPredict yi | β^\\nPredict yi\\nExperiment\\nNotes: The columns correspond to the different reservation values for bidder 3 in a given simulation,\\nand the rows correspond to the different reservation values for bidder 2. The y-axis is the clearing\\nprice, and the x-axis lists bidder 1’s reservation price. The black triangles track the observed clearing\\nprice in each simulated experiment, the black line shows the predictions made by auction theory\\n(MSET heory = 128), the blue line indicates the LLM’s predictions without the fitted SCM—the\\npredict-yi task (MSEyi = 8628), and the red curve is the LLM’s predictions with the fitted SCM—\\nthe predict-yi|ˆβ−i task (MSEyi| ˆβ−i = 1505).\\n61\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 62, 'text': 'Figure A.11: Prompt used to elicity LLM predictions for the Predict-ˆβ task.\\nI have just run an experiment to estimate the paths in the SCM from the\\nTIKZ diagram below, which is delineated by triple backticks.\\nWe ran the\\nexperiment on multiple instances of GPT-4, once for each combination of the\\ndifferent “Attribute Treatments” in the accompanying table. This table also\\nincludes information about the variables and the individual agents involved in\\nthe scenario. Your task is to predict the point estimates for the paths in the\\nSCMs as accurately as possible based on the experiments. You can see the\\nsummary statistics of the treatment variables below each variable name in the\\nTikz Diagram. We want to know how good you are at predicting the outcomes\\nof experiments run on you. Make sure you consider the correct units for both\\nthe cause and the outcome for each path. Please output your answer in the\\nfollowing form and do not include any other text: {’predictions’: dictionary of\\npoint estimate predictions for each path} {’sig’: dictionary of whether or not\\neach path is significant} ‘‘‘Figure X and Table X’’’\\nNotes: For each experiment, we input the accompanying table and the TIKZ diagram into the LLM\\nbetween the triple backticks. For example, for the bargaining scenario, these are Figure 2b and\\nTable 2a.\\n62\\n'}), Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 63, 'text': 'Table A.3: Example of the information generated for each variable in an SCM.\\nInformation Type\\nDeal Occurred\\n(Endogenous)\\nBuyer’s Budget\\n(Exogenous)\\nSeller’s Attachment\\n(Exogenous)\\nOperationalization\\n1 if a deal\\noccurs, 0\\notherwise\\nMax amount the\\nbuyer will\\nspend\\nSeller’s emotional\\nattachment level\\non a scale\\nVariable Type\\nBinary\\nContinuous\\nOrdinal\\nUnits\\nBinary\\nDollars\\nLevels of\\nattachment\\nLevels\\n{0, 1}\\n{$0-$5, ...,\\n$40+}\\n{Low, ..., High}\\nExplicit\\nMeasurement\\nQuestions\\nBuyer:\\n‘‘Did\\na deal\\noccur?’’\\n-\\n-\\nData Aggregation\\nMethod\\nSingle Value\\n-\\n-\\nScenario or\\nIndividual\\n-\\nIndividual\\nIndividual\\nVaried Attribute\\nProxies\\n-\\n‘‘Your budget’’\\n‘‘Your attachment\\nlevel’’\\nAttribute\\nTreatments\\n-\\n{$3, ..., $45}\\n{no attachment,\\n...,\\nextreme attachment}\\nNotes: Each row shows a different piece of information generated for the variables in the SCM.\\nThe first column represents the type of information, the second column represents the information\\nfor the endogenous variable, and the third and fourth columns represent the information for the\\nexogenous variables. This is example information based on the SCM in Figure A.3a.\\n63\\n'})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import ScenarioList\n",
    "\n",
    "scenarios = ScenarioList.from_pdf(ass_pdf.to_tempfile())\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7f65d-c5cd-410c-9675-2d5df4bc3013",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can select pages to use if we do not want to use all of them -- e.g., here we filter just the first page to use with our survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f07e3ae-ca2a-47d0-8f24-12aa6211ee90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><a href='https://docs.expectedparrot.com/en/latest/scenarios.html#scenariolist'>ScenarioList</a> scenarios: 1; keys: ['page', 'filename', 'text'];</p>\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_2b0a5_row0_col0, #T_2b0a5_row0_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2b0a5_row0_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2b0a5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2b0a5_level0_col0\" class=\"col_heading level0 col0\" >filename</th>\n",
       "      <th id=\"T_2b0a5_level0_col1\" class=\"col_heading level0 col1\" >page</th>\n",
       "      <th id=\"T_2b0a5_level0_col2\" class=\"col_heading level0 col2\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2b0a5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2b0a5_row0_col0\" class=\"data row0 col0\" >tmpcui5my9a.pdf</td>\n",
       "      <td id=\"T_2b0a5_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_2b0a5_row0_col2\" class=\"data row0 col2\" >Automated Social Science:\n",
       "Language Models as Scientist and Subjects∗\n",
       "Benjamin S. Manning†\n",
       "MIT\n",
       "Kehang Zhu†\n",
       "Harvard\n",
       "John J. Horton\n",
       "MIT & NBER\n",
       "April 26, 2024\n",
       "Abstract\n",
       "We present an approach for automatically generating and testing, in silico,\n",
       "social scientific hypotheses. This automation is made possible by recent ad-\n",
       "vances in large language models (LLM), but the key feature of the approach\n",
       "is the use of structural causal models. Structural causal models provide a lan-\n",
       "guage to state hypotheses, a blueprint for constructing LLM-based agents, an\n",
       "experimental design, and a plan for data analysis. The fitted structural causal\n",
       "model becomes an object available for prediction or the planning of follow-on\n",
       "experiments. We demonstrate the approach with several scenarios: a nego-\n",
       "tiation, a bail hearing, a job interview, and an auction. In each case, causal\n",
       "relationships are both proposed and tested by the system, finding evidence\n",
       "for some and not others. We provide evidence that the insights from these\n",
       "simulations of social interactions are not available to the LLM purely through\n",
       "direct elicitation. When given its proposed structural causal model for each\n",
       "scenario, the LLM is good at predicting the signs of estimated effects, but\n",
       "it cannot reliably predict the magnitudes of those estimates. In the auction\n",
       "experiment, the in silico simulation results closely match the predictions of\n",
       "auction theory, but elicited predictions of the clearing prices from the LLM\n",
       "are inaccurate. However, the LLM’s predictions are dramatically improved if\n",
       "the model can condition on the fitted structural causal model. In short, the\n",
       "LLM knows more than it can (immediately) tell.\n",
       "∗Thanks to generous support from Drew Houston and his AI for Augmentation and Productivity\n",
       "seed grant. Thanks to Jordan Ellenberg, Benjamin Lira Luttges, David Holtz, Bruce Sacerdote,\n",
       "Paul R¨ottger, Mohammed Alsobay, Ray Duch, Matt Schwartz, David Autor, and Dean Eckles\n",
       "for their helpful feedback. Author’s contact information, code, and data are currently or will be\n",
       "available at http://www.benjaminmanning.io/.\n",
       "†Both authors contributed equally to this work.\n",
       "1\n",
       "arXiv:2404.11794v2  [econ.GN]  25 Apr 2024\n",
       "</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "ScenarioList([Scenario({'filename': 'tmpcui5my9a.pdf', 'page': 1, 'text': 'Automated Social Science:\\nLanguage Models as Scientist and Subjects∗\\nBenjamin S. Manning†\\nMIT\\nKehang Zhu†\\nHarvard\\nJohn J. Horton\\nMIT & NBER\\nApril 26, 2024\\nAbstract\\nWe present an approach for automatically generating and testing, in silico,\\nsocial scientific hypotheses. This automation is made possible by recent ad-\\nvances in large language models (LLM), but the key feature of the approach\\nis the use of structural causal models. Structural causal models provide a lan-\\nguage to state hypotheses, a blueprint for constructing LLM-based agents, an\\nexperimental design, and a plan for data analysis. The fitted structural causal\\nmodel becomes an object available for prediction or the planning of follow-on\\nexperiments. We demonstrate the approach with several scenarios: a nego-\\ntiation, a bail hearing, a job interview, and an auction. In each case, causal\\nrelationships are both proposed and tested by the system, finding evidence\\nfor some and not others. We provide evidence that the insights from these\\nsimulations of social interactions are not available to the LLM purely through\\ndirect elicitation. When given its proposed structural causal model for each\\nscenario, the LLM is good at predicting the signs of estimated effects, but\\nit cannot reliably predict the magnitudes of those estimates. In the auction\\nexperiment, the in silico simulation results closely match the predictions of\\nauction theory, but elicited predictions of the clearing prices from the LLM\\nare inaccurate. However, the LLM’s predictions are dramatically improved if\\nthe model can condition on the fitted structural causal model. In short, the\\nLLM knows more than it can (immediately) tell.\\n∗Thanks to generous support from Drew Houston and his AI for Augmentation and Productivity\\nseed grant. Thanks to Jordan Ellenberg, Benjamin Lira Luttges, David Holtz, Bruce Sacerdote,\\nPaul R¨ottger, Mohammed Alsobay, Ray Duch, Matt Schwartz, David Autor, and Dean Eckles\\nfor their helpful feedback. Author’s contact information, code, and data are currently or will be\\navailable at http://www.benjaminmanning.io/.\\n†Both authors contributed equally to this work.\\n1\\narXiv:2404.11794v2  [econ.GN]  25 Apr 2024\\n'})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automated_social_scientist = scenarios.filter(\"page == 1\")\n",
    "automated_social_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e0775-6f54-47fb-b4b4-21d15573ed3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here we create a survey of questions that we will administer with the selected PDF page. Note that the `from_pdf()` method requires that the scenario placeholders be `{{ text }}` (the key can be renamed as desired):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18bf771b-a06e-4737-aad9-4b218479fc4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from edsl import QuestionFreeText, QuestionList, ScenarioList, Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e927902f-4c40-4df4-9188-fc2fc11a5943",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_summary = QuestionFreeText(\n",
    "    question_name=\"summary\",\n",
    "    question_text=\"Briefly summarize the abstract of this paper: {{ scenario.text }}\",\n",
    ")\n",
    "\n",
    "q_authors = QuestionList(\n",
    "    question_name=\"authors\",\n",
    "    question_text=\"List the names of all the authors of the following paper: {{ scenario.text }}\",\n",
    ")\n",
    "\n",
    "q_thanks = QuestionList(\n",
    "    question_name=\"thanks\",\n",
    "    question_text=\"List the names of the people thanked in the following paper: {{ scenario.text }}\",\n",
    ")\n",
    "\n",
    "survey = Survey([q_summary, q_authors, q_thanks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccab969-3067-4da0-a81a-a606388da844",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we can add the scenario to to the survey and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179aeda5-bd7b-4a61-9772-af1a18456893",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <!-- #region Remove Inference Info -->\n",
       "            <div id=\"logger-e392868a-8a67-44c5-98d2-1cedb880eae3\" class=\"job-logger\">\n",
       "                <div class=\"job-logger-header\">\n",
       "                    <span>\n",
       "                        <span id=\"arrow-e392868a-8a67-44c5-98d2-1cedb880eae3\">▼</span> \n",
       "                        Job Status (2025-03-03 12:21:33)\n",
       "                    </span>\n",
       "                </div>\n",
       "                <div id=\"content-e392868a-8a67-44c5-98d2-1cedb880eae3\" style=\"display: block;\">\n",
       "                    <table class=\"job-logger-table\">\n",
       "                        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Job UUID</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\">2bfc1938-329e-4c90-89ce-0b25ce05fcb8</td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Progress Bar URL</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\"><a href=\"https://www.expectedparrot.com/home/remote-job-progress/2bfc1938-329e-4c90-89ce-0b25ce05fcb8\" target=\"_blank\" class=\"job-logger-link\">https://www.expectedparrot.com/home/remote-job-progress/2bfc1938-329e-4c90-89ce-0b25ce05fcb8</a></td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Exceptions Report URL</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\">None</td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Results UUID</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\">11212188-fc72-4a06-9323-d9a020e22e69</td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Results URL</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\"><a href=\"https://www.expectedparrot.com/content/11212188-fc72-4a06-9323-d9a020e22e69\" target=\"_blank\" class=\"job-logger-link\">https://www.expectedparrot.com/content/11212188-fc72-4a06-9323-d9a020e22e69</a></td>\n",
       "            </tr>\n",
       "        \n",
       "                    </table>\n",
       "                    \n",
       "                <div class=\"job-logger-status\">\n",
       "                    <span style=\"margin-right: 8px;\" class=\"job-logger-success\">✓</span><strong>Current Status:</strong> Job completed and Results stored on Coop: <a href=\"https://www.expectedparrot.com/content/11212188-fc72-4a06-9323-d9a020e22e69\" target=\"_blank\" class=\"job-logger-link\">https://www.expectedparrot.com/content/11212188-fc72-4a06-9323-d9a020e22e69</a>\n",
       "                </div>\n",
       "            \n",
       "                </div>\n",
       "            </div>\n",
       "            <!-- # endregion -->\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Base theme variables */\n",
       "            :root {\n",
       "                --jl-bg-primary: #ffffff;\n",
       "                --jl-bg-secondary: #f5f5f5;\n",
       "                --jl-border-color: #e0e0e0;\n",
       "                --jl-text-primary: #24292e;\n",
       "                --jl-text-secondary: #586069;\n",
       "                --jl-link-color: #0366d6;\n",
       "                --jl-success-color: #28a745;\n",
       "                --jl-error-color: #d73a49;\n",
       "                --jl-header-bg: #f1f1f1;\n",
       "            }\n",
       "            \n",
       "            /* Dark theme variables */\n",
       "            .theme-dark {\n",
       "                --jl-bg-primary: #1e1e1e;\n",
       "                --jl-bg-secondary: #252526;\n",
       "                --jl-border-color: #2d2d2d;\n",
       "                --jl-text-primary: #cccccc;\n",
       "                --jl-text-secondary: #999999;\n",
       "                --jl-link-color: #4e94ce;\n",
       "                --jl-success-color: #89d185;\n",
       "                --jl-error-color: #f14c4c;\n",
       "                --jl-header-bg: #333333;\n",
       "            }\n",
       "\n",
       "            /* High contrast theme variables */\n",
       "            .theme-high-contrast {\n",
       "                --jl-bg-primary: #000000;\n",
       "                --jl-bg-secondary: #1a1a1a;\n",
       "                --jl-border-color: #404040;\n",
       "                --jl-text-primary: #ffffff;\n",
       "                --jl-text-secondary: #cccccc;\n",
       "                --jl-link-color: #66b3ff;\n",
       "                --jl-success-color: #00ff00;\n",
       "                --jl-error-color: #ff0000;\n",
       "                --jl-header-bg: #262626;\n",
       "            }\n",
       "            \n",
       "            .job-logger {\n",
       "                font-family: system-ui, -apple-system, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 10px 0;\n",
       "                color: var(--jl-text-primary);\n",
       "                box-shadow: 0 1px 3px rgba(0,0,0,0.12);\n",
       "                border-radius: 4px;\n",
       "                overflow: hidden;\n",
       "            }\n",
       "            \n",
       "            .job-logger-header {\n",
       "                padding: 12px 16px;\n",
       "                background: var(--jl-header-bg);\n",
       "                border: none;\n",
       "                border-radius: 4px 4px 0 0;\n",
       "                cursor: pointer;\n",
       "                color: var(--jl-text-primary);\n",
       "                user-select: none;\n",
       "                font-weight: 500;\n",
       "                letter-spacing: 0.3px;\n",
       "                display: flex;\n",
       "                justify-content: space-between;\n",
       "                align-items: center;\n",
       "            }\n",
       "            \n",
       "            .theme-select {\n",
       "                padding: 4px 8px;\n",
       "                border-radius: 4px;\n",
       "                border: 1px solid var(--jl-border-color);\n",
       "                background: var(--jl-bg-primary);\n",
       "                color: var(--jl-text-primary);\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            \n",
       "            .job-logger-table {\n",
       "                width: 100%;\n",
       "                border-collapse: separate;\n",
       "                border-spacing: 0;\n",
       "                background: var(--jl-bg-primary);\n",
       "                border: 1px solid var(--jl-border-color);\n",
       "                margin-top: -1px;\n",
       "            }\n",
       "            \n",
       "            .job-logger-cell {\n",
       "                padding: 12px 16px;\n",
       "                border-bottom: 1px solid var(--jl-border-color);\n",
       "                line-height: 1.4;\n",
       "            }\n",
       "            \n",
       "            .job-logger-label {\n",
       "                font-weight: 500;\n",
       "                color: var(--jl-text-primary);\n",
       "                width: 25%;\n",
       "                background: var(--jl-bg-secondary);\n",
       "            }\n",
       "            \n",
       "            .job-logger-value {\n",
       "                color: var(--jl-text-secondary);\n",
       "                word-break: break-word;\n",
       "            }\n",
       "            \n",
       "            .job-logger-status {\n",
       "                margin: 0;\n",
       "                padding: 12px 16px;\n",
       "                background-color: var(--jl-bg-secondary);\n",
       "                border: 1px solid var(--jl-border-color);\n",
       "                border-top: none;\n",
       "                border-radius: 0 0 4px 4px;\n",
       "                color: var(--jl-text-primary);\n",
       "                font-size: 0.95em;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <script>\n",
       "            class ThemeManager {\n",
       "                constructor(logId, initialTheme = 'auto') {\n",
       "                    this.logId = logId;\n",
       "                    this.currentTheme = initialTheme;\n",
       "                    this.darkModeMediaQuery = window.matchMedia('(prefers-color-scheme: dark)');\n",
       "                    this.init();\n",
       "                }\n",
       "                \n",
       "                init() {\n",
       "                    this.setupThemeSwitcher();\n",
       "                    this.updateTheme(this.currentTheme);\n",
       "                    \n",
       "                    this.darkModeMediaQuery.addListener(() => {\n",
       "                        if (this.currentTheme === 'auto') {\n",
       "                            this.updateTheme('auto');\n",
       "                        }\n",
       "                    });\n",
       "                }\n",
       "                \n",
       "                setupThemeSwitcher() {\n",
       "                    const logger = document.querySelector(`#logger-${this.logId}`);\n",
       "                    if (!logger) return;\n",
       "                    \n",
       "                    const switcher = document.createElement('div');\n",
       "                    switcher.className = 'theme-switcher';\n",
       "                    switcher.innerHTML = `\n",
       "                        <select id=\"theme-select-${this.logId}\" class=\"theme-select\">\n",
       "                            <option value=\"auto\">Auto</option>\n",
       "                            <option value=\"light\">Light</option>\n",
       "                            <option value=\"dark\">Dark</option>\n",
       "                            <option value=\"high-contrast\">High Contrast</option>\n",
       "                        </select>\n",
       "                    `;\n",
       "                    \n",
       "                    const header = logger.querySelector('.job-logger-header');\n",
       "                    header.appendChild(switcher);\n",
       "                    \n",
       "                    const select = switcher.querySelector('select');\n",
       "                    select.value = this.currentTheme;\n",
       "                    select.addEventListener('change', (e) => {\n",
       "                        this.updateTheme(e.target.value);\n",
       "                    });\n",
       "                }\n",
       "                \n",
       "                updateTheme(theme) {\n",
       "                    const logger = document.querySelector(`#logger-${this.logId}`);\n",
       "                    if (!logger) return;\n",
       "                    \n",
       "                    this.currentTheme = theme;\n",
       "                    \n",
       "                    logger.classList.remove('theme-light', 'theme-dark', 'theme-high-contrast');\n",
       "                    \n",
       "                    if (theme === 'auto') {\n",
       "                        const isDark = this.darkModeMediaQuery.matches;\n",
       "                        logger.classList.add(isDark ? 'theme-dark' : 'theme-light');\n",
       "                    } else {\n",
       "                        logger.classList.add(`theme-${theme}`);\n",
       "                    }\n",
       "                    \n",
       "                    try {\n",
       "                        localStorage.setItem('jobLoggerTheme', theme);\n",
       "                    } catch (e) {\n",
       "                        console.warn('Unable to save theme preference:', e);\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            \n",
       "            window.initThemeManager = (logId, initialTheme) => {\n",
       "                new ThemeManager(logId, initialTheme);\n",
       "            };\n",
       "        </script>\n",
       "        \n",
       "        <script>\n",
       "            document.addEventListener('DOMContentLoaded', () => {\n",
       "                window.initThemeManager('e392868a-8a67-44c5-98d2-1cedb880eae3', 'auto');\n",
       "            });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = survey.by(automated_social_scientist).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5523072-8025-499e-a144-4ca2f4574591",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can see a list of all the components of results that are directly accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ffbe92-9155-49f2-b824-03e125ce36ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_df7b1_row0_col0, #T_df7b1_row1_col0, #T_df7b1_row2_col0, #T_df7b1_row3_col0, #T_df7b1_row4_col0, #T_df7b1_row5_col0, #T_df7b1_row6_col0, #T_df7b1_row7_col0, #T_df7b1_row8_col0, #T_df7b1_row9_col0, #T_df7b1_row10_col0, #T_df7b1_row11_col0, #T_df7b1_row12_col0, #T_df7b1_row13_col0, #T_df7b1_row14_col0, #T_df7b1_row15_col0, #T_df7b1_row16_col0, #T_df7b1_row17_col0, #T_df7b1_row18_col0, #T_df7b1_row19_col0, #T_df7b1_row20_col0, #T_df7b1_row21_col0, #T_df7b1_row22_col0, #T_df7b1_row23_col0, #T_df7b1_row24_col0, #T_df7b1_row25_col0, #T_df7b1_row26_col0, #T_df7b1_row27_col0, #T_df7b1_row28_col0, #T_df7b1_row29_col0, #T_df7b1_row30_col0, #T_df7b1_row31_col0, #T_df7b1_row32_col0, #T_df7b1_row33_col0, #T_df7b1_row34_col0, #T_df7b1_row35_col0, #T_df7b1_row36_col0, #T_df7b1_row37_col0, #T_df7b1_row38_col0, #T_df7b1_row39_col0, #T_df7b1_row40_col0, #T_df7b1_row41_col0, #T_df7b1_row42_col0, #T_df7b1_row43_col0, #T_df7b1_row44_col0, #T_df7b1_row45_col0, #T_df7b1_row46_col0, #T_df7b1_row47_col0, #T_df7b1_row48_col0, #T_df7b1_row49_col0, #T_df7b1_row50_col0, #T_df7b1_row51_col0, #T_df7b1_row52_col0, #T_df7b1_row53_col0, #T_df7b1_row54_col0, #T_df7b1_row55_col0, #T_df7b1_row56_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_df7b1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_df7b1_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_df7b1_row0_col0\" class=\"data row0 col0\" >agent.agent_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_df7b1_row1_col0\" class=\"data row1 col0\" >agent.agent_instruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_df7b1_row2_col0\" class=\"data row2 col0\" >agent.agent_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_df7b1_row3_col0\" class=\"data row3 col0\" >answer.authors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_df7b1_row4_col0\" class=\"data row4 col0\" >answer.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_df7b1_row5_col0\" class=\"data row5 col0\" >answer.thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_df7b1_row6_col0\" class=\"data row6 col0\" >cache_keys.authors_cache_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_df7b1_row7_col0\" class=\"data row7 col0\" >cache_keys.summary_cache_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_df7b1_row8_col0\" class=\"data row8 col0\" >cache_keys.thanks_cache_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_df7b1_row9_col0\" class=\"data row9 col0\" >cache_used.authors_cache_used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_df7b1_row10_col0\" class=\"data row10 col0\" >cache_used.summary_cache_used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_df7b1_row11_col0\" class=\"data row11 col0\" >cache_used.thanks_cache_used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_df7b1_row12_col0\" class=\"data row12 col0\" >comment.authors_comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_df7b1_row13_col0\" class=\"data row13 col0\" >comment.summary_comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_df7b1_row14_col0\" class=\"data row14 col0\" >comment.thanks_comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_df7b1_row15_col0\" class=\"data row15 col0\" >generated_tokens.authors_generated_tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_df7b1_row16_col0\" class=\"data row16 col0\" >generated_tokens.summary_generated_tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_df7b1_row17_col0\" class=\"data row17 col0\" >generated_tokens.thanks_generated_tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_df7b1_row18_col0\" class=\"data row18 col0\" >iteration.iteration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_df7b1_row19_col0\" class=\"data row19 col0\" >model.frequency_penalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_df7b1_row20_col0\" class=\"data row20 col0\" >model.inference_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_df7b1_row21_col0\" class=\"data row21 col0\" >model.logprobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_df7b1_row22_col0\" class=\"data row22 col0\" >model.max_tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_df7b1_row23_col0\" class=\"data row23 col0\" >model.model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_df7b1_row24_col0\" class=\"data row24 col0\" >model.model_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_df7b1_row25_col0\" class=\"data row25 col0\" >model.presence_penalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_df7b1_row26_col0\" class=\"data row26 col0\" >model.temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_df7b1_row27_col0\" class=\"data row27 col0\" >model.top_logprobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_df7b1_row28_col0\" class=\"data row28 col0\" >model.top_p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_df7b1_row29_col0\" class=\"data row29 col0\" >prompt.authors_system_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_df7b1_row30_col0\" class=\"data row30 col0\" >prompt.authors_user_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_df7b1_row31_col0\" class=\"data row31 col0\" >prompt.summary_system_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_df7b1_row32_col0\" class=\"data row32 col0\" >prompt.summary_user_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_df7b1_row33_col0\" class=\"data row33 col0\" >prompt.thanks_system_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_df7b1_row34_col0\" class=\"data row34 col0\" >prompt.thanks_user_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_df7b1_row35_col0\" class=\"data row35 col0\" >question_options.authors_question_options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_df7b1_row36_col0\" class=\"data row36 col0\" >question_options.summary_question_options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_df7b1_row37_col0\" class=\"data row37 col0\" >question_options.thanks_question_options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_df7b1_row38_col0\" class=\"data row38 col0\" >question_text.authors_question_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_df7b1_row39_col0\" class=\"data row39 col0\" >question_text.summary_question_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_df7b1_row40_col0\" class=\"data row40 col0\" >question_text.thanks_question_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_df7b1_row41_col0\" class=\"data row41 col0\" >question_type.authors_question_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_df7b1_row42_col0\" class=\"data row42 col0\" >question_type.summary_question_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_df7b1_row43_col0\" class=\"data row43 col0\" >question_type.thanks_question_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_df7b1_row44_col0\" class=\"data row44 col0\" >raw_model_response.authors_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_df7b1_row45_col0\" class=\"data row45 col0\" >raw_model_response.authors_one_usd_buys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_df7b1_row46_col0\" class=\"data row46 col0\" >raw_model_response.authors_raw_model_response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_df7b1_row47_col0\" class=\"data row47 col0\" >raw_model_response.summary_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_df7b1_row48_col0\" class=\"data row48 col0\" >raw_model_response.summary_one_usd_buys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_df7b1_row49_col0\" class=\"data row49 col0\" >raw_model_response.summary_raw_model_response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_df7b1_row50_col0\" class=\"data row50 col0\" >raw_model_response.thanks_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_df7b1_row51_col0\" class=\"data row51 col0\" >raw_model_response.thanks_one_usd_buys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_df7b1_row52_col0\" class=\"data row52 col0\" >raw_model_response.thanks_raw_model_response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_df7b1_row53_col0\" class=\"data row53 col0\" >scenario.filename</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_df7b1_row54_col0\" class=\"data row54 col0\" >scenario.page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_df7b1_row55_col0\" class=\"data row55 col0\" >scenario.scenario_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df7b1_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_df7b1_row56_col0\" class=\"data row56 col0\" >scenario.text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "PrettyList(['agent.agent_index',\n",
       "            'agent.agent_instruction',\n",
       "            'agent.agent_name',\n",
       "            'answer.authors',\n",
       "            'answer.summary',\n",
       "            'answer.thanks',\n",
       "            'cache_keys.authors_cache_key',\n",
       "            'cache_keys.summary_cache_key',\n",
       "            'cache_keys.thanks_cache_key',\n",
       "            'cache_used.authors_cache_used',\n",
       "            'cache_used.summary_cache_used',\n",
       "            'cache_used.thanks_cache_used',\n",
       "            'comment.authors_comment',\n",
       "            'comment.summary_comment',\n",
       "            'comment.thanks_comment',\n",
       "            'generated_tokens.authors_generated_tokens',\n",
       "            'generated_tokens.summary_generated_tokens',\n",
       "            'generated_tokens.thanks_generated_tokens',\n",
       "            'iteration.iteration',\n",
       "            'model.frequency_penalty',\n",
       "            'model.inference_service',\n",
       "            'model.logprobs',\n",
       "            'model.max_tokens',\n",
       "            'model.model',\n",
       "            'model.model_index',\n",
       "            'model.presence_penalty',\n",
       "            'model.temperature',\n",
       "            'model.top_logprobs',\n",
       "            'model.top_p',\n",
       "            'prompt.authors_system_prompt',\n",
       "            'prompt.authors_user_prompt',\n",
       "            'prompt.summary_system_prompt',\n",
       "            'prompt.summary_user_prompt',\n",
       "            'prompt.thanks_system_prompt',\n",
       "            'prompt.thanks_user_prompt',\n",
       "            'question_options.authors_question_options',\n",
       "            'question_options.summary_question_options',\n",
       "            'question_options.thanks_question_options',\n",
       "            'question_text.authors_question_text',\n",
       "            'question_text.summary_question_text',\n",
       "            'question_text.thanks_question_text',\n",
       "            'question_type.authors_question_type',\n",
       "            'question_type.summary_question_type',\n",
       "            'question_type.thanks_question_type',\n",
       "            'raw_model_response.authors_cost',\n",
       "            'raw_model_response.authors_one_usd_buys',\n",
       "            'raw_model_response.authors_raw_model_response',\n",
       "            'raw_model_response.summary_cost',\n",
       "            'raw_model_response.summary_one_usd_buys',\n",
       "            'raw_model_response.summary_raw_model_response',\n",
       "            'raw_model_response.thanks_cost',\n",
       "            'raw_model_response.thanks_one_usd_buys',\n",
       "            'raw_model_response.thanks_raw_model_response',\n",
       "            'scenario.filename',\n",
       "            'scenario.page',\n",
       "            'scenario.scenario_index',\n",
       "            'scenario.text'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4219d93-cdb1-493a-8033-7ae18866ad50",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can select components of the results to inspect and print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a501e9-5d1a-4fe4-819c-db3dc20c0bb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_e285a_row0_col0, #T_e285a_row0_col1, #T_e285a_row0_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e285a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e285a_level0_col0\" class=\"col_heading level0 col0\" >answer.summary</th>\n",
       "      <th id=\"T_e285a_level0_col1\" class=\"col_heading level0 col1\" >answer.authors</th>\n",
       "      <th id=\"T_e285a_level0_col2\" class=\"col_heading level0 col2\" >answer.thanks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e285a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e285a_row0_col0\" class=\"data row0 col0\" >The paper introduces a method for automatically generating and testing social science hypotheses using large language models (LLMs) and structural causal models. This approach leverages LLMs to create agents and design experiments, while structural causal models help in formulating hypotheses and analyzing data. The fitted models can be used for predictions or further experiments. The authors demonstrate this method through scenarios like negotiations and auctions, where causal relationships are examined. The study finds that while LLMs can predict the direction of effects, they struggle with estimating magnitudes unless conditioned on the causal model. The research shows that LLMs possess implicit knowledge that becomes evident when structured through causal models.</td>\n",
       "      <td id=\"T_e285a_row0_col1\" class=\"data row0 col1\" >['Benjamin S. Manning', 'Kehang Zhu', 'John J. Horton']</td>\n",
       "      <td id=\"T_e285a_row0_col2\" class=\"data row0 col2\" >['Drew Houston', 'Jordan Ellenberg', 'Benjamin Lira Luttges', 'David Holtz', 'Bruce Sacerdote', 'Paul Röttger', 'Mohammed Alsobay', 'Ray Duch', 'Matt Schwartz', 'David Autor', 'Dean Eckles']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "Dataset([{'answer.summary': ['The paper introduces a method for automatically generating and testing social science hypotheses using large language models (LLMs) and structural causal models. This approach leverages LLMs to create agents and design experiments, while structural causal models help in formulating hypotheses and analyzing data. The fitted models can be used for predictions or further experiments. The authors demonstrate this method through scenarios like negotiations and auctions, where causal relationships are examined. The study finds that while LLMs can predict the direction of effects, they struggle with estimating magnitudes unless conditioned on the causal model. The research shows that LLMs possess implicit knowledge that becomes evident when structured through causal models.']}, {'answer.authors': [['Benjamin S. Manning', 'Kehang Zhu', 'John J. Horton']]}, {'answer.thanks': [['Drew Houston', 'Jordan Ellenberg', 'Benjamin Lira Luttges', 'David Holtz', 'Bruce Sacerdote', 'Paul Röttger', 'Mohammed Alsobay', 'Ray Duch', 'Matt Schwartz', 'David Autor', 'Dean Eckles']]}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.select(\"summary\", \"authors\", \"thanks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c98f56-23eb-4f01-a553-152fd75a408a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Posting to the Coop\n",
    "The [Coop](https://www.expectedparrot.com/content/explore) is a platform for creating, storing and sharing LLM-based research.\n",
    "It is fully integrated with EDSL and accessible from your workspace or Coop account page.\n",
    "Learn more about [creating an account](https://www.expectedparrot.com/login) and [using the Coop](https://docs.expectedparrot.com/en/latest/coop.html).\n",
    "\n",
    "Here we demonstrate how to post this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93d1dd5-509d-48e6-93e1-815d2d892764",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from edsl import Notebook\n",
    "\n",
    "nb = Notebook(path = \"scenario_from_pdf.ipynb\")\n",
    "\n",
    "if refresh := False:\n",
    "    nb.push(\n",
    "        description = \"Example code for generating scenarios from PDFs\", \n",
    "        alias = \"scenario-from-pdf-notebook\",\n",
    "        visibility = \"public\"\n",
    "    )\n",
    "else:\n",
    "    nb.patch('b0bc949b-e3c9-40f8-b5e9-87e0ea2c8e3a', value = nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
