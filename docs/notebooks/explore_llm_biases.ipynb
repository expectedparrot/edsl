{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d4d5c2583fc14fdb895e689f40ba6737",
    "deepnote_cell_type": "markdown",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Cognitive testing & LLM biases\n",
    "This notebook provides example code for using [EDSL](https://docs.expectedparrot.com) to investigate biases of large language models. \n",
    "\n",
    "[EDSL is an open-source library](https://github.com/expectedparrot/edsl) for simulating surveys, experiments and other research with AI agents and large language models. \n",
    "Before running the code below, please ensure that you have [installed the EDSL library](https://docs.expectedparrot.com/en/latest/installation.html) and either [activated remote inference](https://docs.expectedparrot.com/en/latest/remote_inference.html) from your [Coop account](https://docs.expectedparrot.com/en/latest/coop.html) or [stored API keys](https://docs.expectedparrot.com/en/latest/api_keys.html) for the language models that you want to use with EDSL. Please also see our [documentation page](https://docs.expectedparrot.com/) for tips and tutorials on getting started using EDSL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Selecting language models\n",
    "A list of current available models can be viewed [here](https://www.expectedparrot.com/getting-started/coop-pricing).\n",
    "\n",
    "To see a list of service providers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><a href='https://docs.expectedparrot.com/en/latest/scenarios.html#scenariolist'>ScenarioList</a> scenarios: 17; keys: ['service'];</p>\n",
       "        <style>\n",
       "            .edsl-table-64661c96 {\n",
       "                border-collapse: collapse;\n",
       "                width: auto;\n",
       "                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;\n",
       "                font-size: 12px;\n",
       "            }\n",
       "            .edsl-table-64661c96 th {\n",
       "                background-color: rgba(127, 127, 127, 0.2);\n",
       "                backdrop-filter: blur(8px);\n",
       "                -webkit-backdrop-filter: blur(8px);\n",
       "                font-weight: 600;\n",
       "                padding: 12px 8px;\n",
       "                text-align: left;\n",
       "                vertical-align: top;\n",
       "                border: 1px solid rgba(127, 127, 127, 0.3);\n",
       "                border-bottom: 2px solid rgba(127, 127, 127, 0.5);\n",
       "                position: sticky;\n",
       "                top: 0;\n",
       "                z-index: 10;\n",
       "                white-space: nowrap;\n",
       "                min-width: 120px;\n",
       "            }\n",
       "            @media (prefers-color-scheme: light) {\n",
       "                .edsl-table-64661c96 th {\n",
       "                    background-color: rgba(248, 249, 250, 0.9);\n",
       "                    color: #333;\n",
       "                }\n",
       "            }\n",
       "            @media (prefers-color-scheme: dark) {\n",
       "                .edsl-table-64661c96 th {\n",
       "                    background-color: rgba(40, 44, 52, 0.9);\n",
       "                    color: #e6e6e6;\n",
       "                }\n",
       "            }\n",
       "            .edsl-table-64661c96 td {\n",
       "                padding: 8px;\n",
       "                text-align: left;\n",
       "                vertical-align: top;\n",
       "                white-space: pre-wrap;\n",
       "                min-width: 120px;\n",
       "                max-width: 400px;\n",
       "                word-wrap: break-word;\n",
       "                border: 1px solid rgba(127, 127, 127, 0.3);\n",
       "            }\n",
       "            .edsl-table-64661c96 tbody tr:nth-child(odd) {\n",
       "                background-color: rgba(127, 127, 127, 0.05);\n",
       "            }\n",
       "            .edsl-table-64661c96 tbody tr:hover {\n",
       "                background-color: rgba(59, 130, 246, 0.15);\n",
       "            }\n",
       "            .toggle-container-64661c96 {\n",
       "                display: flex;\n",
       "                justify-content: flex-end;\n",
       "                align-items: center;\n",
       "                margin-bottom: 5px;\n",
       "                font-size: 11px;\n",
       "                color: #666;\n",
       "            }\n",
       "            .toggle-switch-64661c96 {\n",
       "                position: relative;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                gap: 8px;\n",
       "            }\n",
       "            .toggle-switch-64661c96 input {\n",
       "                opacity: 0;\n",
       "                width: 0;\n",
       "                height: 0;\n",
       "            }\n",
       "            .toggle-slider-64661c96 {\n",
       "                position: relative;\n",
       "                display: inline-block;\n",
       "                width: 36px;\n",
       "                height: 20px;\n",
       "                background-color: #ccc;\n",
       "                border-radius: 20px;\n",
       "                cursor: pointer;\n",
       "                transition: background-color 0.3s;\n",
       "            }\n",
       "            .toggle-slider-64661c96:before {\n",
       "                content: \"\";\n",
       "                position: absolute;\n",
       "                height: 14px;\n",
       "                width: 14px;\n",
       "                left: 3px;\n",
       "                bottom: 3px;\n",
       "                background-color: white;\n",
       "                border-radius: 50%;\n",
       "                transition: transform 0.3s;\n",
       "            }\n",
       "            .toggle-switch-64661c96 input:checked + .toggle-slider-64661c96 {\n",
       "                background-color: #007bff;\n",
       "            }\n",
       "            .toggle-switch-64661c96 input:checked + .toggle-slider-64661c96:before {\n",
       "                transform: translateX(16px);\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "            <div class=\"toggle-container-64661c96\">\n",
       "                <label class=\"toggle-switch-64661c96\">\n",
       "                    <span style=\"order: -1;\">Off</span>\n",
       "                    <input type=\"checkbox\" id=\"toggle-heatmap-64661c96\" onchange=\"window.toggleHeatmap_64661c96(this.checked)\">\n",
       "                    <span class=\"toggle-slider-64661c96\"></span>\n",
       "                    <span>Heat Map</span>\n",
       "                </label>\n",
       "            </div>\n",
       "            <div style=\"max-height: 500px; overflow-x: auto; overflow-y: auto; width: 100%;\"><table id=\"pandas-table-64661c96\" class=\"edsl-table-64661c96\"><thead><tr><th>service</th></tr></thead><tbody><tr><td>anthropic</td></tr><tr><td>azure</td></tr><tr><td>bedrock</td></tr><tr><td>deep_infra</td></tr><tr><td>deepseek</td></tr><tr><td>google</td></tr><tr><td>groq</td></tr><tr><td>mistral</td></tr><tr><td>ollama</td></tr><tr><td>open_router</td></tr><tr><td>openai</td></tr><tr><td>openai_v2</td></tr><tr><td>perplexity</td></tr><tr><td>remote_proxy_handler</td></tr><tr><td>service_enums</td></tr><tr><td>together</td></tr><tr><td>xai</td></tr></tbody></table></div>\n",
       "            <script>\n",
       "                (function() {\n",
       "                    const tableId = 'pandas-table-64661c96';\n",
       "                    let heatmapEnabled = false;\n",
       "\n",
       "                    window.toggleHeatmap_64661c96 = function(enabled) {\n",
       "                        heatmapEnabled = enabled;\n",
       "                        const table = document.getElementById(tableId);\n",
       "                        if (!table) return;\n",
       "\n",
       "                        const cells = table.querySelectorAll('td[data-percentile]');\n",
       "                        cells.forEach(cell => {\n",
       "                            if (enabled) {\n",
       "                                const percentile = parseFloat(cell.getAttribute('data-percentile'));\n",
       "                                // Single color intensity: light blue to dark blue\n",
       "                                const intensity = percentile / 100;\n",
       "                                const alpha = 0.1 + (intensity * 0.6); // From 10% to 70% opacity\n",
       "                                cell.style.backgroundColor = `rgba(59, 130, 246, ${alpha})`;\n",
       "                            } else {\n",
       "                                cell.style.backgroundColor = '';\n",
       "                            }\n",
       "                        });\n",
       "                    };\n",
       "                })();\n",
       "            </script>\n",
       "            "
      ],
      "text/plain": [
       "ScenarioList(...)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Model\n",
    "\n",
    "Model.services()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To inspect the default model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><a href=''>LanguageModel</a></p>\n",
       "        <style>\n",
       "            .edsl-table-1215cc75 {\n",
       "                border-collapse: collapse;\n",
       "                width: auto;\n",
       "                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;\n",
       "                font-size: 12px;\n",
       "            }\n",
       "            .edsl-table-1215cc75 th {\n",
       "                background-color: rgba(127, 127, 127, 0.2);\n",
       "                backdrop-filter: blur(8px);\n",
       "                -webkit-backdrop-filter: blur(8px);\n",
       "                font-weight: 600;\n",
       "                padding: 12px 8px;\n",
       "                text-align: left;\n",
       "                vertical-align: top;\n",
       "                border: 1px solid rgba(127, 127, 127, 0.3);\n",
       "                border-bottom: 2px solid rgba(127, 127, 127, 0.5);\n",
       "                position: sticky;\n",
       "                top: 0;\n",
       "                z-index: 10;\n",
       "                white-space: nowrap;\n",
       "                min-width: 120px;\n",
       "            }\n",
       "            @media (prefers-color-scheme: light) {\n",
       "                .edsl-table-1215cc75 th {\n",
       "                    background-color: rgba(248, 249, 250, 0.9);\n",
       "                    color: #333;\n",
       "                }\n",
       "            }\n",
       "            @media (prefers-color-scheme: dark) {\n",
       "                .edsl-table-1215cc75 th {\n",
       "                    background-color: rgba(40, 44, 52, 0.9);\n",
       "                    color: #e6e6e6;\n",
       "                }\n",
       "            }\n",
       "            .edsl-table-1215cc75 td {\n",
       "                padding: 8px;\n",
       "                text-align: left;\n",
       "                vertical-align: top;\n",
       "                white-space: pre-wrap;\n",
       "                min-width: 120px;\n",
       "                max-width: 400px;\n",
       "                word-wrap: break-word;\n",
       "                border: 1px solid rgba(127, 127, 127, 0.3);\n",
       "            }\n",
       "            .edsl-table-1215cc75 tbody tr:nth-child(odd) {\n",
       "                background-color: rgba(127, 127, 127, 0.05);\n",
       "            }\n",
       "            .edsl-table-1215cc75 tbody tr:hover {\n",
       "                background-color: rgba(59, 130, 246, 0.15);\n",
       "            }\n",
       "            .toggle-container-1215cc75 {\n",
       "                display: flex;\n",
       "                justify-content: flex-end;\n",
       "                align-items: center;\n",
       "                margin-bottom: 5px;\n",
       "                font-size: 11px;\n",
       "                color: #666;\n",
       "            }\n",
       "            .toggle-switch-1215cc75 {\n",
       "                position: relative;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                gap: 8px;\n",
       "            }\n",
       "            .toggle-switch-1215cc75 input {\n",
       "                opacity: 0;\n",
       "                width: 0;\n",
       "                height: 0;\n",
       "            }\n",
       "            .toggle-slider-1215cc75 {\n",
       "                position: relative;\n",
       "                display: inline-block;\n",
       "                width: 36px;\n",
       "                height: 20px;\n",
       "                background-color: #ccc;\n",
       "                border-radius: 20px;\n",
       "                cursor: pointer;\n",
       "                transition: background-color 0.3s;\n",
       "            }\n",
       "            .toggle-slider-1215cc75:before {\n",
       "                content: \"\";\n",
       "                position: absolute;\n",
       "                height: 14px;\n",
       "                width: 14px;\n",
       "                left: 3px;\n",
       "                bottom: 3px;\n",
       "                background-color: white;\n",
       "                border-radius: 50%;\n",
       "                transition: transform 0.3s;\n",
       "            }\n",
       "            .toggle-switch-1215cc75 input:checked + .toggle-slider-1215cc75 {\n",
       "                background-color: #007bff;\n",
       "            }\n",
       "            .toggle-switch-1215cc75 input:checked + .toggle-slider-1215cc75:before {\n",
       "                transform: translateX(16px);\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "            <div class=\"toggle-container-1215cc75\">\n",
       "                <label class=\"toggle-switch-1215cc75\">\n",
       "                    <span style=\"order: -1;\">Off</span>\n",
       "                    <input type=\"checkbox\" id=\"toggle-heatmap-1215cc75\" onchange=\"window.toggleHeatmap_1215cc75(this.checked)\">\n",
       "                    <span class=\"toggle-slider-1215cc75\"></span>\n",
       "                    <span>Heat Map</span>\n",
       "                </label>\n",
       "            </div>\n",
       "            <div style=\"max-height: 500px; overflow-x: auto; overflow-y: auto; width: 100%;\"><table id=\"pandas-table-1215cc75\" class=\"edsl-table-1215cc75\"><thead><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>model</td><td>gpt-4o</td></tr><tr><td>parameters:temperature</td><td>0.5</td></tr><tr><td>parameters:max_tokens</td><td>1000</td></tr><tr><td>parameters:top_p</td><td>1</td></tr><tr><td>parameters:frequency_penalty</td><td>0</td></tr><tr><td>parameters:presence_penalty</td><td>0</td></tr><tr><td>parameters:logprobs</td><td>False</td></tr><tr><td>parameters:top_logprobs</td><td>3</td></tr><tr><td>inference_service</td><td>openai</td></tr></tbody></table></div>\n",
       "            <script>\n",
       "                (function() {\n",
       "                    const tableId = 'pandas-table-1215cc75';\n",
       "                    let heatmapEnabled = false;\n",
       "\n",
       "                    window.toggleHeatmap_1215cc75 = function(enabled) {\n",
       "                        heatmapEnabled = enabled;\n",
       "                        const table = document.getElementById(tableId);\n",
       "                        if (!table) return;\n",
       "\n",
       "                        const cells = table.querySelectorAll('td[data-percentile]');\n",
       "                        cells.forEach(cell => {\n",
       "                            if (enabled) {\n",
       "                                const percentile = parseFloat(cell.getAttribute('data-percentile'));\n",
       "                                // Single color intensity: light blue to dark blue\n",
       "                                const intensity = percentile / 100;\n",
       "                                const alpha = 0.1 + (intensity * 0.6); // From 10% to 70% opacity\n",
       "                                cell.style.backgroundColor = `rgba(59, 130, 246, ${alpha})`;\n",
       "                            } else {\n",
       "                                cell.style.backgroundColor = '';\n",
       "                            }\n",
       "                        });\n",
       "                    };\n",
       "                })();\n",
       "            </script>\n",
       "            "
      ],
      "text/plain": [
       "Model(model_name = 'gpt-4o', service_name = 'openai', temperature = 0.5, max_tokens = 1000, top_p = 1, frequency_penalty = 0, presence_penalty = 0, logprobs = False, top_logprobs = 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here we select several models to compare their responses for the survey that we create in the steps below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "747d40bea4eb41b5a89d8b374216837e",
    "deepnote_cell_type": "code",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model 'claude-3-5-sonnet-20240620' not found in any service. \n                             Available models: ['claude-3-5-haiku-20241022', 'claude-3-7-sonnet-20250219', 'claude-3-haiku-20240307', 'claude-haiku-4-5-20251001', 'claude-opus-4-1-20250805', 'claude-opus-4-20250514', 'claude-opus-4-5-20251101', 'claude-sonnet-4-20250514', 'claude-sonnet-4-5-20250929', 'azure:gpt-4.1', 'azure:gpt-4.1-2', 'azure:gpt-4.1-mini', 'azure:gpt-4o', 'azure:gpt-4o-mini-test', 'azure:gpt-4o-test', 'azure:o1', 'azure:o1-mini', 'azure:o3-mini', 'azure:o4-mini', 'azure:o4-mini-2', 'ai21.jamba-1-5-large-v1:0', 'ai21.jamba-1-5-mini-v1:0', 'amazon.nova-lite-v1:0', 'amazon.nova-micro-v1:0', 'amazon.nova-pro-v1:0', 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'anthropic.claude-3-haiku-20240307-v1:0', 'anthropic.claude-3-sonnet-20240229-v1:0', 'cohere.command-r-plus-v1:0', 'cohere.command-r-v1:0', 'google.gemma-3-12b-it', 'google.gemma-3-27b-it', 'google.gemma-3-4b-it', 'meta.llama3-70b-instruct-v1:0', 'meta.llama3-8b-instruct-v1:0', 'mistral.magistral-small-2509', 'mistral.ministral-3-14b-instruct', 'mistral.ministral-3-3b-instruct', 'mistral.ministral-3-8b-instruct', 'mistral.mistral-7b-instruct-v0:2', 'mistral.mistral-large-2402-v1:0', 'mistral.mistral-large-3-675b-instruct', 'mistral.mistral-small-2402-v1:0', 'mistral.mixtral-8x7b-instruct-v0:1', 'mistral.voxtral-mini-3b-2507', 'mistral.voxtral-small-24b-2507', 'nvidia.nemotron-nano-12b-v2', 'nvidia.nemotron-nano-3-30b', 'qwen.qwen3-32b-v1:0', 'qwen.qwen3-coder-30b-a3b-v1:0', 'qwen.qwen3-next-80b-a3b', 'qwen.qwen3-vl-235b-a22b', 'Gryphe/MythoMax-L2-13b', 'MiniMaxAI/MiniMax-M2', 'NousResearch/Hermes-3-Llama-3.1-405B', 'NousResearch/Hermes-3-Llama-3.1-70B', 'Qwen/Qwen2.5-72B-Instruct', 'Qwen/Qwen2.5-VL-32B-Instruct', 'Qwen/Qwen3-235B-A22B-Instruct-2507', 'Qwen/Qwen3-235B-A22B-Thinking-2507', 'Qwen/Qwen3-Coder-480B-A35B-Instruct', 'Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo', 'Qwen/Qwen3-Next-80B-A3B-Instruct', 'Qwen/Qwen3-VL-235B-A22B-Instruct', 'Qwen/Qwen3-VL-30B-A3B-Instruct', 'Sao10K/L3-8B-Lunaris-v1-Turbo', 'Sao10K/L3.1-70B-Euryale-v2.2', 'Sao10K/L3.3-70B-Euryale-v2.3', 'allenai/Olmo-3.1-32B-Instruct', 'allenai/olmOCR-2-7B-1025', 'anthropic/claude-3-7-sonnet-latest', 'anthropic/claude-4-opus', 'anthropic/claude-4-sonnet', 'deepseek-ai/DeepSeek-V3', 'deepseek-ai/DeepSeek-V3-0324', 'deepseek-ai/DeepSeek-V3.1', 'deepseek-ai/DeepSeek-V3.1-Terminus', 'deepseek-ai/DeepSeek-V3.2', 'google/gemini-2.5-flash', 'google/gemini-2.5-pro', 'google/gemma-3-12b-it', 'google/gemma-3-27b-it', 'google/gemma-3-4b-it', 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'meta-llama/Llama-3.2-3B-Instruct', 'meta-llama/Llama-3.3-70B-Instruct-Turbo', 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', 'meta-llama/Llama-4-Scout-17B-16E-Instruct', 'meta-llama/Meta-Llama-3-8B-Instruct', 'meta-llama/Meta-Llama-3.1-70B-Instruct', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', 'microsoft/WizardLM-2-8x22B', 'microsoft/phi-4', 'mistralai/Mistral-Nemo-Instruct-2407', 'mistralai/Mistral-Small-24B-Instruct-2501', 'mistralai/Mistral-Small-3.2-24B-Instruct-2506', 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'moonshotai/Kimi-K2-Instruct-0905', 'moonshotai/Kimi-K2-Thinking', 'nvidia/Llama-3.1-Nemotron-70B-Instruct', 'nvidia/Llama-3.3-Nemotron-Super-49B-v1.5', 'nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL', 'nvidia/NVIDIA-Nemotron-Nano-9B-v2', 'nvidia/Nemotron-3-Nano-30B-A3B', 'openai/gpt-oss-120b', 'openai/gpt-oss-120b-Turbo', 'openai/gpt-oss-20b', 'zai-org/GLM-4.6', 'zai-org/GLM-4.6V', 'zai-org/GLM-4.7', 'deepseek-chat', 'deepseek-reasoner', 'gemini-2.0-flash', 'gemini-2.0-flash-001', 'gemini-2.0-flash-exp', 'gemini-2.0-flash-exp-image-generation', 'gemini-2.0-flash-lite', 'gemini-2.0-flash-lite-001', 'gemini-2.0-flash-lite-preview', 'gemini-2.0-flash-lite-preview-02-05', 'gemini-2.5-flash', 'gemini-2.5-flash-image', 'gemini-2.5-flash-lite', 'gemini-2.5-flash-lite-preview-09-2025', 'gemini-2.5-flash-preview-09-2025', 'gemini-2.5-pro', 'gemini-3-flash-preview', 'gemini-3-pro-image-preview', 'gemini-3-pro-preview', 'gemini-flash-latest', 'gemini-flash-lite-latest', 'gemini-pro-latest', 'gemini-robotics-er-1.5-preview', 'gemma-3-12b-it', 'gemma-3-1b-it', 'gemma-3-27b-it', 'gemma-3-4b-it', 'gemma-3n-e2b-it', 'gemma-3n-e4b-it', 'nano-banana-pro-preview', 'allam-2-7b', 'groq/compound', 'groq/compound-mini', 'llama-3.1-8b-instant', 'llama-3.3-70b-versatile', 'meta-llama/llama-4-maverick-17b-128e-instruct', 'meta-llama/llama-4-scout-17b-16e-instruct', 'moonshotai/kimi-k2-instruct', 'moonshotai/kimi-k2-instruct-0905', 'openai/gpt-oss-safeguard-20b', 'codestral-2411-rc5', 'codestral-2412', 'codestral-2501', 'codestral-2508', 'codestral-latest', 'devstral-2512', 'devstral-latest', 'devstral-medium-2507', 'devstral-medium-latest', 'devstral-small-2507', 'devstral-small-latest', 'labs-devstral-small-2512', 'labs-mistral-small-creative', 'ministral-14b-2512', 'ministral-14b-latest', 'ministral-3b-2410', 'ministral-3b-2512', 'ministral-3b-latest', 'ministral-8b-2410', 'ministral-8b-2512', 'ministral-8b-latest', 'mistral-large-2411', 'mistral-large-2512', 'mistral-large-latest', 'mistral-large-pixtral-2411', 'mistral-medium-2505', 'mistral-medium-2508', 'mistral-small-2501', 'mistral-small-2506', 'mistral-small-latest', 'mistral-tiny', 'mistral-tiny-2312', 'mistral-tiny-2407', 'mistral-tiny-latest', 'mistral-vibe-cli-latest', 'open-mistral-7b', 'open-mistral-nemo', 'open-mistral-nemo-2407', 'pixtral-12b', 'pixtral-12b-2409', 'pixtral-12b-latest', 'pixtral-large-2411', 'pixtral-large-latest', 'voxtral-mini-2507', 'voxtral-mini-latest', 'voxtral-small-2507', 'voxtral-small-latest', 'chatgpt-4o-latest', 'gpt-3.5-turbo', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-16k', 'gpt-4', 'gpt-4-0125-preview', 'gpt-4-0613', 'gpt-4-1106-preview', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-turbo-preview', 'gpt-4.1', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano', 'gpt-4.1-nano-2025-04-14', 'gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4o-2024-08-06', 'gpt-4o-2024-11-20', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-5', 'gpt-5-chat-latest', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5.1', 'gpt-5.1-2025-11-13', 'gpt-5.2', 'gpt-5.2-2025-12-11', 'o1', 'o3', 'o3-mini', 'o4-mini', 'gpt-5-2025-08-07', 'gpt-5-codex', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-5-pro-2025-10-06', 'gpt-5.1-chat-latest', 'gpt-5.1-codex', 'gpt-5.1-codex-mini', 'o1-2024-12-17', 'o1-pro', 'o1-pro-2025-03-19', 'o3-2025-04-16', 'o3-mini-2025-01-31', 'o3-pro', 'o3-pro-2025-06-10', 'o4-mini-2025-04-16', 'sonar', 'sonar-deep-research', 'sonar-pro', 'sonar-reasoning-pro', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen/Qwen2.5-7B-Instruct-Turbo', 'Qwen/Qwen3-235B-A22B-Instruct-2507-tput', 'Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8', 'Qwen/Qwen3-Next-80B-A3B-Thinking', 'Qwen/Qwen3-VL-32B-Instruct', 'Qwen/Qwen3-VL-8B-Instruct', 'ServiceNow-AI/Apriel-1.5-15b-Thinker', 'ServiceNow-AI/Apriel-1.6-15b-Thinker', 'arcee-ai/trinity-mini', 'arize-ai/qwen-2-1.5b-instruct', 'deepcogito/cogito-v2-1-671b', 'deepcogito/cogito-v2-preview-llama-109B-MoE', 'deepcogito/cogito-v2-preview-llama-405B', 'deepcogito/cogito-v2-preview-llama-70B', 'deepseek-ai/DeepSeek-R1', 'essentialai/rnj-1-instruct', 'google/gemma-2b-it-Ishan', 'google/gemma-3n-E4B-it', 'marin-community/marin-8b-instruct', 'meta-llama/Llama-3.2-3B-Instruct-Turbo', 'meta-llama/Meta-Llama-3-8B-Instruct-Lite', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'mistralai/Ministral-3-14B-Instruct-2512', 'mistralai/Mistral-7B-Instruct-v0.2', 'mistralai/Mistral-7B-Instruct-v0.3', 'mistralai/Voxtral-Mini-3B-2507', 'scb10x/scb10x-typhoon-2-1-gemma3-12b', 'togethercomputer/Refuel-Llm-V2', 'togethercomputer/Refuel-Llm-V2-Small', 'zai-org/GLM-4.5-Air-FP8', 'grok-2-vision-1212', 'grok-3', 'grok-4-0709', 'grok-4-1-fast-non-reasoning', 'grok-4-1-fast-reasoning', 'grok-4-fast-non-reasoning', 'grok-4-fast-reasoning']. \n                             Available services: ['anthropic', 'azure', 'bedrock', 'deep_infra', 'deepseek', 'google', 'groq', 'mistral', 'openai', 'openai_v2', 'perplexity', 'together', 'xai']\n                            Used source: coop_working",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01medsl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelList\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m models = \u001b[43mModelList\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-5-sonnet-20240620\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tools/ep/edsl/edsl/language_models/model_list.py:101\u001b[39m, in \u001b[36mModelList.__init__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Store the actual model objects if provided\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28mself\u001b[39m._cached_models = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mself\u001b[39m._cached_models = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01medsl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelList\n\u001b[32m      3\u001b[39m models = ModelList(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclaude-3-5-sonnet-20240620\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tools/ep/edsl/edsl/language_models/model.py:123\u001b[39m, in \u001b[36mModel.__new__\u001b[39m\u001b[34m(cls, model_name, service_name, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m         service_name = \u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    122\u001b[39m registry = \u001b[38;5;28mcls\u001b[39m.get_inference_service_registry()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m factory = \u001b[43mregistry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_language_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mservice_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m factory(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tools/ep/edsl/edsl/inference_services/inference_service_registry.py:404\u001b[39m, in \u001b[36mInferenceServiceRegistry.create_language_model\u001b[39m\u001b[34m(self, model_name, service_name, *args, **kwargs)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a language model instance for the given model name.\u001b[39;00m\n\u001b[32m    388\u001b[39m \n\u001b[32m    389\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    400\u001b[39m \u001b[33;03m    KeyError: If the specified service_name is not registered\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m service_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Use automatic lookup as before\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     service_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_service_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service_name:\n\u001b[32m    406\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    407\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo service found for model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    408\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable services: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.list_registered_services()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    409\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tools/ep/edsl/edsl/inference_services/inference_service_registry.py:332\u001b[39m, in \u001b[36mInferenceServiceRegistry.get_service_for_model\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m    330\u001b[39m services = \u001b[38;5;28mself\u001b[39m.model_to_services.get(model_name, [])\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m services:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    333\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found in any service. \u001b[39m\n\u001b[32m    334\u001b[39m \u001b[33m                     Available models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.model_to_services.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\n\u001b[32m    335\u001b[39m \u001b[33m                     Available services: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.service_to_models.keys())\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[33m                    Used source: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._source_handler.used_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    337\u001b[39m     )\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m# Find the first preferred service that provides this model\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m preferred_service \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._service_preferences:\n",
      "\u001b[31mValueError\u001b[39m: Model 'claude-3-5-sonnet-20240620' not found in any service. \n                             Available models: ['claude-3-5-haiku-20241022', 'claude-3-7-sonnet-20250219', 'claude-3-haiku-20240307', 'claude-haiku-4-5-20251001', 'claude-opus-4-1-20250805', 'claude-opus-4-20250514', 'claude-opus-4-5-20251101', 'claude-sonnet-4-20250514', 'claude-sonnet-4-5-20250929', 'azure:gpt-4.1', 'azure:gpt-4.1-2', 'azure:gpt-4.1-mini', 'azure:gpt-4o', 'azure:gpt-4o-mini-test', 'azure:gpt-4o-test', 'azure:o1', 'azure:o1-mini', 'azure:o3-mini', 'azure:o4-mini', 'azure:o4-mini-2', 'ai21.jamba-1-5-large-v1:0', 'ai21.jamba-1-5-mini-v1:0', 'amazon.nova-lite-v1:0', 'amazon.nova-micro-v1:0', 'amazon.nova-pro-v1:0', 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'anthropic.claude-3-haiku-20240307-v1:0', 'anthropic.claude-3-sonnet-20240229-v1:0', 'cohere.command-r-plus-v1:0', 'cohere.command-r-v1:0', 'google.gemma-3-12b-it', 'google.gemma-3-27b-it', 'google.gemma-3-4b-it', 'meta.llama3-70b-instruct-v1:0', 'meta.llama3-8b-instruct-v1:0', 'mistral.magistral-small-2509', 'mistral.ministral-3-14b-instruct', 'mistral.ministral-3-3b-instruct', 'mistral.ministral-3-8b-instruct', 'mistral.mistral-7b-instruct-v0:2', 'mistral.mistral-large-2402-v1:0', 'mistral.mistral-large-3-675b-instruct', 'mistral.mistral-small-2402-v1:0', 'mistral.mixtral-8x7b-instruct-v0:1', 'mistral.voxtral-mini-3b-2507', 'mistral.voxtral-small-24b-2507', 'nvidia.nemotron-nano-12b-v2', 'nvidia.nemotron-nano-3-30b', 'qwen.qwen3-32b-v1:0', 'qwen.qwen3-coder-30b-a3b-v1:0', 'qwen.qwen3-next-80b-a3b', 'qwen.qwen3-vl-235b-a22b', 'Gryphe/MythoMax-L2-13b', 'MiniMaxAI/MiniMax-M2', 'NousResearch/Hermes-3-Llama-3.1-405B', 'NousResearch/Hermes-3-Llama-3.1-70B', 'Qwen/Qwen2.5-72B-Instruct', 'Qwen/Qwen2.5-VL-32B-Instruct', 'Qwen/Qwen3-235B-A22B-Instruct-2507', 'Qwen/Qwen3-235B-A22B-Thinking-2507', 'Qwen/Qwen3-Coder-480B-A35B-Instruct', 'Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo', 'Qwen/Qwen3-Next-80B-A3B-Instruct', 'Qwen/Qwen3-VL-235B-A22B-Instruct', 'Qwen/Qwen3-VL-30B-A3B-Instruct', 'Sao10K/L3-8B-Lunaris-v1-Turbo', 'Sao10K/L3.1-70B-Euryale-v2.2', 'Sao10K/L3.3-70B-Euryale-v2.3', 'allenai/Olmo-3.1-32B-Instruct', 'allenai/olmOCR-2-7B-1025', 'anthropic/claude-3-7-sonnet-latest', 'anthropic/claude-4-opus', 'anthropic/claude-4-sonnet', 'deepseek-ai/DeepSeek-V3', 'deepseek-ai/DeepSeek-V3-0324', 'deepseek-ai/DeepSeek-V3.1', 'deepseek-ai/DeepSeek-V3.1-Terminus', 'deepseek-ai/DeepSeek-V3.2', 'google/gemini-2.5-flash', 'google/gemini-2.5-pro', 'google/gemma-3-12b-it', 'google/gemma-3-27b-it', 'google/gemma-3-4b-it', 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'meta-llama/Llama-3.2-3B-Instruct', 'meta-llama/Llama-3.3-70B-Instruct-Turbo', 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', 'meta-llama/Llama-4-Scout-17B-16E-Instruct', 'meta-llama/Meta-Llama-3-8B-Instruct', 'meta-llama/Meta-Llama-3.1-70B-Instruct', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', 'microsoft/WizardLM-2-8x22B', 'microsoft/phi-4', 'mistralai/Mistral-Nemo-Instruct-2407', 'mistralai/Mistral-Small-24B-Instruct-2501', 'mistralai/Mistral-Small-3.2-24B-Instruct-2506', 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'moonshotai/Kimi-K2-Instruct-0905', 'moonshotai/Kimi-K2-Thinking', 'nvidia/Llama-3.1-Nemotron-70B-Instruct', 'nvidia/Llama-3.3-Nemotron-Super-49B-v1.5', 'nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL', 'nvidia/NVIDIA-Nemotron-Nano-9B-v2', 'nvidia/Nemotron-3-Nano-30B-A3B', 'openai/gpt-oss-120b', 'openai/gpt-oss-120b-Turbo', 'openai/gpt-oss-20b', 'zai-org/GLM-4.6', 'zai-org/GLM-4.6V', 'zai-org/GLM-4.7', 'deepseek-chat', 'deepseek-reasoner', 'gemini-2.0-flash', 'gemini-2.0-flash-001', 'gemini-2.0-flash-exp', 'gemini-2.0-flash-exp-image-generation', 'gemini-2.0-flash-lite', 'gemini-2.0-flash-lite-001', 'gemini-2.0-flash-lite-preview', 'gemini-2.0-flash-lite-preview-02-05', 'gemini-2.5-flash', 'gemini-2.5-flash-image', 'gemini-2.5-flash-lite', 'gemini-2.5-flash-lite-preview-09-2025', 'gemini-2.5-flash-preview-09-2025', 'gemini-2.5-pro', 'gemini-3-flash-preview', 'gemini-3-pro-image-preview', 'gemini-3-pro-preview', 'gemini-flash-latest', 'gemini-flash-lite-latest', 'gemini-pro-latest', 'gemini-robotics-er-1.5-preview', 'gemma-3-12b-it', 'gemma-3-1b-it', 'gemma-3-27b-it', 'gemma-3-4b-it', 'gemma-3n-e2b-it', 'gemma-3n-e4b-it', 'nano-banana-pro-preview', 'allam-2-7b', 'groq/compound', 'groq/compound-mini', 'llama-3.1-8b-instant', 'llama-3.3-70b-versatile', 'meta-llama/llama-4-maverick-17b-128e-instruct', 'meta-llama/llama-4-scout-17b-16e-instruct', 'moonshotai/kimi-k2-instruct', 'moonshotai/kimi-k2-instruct-0905', 'openai/gpt-oss-safeguard-20b', 'codestral-2411-rc5', 'codestral-2412', 'codestral-2501', 'codestral-2508', 'codestral-latest', 'devstral-2512', 'devstral-latest', 'devstral-medium-2507', 'devstral-medium-latest', 'devstral-small-2507', 'devstral-small-latest', 'labs-devstral-small-2512', 'labs-mistral-small-creative', 'ministral-14b-2512', 'ministral-14b-latest', 'ministral-3b-2410', 'ministral-3b-2512', 'ministral-3b-latest', 'ministral-8b-2410', 'ministral-8b-2512', 'ministral-8b-latest', 'mistral-large-2411', 'mistral-large-2512', 'mistral-large-latest', 'mistral-large-pixtral-2411', 'mistral-medium-2505', 'mistral-medium-2508', 'mistral-small-2501', 'mistral-small-2506', 'mistral-small-latest', 'mistral-tiny', 'mistral-tiny-2312', 'mistral-tiny-2407', 'mistral-tiny-latest', 'mistral-vibe-cli-latest', 'open-mistral-7b', 'open-mistral-nemo', 'open-mistral-nemo-2407', 'pixtral-12b', 'pixtral-12b-2409', 'pixtral-12b-latest', 'pixtral-large-2411', 'pixtral-large-latest', 'voxtral-mini-2507', 'voxtral-mini-latest', 'voxtral-small-2507', 'voxtral-small-latest', 'chatgpt-4o-latest', 'gpt-3.5-turbo', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-16k', 'gpt-4', 'gpt-4-0125-preview', 'gpt-4-0613', 'gpt-4-1106-preview', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-turbo-preview', 'gpt-4.1', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano', 'gpt-4.1-nano-2025-04-14', 'gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4o-2024-08-06', 'gpt-4o-2024-11-20', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-5', 'gpt-5-chat-latest', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5.1', 'gpt-5.1-2025-11-13', 'gpt-5.2', 'gpt-5.2-2025-12-11', 'o1', 'o3', 'o3-mini', 'o4-mini', 'gpt-5-2025-08-07', 'gpt-5-codex', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-5-pro-2025-10-06', 'gpt-5.1-chat-latest', 'gpt-5.1-codex', 'gpt-5.1-codex-mini', 'o1-2024-12-17', 'o1-pro', 'o1-pro-2025-03-19', 'o3-2025-04-16', 'o3-mini-2025-01-31', 'o3-pro', 'o3-pro-2025-06-10', 'o4-mini-2025-04-16', 'sonar', 'sonar-deep-research', 'sonar-pro', 'sonar-reasoning-pro', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen/Qwen2.5-7B-Instruct-Turbo', 'Qwen/Qwen3-235B-A22B-Instruct-2507-tput', 'Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8', 'Qwen/Qwen3-Next-80B-A3B-Thinking', 'Qwen/Qwen3-VL-32B-Instruct', 'Qwen/Qwen3-VL-8B-Instruct', 'ServiceNow-AI/Apriel-1.5-15b-Thinker', 'ServiceNow-AI/Apriel-1.6-15b-Thinker', 'arcee-ai/trinity-mini', 'arize-ai/qwen-2-1.5b-instruct', 'deepcogito/cogito-v2-1-671b', 'deepcogito/cogito-v2-preview-llama-109B-MoE', 'deepcogito/cogito-v2-preview-llama-405B', 'deepcogito/cogito-v2-preview-llama-70B', 'deepseek-ai/DeepSeek-R1', 'essentialai/rnj-1-instruct', 'google/gemma-2b-it-Ishan', 'google/gemma-3n-E4B-it', 'marin-community/marin-8b-instruct', 'meta-llama/Llama-3.2-3B-Instruct-Turbo', 'meta-llama/Meta-Llama-3-8B-Instruct-Lite', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'mistralai/Ministral-3-14B-Instruct-2512', 'mistralai/Mistral-7B-Instruct-v0.2', 'mistralai/Mistral-7B-Instruct-v0.3', 'mistralai/Voxtral-Mini-3B-2507', 'scb10x/scb10x-typhoon-2-1-gemma3-12b', 'togethercomputer/Refuel-Llm-V2', 'togethercomputer/Refuel-Llm-V2-Small', 'zai-org/GLM-4.5-Air-FP8', 'grok-2-vision-1212', 'grok-3', 'grok-4-0709', 'grok-4-1-fast-non-reasoning', 'grok-4-1-fast-reasoning', 'grok-4-fast-non-reasoning', 'grok-4-fast-reasoning']. \n                             Available services: ['anthropic', 'azure', 'bedrock', 'deep_infra', 'deepseek', 'google', 'groq', 'mistral', 'openai', 'openai_v2', 'perplexity', 'together', 'xai']\n                            Used source: coop_working"
     ]
    }
   ],
   "source": [
    "from edsl import ModelList\n",
    "\n",
    "models = ModelList(\n",
    "    Model(m) for m in [\"gemini-2.5-flash\", \"gpt-4o\", \"claude-3-5-sonnet-20240620\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Generating content\n",
    "EDSL comes with a variety of standard survey question types, such as multiple choice, free text, etc. These can be selected based on the desired format of the response. See details about all types [here](https://docs.expectedparrot.com/en/latest/questions.html#question-type-classes). We can use `QuestionFreeText` to prompt the models to generate some content for our experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1325605571cc41a194255b80b2fb2f87",
    "deepnote_cell_type": "code",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from edsl import QuestionFreeText\n",
    "\n",
    "q = QuestionFreeText(\n",
    "    question_name = \"poem\",\n",
    "    question_text = \"Please draft a short poem about any topic. Return only the poem.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We generate a response to the question by adding the models to use with the `by` method and then calling the `run` method. This generates a `Results` object with a `Result` for each response to the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "724ca2c7a38f4164a225ed4a8dcc2b1f",
    "deepnote_cell_type": "code",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = q.by(models).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To see a list of all components of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "054ec708d2f84854b971127f64ff2054",
    "deepnote_cell_type": "code",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can inspect components of the results individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c68d3be8bada402ea17184b978abfa70",
    "deepnote_cell_type": "code",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.select(\"model\", \"poem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "09c51c4a264248d3a6ca865d70844279",
    "deepnote_cell_type": "markdown",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Conducting a review\n",
    "Next we create a question to have a model evaluating a response that we use as an input to the new question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from edsl import QuestionLinearScale\n",
    "\n",
    "q_score = QuestionLinearScale(\n",
    "    question_name = \"score\",\n",
    "    question_text = \"Please give the following poem a score. No easy grading! Poem: {{ scenario.poem }}\",\n",
    "    question_options = [0, 1, 2, 3, 4, 5],\n",
    "    option_labels = {0: \"Very poor\", 5: \"Excellent\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Parameterizing questions\n",
    "We use `Scenario` objects to add each response to the new question. EDSL comes with many methods for creating scenarios from different data sources (PDFs, CSVs, docs, images, lists, etc.), as well as `Results` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenarios = (\n",
    "    results.to_scenario_list()\n",
    "    .select(\"model\", \"poem\")\n",
    "    .rename({\"model\": \"drafting_model\"}) # renaming the 'model' field to distinguish the evaluating model \n",
    ")\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Finally, we conduct the evaluation by having each model score each haiku that was generated (without information about whether the model itself was the source):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = q_score.by(scenarios).by(models).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.sort_by(\"drafting_model\", \"model\").select(\"drafting_model\", \"model\", \"poem\", \"score\", \"score_comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Posting to the Coop\n",
    "The [Coop](https://www.expectedparrot.com/content/explore) is a platform for creating, storing and sharing LLM-based research.\n",
    "It is fully integrated with EDSL and accessible from your workspace or Coop account page.\n",
    "Learn more about [creating an account](https://www.expectedparrot.com/login) and [using the Coop](https://docs.expectedparrot.com/en/latest/coop.html).\n",
    "\n",
    "Here we post this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from edsl import Notebook\n",
    "\n",
    "nb = Notebook(path = \"explore_llm_biases.ipynb\")\n",
    "\n",
    "if refresh := False:\n",
    "    nb.push(\n",
    "        description = \"Example code for comparing model responses and biases\", \n",
    "        alias = \"explore-llm-biases-notebook\",\n",
    "        visibility = \"public\"\n",
    "    )\n",
    "else:\n",
    "    nb.patch(\"https://www.expectedparrot.com/content/RobinHorton/explore-llm-biases-notebook\", value = nb)"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6d1e666ba52649708894044c2a755567",
  "deepnote_persisted_session": {
   "createdAt": "2024-03-01T17:07:23.650Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
