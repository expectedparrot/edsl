{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6beea6a-e628-4363-9a2c-247b396479d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Model test report\n",
    "This notebook provides example EDSL code for running test questions with language models of your choice and generating a model performance report.\n",
    "It is the same test that is run daily to update the model pricing and availability page at [Coop](https://www.expectedparrot.com/login), a free platform for creating and sharing AI-based research: https://www.expectedparrot.com/home/report.\n",
    "\n",
    "The text questions are designed to show whether a given model is live (not deprecated) and capable of answering a simple question, and also whether it is a vision model, capable of recognizing a simple image (a picture of the Expected Parrot logo).\n",
    "The questions are readily editable and can be modified to test other content of your choice, e.g., more complicated questions or question types, or other data types.\n",
    "EDSL comes with a variety of methods for automatically adding different types of content to your surveys, including PNG, PDS, CSV, tables, dictionaries, lists, etc., which we also demonstrate below.\n",
    "We recommend using and modifying the code as needed to individually test the models, questions, scenarios and other components of your job before running a larger job.\n",
    "\n",
    "To learn more about each of the objects and methods used below please see the EDSL [documentation page](https://docs.expectedparrot.com).\n",
    "\n",
    "If you have questions or need help, please post a message to our [Discord channel](https://discord.com/invite/mxAYkjfy9m) or send an email to info@expected parrot.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05769d8b-0aea-4f23-b302-cd65769720a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import (\n",
    "    Cache,\n",
    "    FileStore,\n",
    "    Model,\n",
    "    ModelList,\n",
    "    QuestionMultipleChoice,\n",
    "    QuestionFreeText,\n",
    "    Scenario,\n",
    "    ScenarioList,\n",
    "    Survey,\n",
    "    Results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6970a2a-90e1-48d9-a721-cab56ebc3448",
   "metadata": {},
   "source": [
    "## Test questions\n",
    "Here we create a survey of simple questions to test each model's ability to answer a question and recognize an image.\n",
    "Modify the questions and question types as needed to test a model's ability to complete your own survey.\n",
    "(If you add other question types, be sure to import them above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19533a99-93f6-4987-8ad3-17e259dc8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = QuestionMultipleChoice(\n",
    "    question_name = \"capital_of_france\",\n",
    "    question_text = \"What is the capital of France?\",\n",
    "    question_options = [\"Paris\", \"London\", \"Berlin\"],\n",
    ")\n",
    "\n",
    "q2 = QuestionFreeText(\n",
    "    question_name = \"image_description\",\n",
    "    question_text = \"Describe what you see in this image: {{ image }}\",\n",
    ")\n",
    "\n",
    "survey = Survey(questions=[q1, q2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789f616-9048-42ec-9eb0-1258a14fa3ec",
   "metadata": {},
   "source": [
    "## Scenarios\n",
    "The second test question above uses a `{{ placeholder }}` for content to be added to the question when it is run.\n",
    "EDSL comes with a variety of methods for automatically adding \"scenarios\" or content to your questions from different data and file types, including PNG, PDF, CSV, text, dictionarities, lists, tables, etc. \n",
    "\n",
    "Here we add an image in order for our test report to identify vision models capable of recognizing a simple picture (the Expected Parrot logo). \n",
    "First, we use the `FileStore` module to [post the image to Coop]() and make it accessible to anyone using this notebook to access it. (Content is unlisted by default; you can make content public or private from your workspace or at the web app. Learn more about [using the filestore](https://docs.expectedparrot.com/en/latest/filestore.html) and [sharing content at Coop](https://docs.expectedparrot.com/en/latest/coop.html).) \n",
    "\n",
    "Then we retrieve it and use it in a `Scenario`. (We could also use multiple images or other content at once. Learn more about [using scenarios to parameterize questions](https://docs.expectedparrot.com/en/latest/scenarios.html) or add metadata to your surveys.)\n",
    "Modify the steps below to use other content with your questions.\n",
    "\n",
    "**Note:** You must have a Coop account in order to post and retrieve content. \n",
    "To run this test with local content only, simply [create a scenario](https://docs.expectedparrot.com/en/latest/scenarios.html) and add it to the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da75cd-212e-4647-8c97-fbb0c8dbfaea",
   "metadata": {},
   "source": [
    "To post a file to Coop and use it in a scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae1dc82-347b-4efa-a1e5-954699dce93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = FileStore(path = \"path/to/file.png\") # update with local filename\n",
    "# scenario = Scenario({\"image\": fs}) # use the parameter key from your question\n",
    "# scenario_list = ScenarioList(data=[scenario])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e560fd-8883-44c0-8240-42c1362aa5f4",
   "metadata": {},
   "source": [
    "To retrieve any available file at Coop to use in a scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c56c5d-ccda-4801-9bcf-f160cb982aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FileStore.pull(\"d6f7e806-1e36-42f0-8979-ccbd4d180b29\") # parrot logo image - update Coop uuid for other images\n",
    "scenario = Scenario({\"image\": fs}) # update to match the parameter key used in your question  \n",
    "scenario_list = ScenarioList(data=[scenario])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48fdce-5006-42ab-b191-3561aa67b1f5",
   "metadata": {},
   "source": [
    "## Update job\n",
    "Create or update the job as needed if there are any edits to the survey questions or scenarios that have been created.\n",
    "(Delete the scenario list if not being used, or replace with new scenarios that have been created.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143983e9-3420-4be2-bcc9-509230349c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = survey.by(scenario_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d795a-b7a5-4974-af80-9f705b6e2442",
   "metadata": {},
   "source": [
    "## Run the test\n",
    "The code below shows how to see a list of available services and specify which ones you want to test.\n",
    "You can also check whether you currently have a local key stored for any service.\n",
    "\n",
    "**Note:** You must have local keys stored for the services that you want to test.\n",
    "Otherwise, you can modify the test code inputs to run the test remotely.\n",
    "\n",
    "To see a list of all services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2868d4e-750f-48ff-91d7-eab41cb04d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_02d2f_row0_col0, #T_02d2f_row1_col0, #T_02d2f_row2_col0, #T_02d2f_row3_col0, #T_02d2f_row4_col0, #T_02d2f_row5_col0, #T_02d2f_row6_col0, #T_02d2f_row7_col0, #T_02d2f_row8_col0, #T_02d2f_row9_col0, #T_02d2f_row10_col0, #T_02d2f_row11_col0, #T_02d2f_row12_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_02d2f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_02d2f_level0_col0\" class=\"col_heading level0 col0\" >Service Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_02d2f_row0_col0\" class=\"data row0 col0\" >anthropic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_02d2f_row1_col0\" class=\"data row1 col0\" >azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_02d2f_row2_col0\" class=\"data row2 col0\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_02d2f_row3_col0\" class=\"data row3 col0\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_02d2f_row4_col0\" class=\"data row4 col0\" >deepseek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_02d2f_row5_col0\" class=\"data row5 col0\" >google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_02d2f_row6_col0\" class=\"data row6 col0\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_02d2f_row7_col0\" class=\"data row7 col0\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_02d2f_row8_col0\" class=\"data row8 col0\" >ollama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_02d2f_row9_col0\" class=\"data row9 col0\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_02d2f_row10_col0\" class=\"data row10 col0\" >perplexity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_02d2f_row11_col0\" class=\"data row11 col0\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02d2f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_02d2f_row12_col0\" class=\"data row12 col0\" >xai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "PrettyList([['anthropic'],\n",
       "            ['azure'],\n",
       "            ['bedrock'],\n",
       "            ['deep_infra'],\n",
       "            ['deepseek'],\n",
       "            ['google'],\n",
       "            ['groq'],\n",
       "            ['mistral'],\n",
       "            ['ollama'],\n",
       "            ['openai'],\n",
       "            ['perplexity'],\n",
       "            ['together'],\n",
       "            ['xai']])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.services()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29a861-78c3-42d4-b546-cf2a44475e79",
   "metadata": {},
   "source": [
    "Change this parameter to `False` if you want to test the models remotely (i.e., not using your own keys for language models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0111dd-d5f9-44a3-b6f5-0a1903d7d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_remote_inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c48a1-c249-4749-89dc-3d22474144f8",
   "metadata": {},
   "source": [
    "Update this code to identify the services that you want to test with your keys.\n",
    "All the models for the service will be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1326ea1c-fe7c-4da4-b928-be1916804754",
   "metadata": {},
   "outputs": [],
   "source": [
    "services_to_test = ['google'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696329bc-1413-4232-ae3a-8acd81f4115f",
   "metadata": {},
   "source": [
    "Specify a filename for the test results that will be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12071c33-d2fb-42af-bca2-cc7e5df1264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test_model_report.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b9f9d-b9c2-4455-a0cb-8a3c0c55922e",
   "metadata": {},
   "source": [
    "Code for the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4afcfa7-7423-4713-b41d-4f4cb376d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from typing import Optional, List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da2cbe53-186e-4116-8aac-87f80d4dd5c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelTest:\n",
    "    def __init__(self):\n",
    "        pass  \n",
    "\n",
    "    def get_model_to_services_mapping(\n",
    "        self, available_models: list[list[str, str]]\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Returns a mapping of model names to their available inference services.\n",
    "        \"\"\"\n",
    "        model_to_services = {}\n",
    "        for item in available_models:\n",
    "            model_name = item[0]\n",
    "            inference_service = item[1]\n",
    "            if model_name in model_to_services:\n",
    "                model_to_services[model_name].append(inference_service)\n",
    "            else:\n",
    "                model_to_services[model_name] = [inference_service]\n",
    "    \n",
    "        return model_to_services\n",
    "    \n",
    "    def get_unique_services(self, available_models: list[list[str, str]]) -> list[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the list of unique services.\n",
    "        \"\"\"\n",
    "        unique_services = set()\n",
    "        for item in available_models:\n",
    "            service_name = item[1]\n",
    "            unique_services.add(service_name)\n",
    "        return list(unique_services)\n",
    "    \n",
    "    def get_model_list(\n",
    "        self, available_models: list[list[str, str]], services_to_run: list[str]\n",
    "    ) -> ModelList:\n",
    "        \"\"\"\n",
    "        Returns the EDSL ModelList object with the models that we want to test.\n",
    "        \"\"\"\n",
    "        models = []\n",
    "        for model_data in available_models:\n",
    "            model_name = model_data[0]\n",
    "            service_name = model_data[1]\n",
    "    \n",
    "            if service_name in services_to_run:\n",
    "                m = Model(service_name=service_name, model_name=model_name)\n",
    "                models.append(m)\n",
    "    \n",
    "        model_list = ModelList(data=models)\n",
    "        return model_list\n",
    "    \n",
    "    def run_job(\n",
    "        self, available_models: list[list[str, str]], services_to_run: list[str]\n",
    "    ) -> Results:\n",
    "        \"\"\"\n",
    "        Runs the test job.\n",
    "        \"\"\"    \n",
    "        model_list = self.get_model_list(available_models, services_to_run)\n",
    "    \n",
    "        results = (\n",
    "            survey.by(scenario_list)\n",
    "            .by(model_list)\n",
    "            .run(\n",
    "                cache=Cache(),\n",
    "                disable_remote_cache=True,\n",
    "                disable_remote_inference=disable_remote_inference,\n",
    "                print_exceptions=False,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    def get_inference_service(\n",
    "        self, model_name: str, model_to_services: dict\n",
    "    ) -> str | None:\n",
    "        \"\"\"\n",
    "        Maps a model to a single inference service, removing that service from all other models.\n",
    "        Returns the selected inference service for the model, or None if no service available.\n",
    "        \"\"\"\n",
    "        # If model doesn't exist or has no services, return None\n",
    "        if model_name not in model_to_services or not model_to_services[model_name]:\n",
    "            return None\n",
    "    \n",
    "        # Take the first available service for this model\n",
    "        selected_service = model_to_services[model_name][0]\n",
    "    \n",
    "        # Remove this service from the model's available services\n",
    "        if selected_service in model_to_services[model_name]:\n",
    "            model_to_services[model_name].remove(selected_service)\n",
    "    \n",
    "        return selected_service\n",
    "    \n",
    "    def parse_exceptions(self, exceptions_dict: dict, field_name: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Parses exceptions for a specific field from the exceptions dictionary.\n",
    "        Returns a joined string of unique exceptions. If there are no exceptions, returns None.\n",
    "        \"\"\"\n",
    "        if field_name not in exceptions_dict:\n",
    "            return None\n",
    "    \n",
    "        unique_exceptions = []\n",
    "        for exception in exceptions_dict[field_name]:\n",
    "            exception_data = exception[\"exception\"]\n",
    "            formatted_exception = (\n",
    "                f\"{exception_data['type']}: {exception_data['message']}\"\n",
    "            )\n",
    "            if formatted_exception not in unique_exceptions:\n",
    "                unique_exceptions.append(formatted_exception)\n",
    "    \n",
    "        if unique_exceptions:\n",
    "            return \"\\n\".join(unique_exceptions)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def parse_results_dict(self, results: dict, model_to_services: dict) -> list[dict]:\n",
    "        \"\"\"\n",
    "        Parses the results dictionary and returns a list of dictionaries with the results.\n",
    "        \"\"\"\n",
    "        records = []\n",
    "    \n",
    "        for key in results.keys():\n",
    "            if key == \"data\":\n",
    "                data = results[key]\n",
    "                for index, item in enumerate(data):\n",
    "                    task_history = results.get(\"task_history\")\n",
    "                    if task_history is not None:\n",
    "                        exceptions_dict = task_history[\"interviews\"][index][\n",
    "                            \"exceptions\"\n",
    "                        ]\n",
    "    \n",
    "                        capital_of_france_exceptions_string = self.parse_exceptions(\n",
    "                            exceptions_dict, \"capital_of_france\"\n",
    "                        )\n",
    "                        image_description_exceptions_string = self.parse_exceptions(\n",
    "                            exceptions_dict, \"image_description\"\n",
    "                        )\n",
    "                    else:\n",
    "                        capital_of_france_exceptions_string = None\n",
    "                        image_description_exceptions_string = None\n",
    "    \n",
    "                    records.append(\n",
    "                        {\n",
    "                            \"inference_service\": self.get_inference_service(\n",
    "                                model_name=item[\"model\"][\"model\"],\n",
    "                                model_to_services=model_to_services,\n",
    "                            ),\n",
    "                            \"model\": item[\"model\"][\"model\"],\n",
    "                            \"answer_capital_of_france\": item[\"answer\"][\n",
    "                                \"capital_of_france\"\n",
    "                            ],\n",
    "                            \"answer_image_description\": item[\"answer\"][\n",
    "                                \"image_description\"\n",
    "                            ],\n",
    "                            \"exceptions_capital_of_france\": capital_of_france_exceptions_string,\n",
    "                            \"exceptions_image_description\": image_description_exceptions_string,\n",
    "                            \"works_with_text\": item[\"answer\"][\"capital_of_france\"]\n",
    "                            == \"Paris\",\n",
    "                            \"works_with_images\": type(\n",
    "                                item[\"answer\"][\"image_description\"]\n",
    "                            )\n",
    "                            == str\n",
    "                            and \"parrot\" in item[\"answer\"][\"image_description\"],\n",
    "                        }\n",
    "                    )\n",
    "        return records\n",
    "    \n",
    "    \n",
    "    def save_to_file(self, results: 'Results', records: List[Dict], filename=\"test_model_report.csv\"):\n",
    "        \"\"\"\n",
    "        Saves the results of this test to a CSV file.\n",
    "        \"\"\"\n",
    "        if records:\n",
    "            # Determine the fieldnames from the keys of the first record\n",
    "            fieldnames = records[0].keys()\n",
    "    \n",
    "            with open(filename, \"w\", newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "                # Write the header row\n",
    "                writer.writeheader()\n",
    "    \n",
    "                # Write each dictionary as a row in the CSV\n",
    "                for record in records:\n",
    "                    writer.writerow(record)\n",
    "\n",
    "                    \n",
    "    \n",
    "    def run_test(\n",
    "        self, services: Optional[list[str]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Runs the test, parses the results, and saves to a file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"Running model test...\")\n",
    "    \n",
    "            start_time = time.time()\n",
    "    \n",
    "            available_models = Model.available()\n",
    "    \n",
    "            unique_services = self.get_unique_services(available_models)\n",
    "    \n",
    "            if services is None:\n",
    "                services_to_run = unique_services\n",
    "            else:\n",
    "                services_to_run = services\n",
    "    \n",
    "            try:\n",
    "                services_to_run.remove(\"azure\")\n",
    "            except ValueError:\n",
    "                pass\n",
    "    \n",
    "            results = self.run_job(available_models, services_to_run)\n",
    "    \n",
    "            end_time = time.time()\n",
    "    \n",
    "            runtime = end_time - start_time\n",
    "            runtime_td = timedelta(seconds=runtime)\n",
    "            runtime_in_seconds = runtime_td.total_seconds()\n",
    "    \n",
    "            print(\n",
    "                f\"Finished running model test. Runtime: {runtime_in_seconds:.3f} seconds\"\n",
    "            )\n",
    "    \n",
    "            print(\"Parsing results...\")\n",
    "    \n",
    "            model_to_services = self.get_model_to_services_mapping(available_models)\n",
    "            records = self.parse_results_dict(results.to_dict(), model_to_services)\n",
    "    \n",
    "            print(\"Finished parsing results.\")\n",
    "            print(f\"Saving to {'file'}...\")\n",
    "    \n",
    "            self.save_to_file(results, records)\n",
    "    \n",
    "            print(f\"Finished saving to {'file'}.\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(\"Exception running model test:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab4c750-4e4e-470b-8d15-caf1ecec12db",
   "metadata": {},
   "source": [
    "Running the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4944816d-3f80-49de-bb41-fec59c60f3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model test...\n",
      "Finished running model test. Runtime: 74.890 seconds\n",
      "Parsing results...\n",
      "Finished parsing results.\n",
      "Saving to file...\n",
      "Finished saving to file.\n"
     ]
    }
   ],
   "source": [
    "test_instance = ModelTest()\n",
    "test_instance.run_test(services=services_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf39aa4-a5e0-4e54-ad1b-4a92aad9f70c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Posting this notebook to Coop\n",
    "Here we also demonstrate how to post any object to Coop, such as this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4ed68a-36a9-46b4-b565-0a742e6ae0a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Run a model test report',\n",
       " 'object_type': 'notebook',\n",
       " 'url': 'https://www.expectedparrot.com/content/0702ea15-6720-4af2-b8e0-1baed4b900c9',\n",
       " 'uuid': '0702ea15-6720-4af2-b8e0-1baed4b900c9',\n",
       " 'version': '0.1.45.dev1',\n",
       " 'visibility': 'public'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Notebook\n",
    "\n",
    "n = Notebook(\"model_test_report.ipynb\")\n",
    "n.push(description = \"Run a model test report\", visibility = \"public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5954ccb-b655-4ee8-99b7-ac0890f475aa",
   "metadata": {},
   "source": [
    "To update an object at Coop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfea9c8a-3508-420a-966a-2e86ab33238a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Notebook\n",
    "\n",
    "n = Notebook(\"model_test_report.ipynb\") # resave the object\n",
    "n.patch(uuid = \"0702ea15-6720-4af2-b8e0-1baed4b900c9\", value = n) # specify the Coop uuid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
